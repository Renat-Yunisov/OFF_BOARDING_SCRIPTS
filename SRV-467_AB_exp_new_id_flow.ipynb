{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b53678",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd4017f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisation\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Data analysis / Data processing\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.options.display.float_format = \"{:,.4f}\".format\n",
    "from datetime import time, timedelta, datetime\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "# Maths & Stats\n",
    "import math \n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import statsmodels.stats.weightstats as ws\n",
    "from statsmodels.stats.proportion import test_proportions_2indep\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "# from ambrosia.designer import Designer\n",
    "# from ambrosia.tester import Tester\n",
    "import expab\n",
    "from sklearn.linear_model import Ridge\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import AB_library\n",
    "# from ambrosia.designer import Designer\n",
    "# from ambrosia.tester import Tester\n",
    "from statsmodels.stats.power import NormalIndPower\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "# System library\n",
    "import os\n",
    "import ipywidgets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# from itables import init_notebook_mode\n",
    "# init_notebook_mode(all_interactive=True)\n",
    "import openpyxl\n",
    "\n",
    "# Data connection\n",
    "from google.cloud import bigquery\n",
    "bigquery_client = bigquery.Client(project='analytics-dev-333113')\n",
    "\n",
    "\n",
    "# Useful functions\n",
    "def read_bq(query, project='analytics-dev-333113'):\n",
    "    client = bigquery.Client(project=project)\n",
    "    query_job = client.query(query)\n",
    "    result_df = query_job.to_dataframe()\n",
    "    return result_df\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "\n",
    "    html_str = ''\n",
    "    for df in args:\n",
    "        html_str += df.to_html()\n",
    "    display_html(\n",
    "        html_str.replace('table','table style=\"display:inline\"'), \n",
    "        raw=True\n",
    "    )\n",
    "\n",
    "def cycle_sql(start, end, query, weeks=False):\n",
    "    \"\"\"\n",
    "    You have to use {date} in your script to add cycle date into this backets\n",
    "    \"\"\"\n",
    "    date_start = datetime.strptime(start, '%Y-%m-%d')\n",
    "    date_end = datetime.strptime(end, '%Y-%m-%d')\n",
    "\n",
    "    if weeks == False:\n",
    "        daterange = [(date_start + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days)+1)]\n",
    "    else:\n",
    "        daterange = [(date_start + timedelta(weeks=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days//7)+1)] # weeks dividing days by 7\n",
    "\n",
    "    total_df = pd.DataFrame()\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for date in daterange:\n",
    "        counter+=1\n",
    "        print(f\"{counter}) Uploading - {date}:\", datetime.today().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        script = query.format(date = date)\n",
    "        df_cycle = bigquery_client.query(script).to_dataframe()\n",
    "        if df_cycle.empty == True:\n",
    "            print('Dataframe is empty')\n",
    "        total_df = pd.concat([df_cycle, total_df])\n",
    "    return total_df  \n",
    "\n",
    "def writing_excel(name:str, dataset1=None, dataset2=None, dataset3=None, dataset4=None):\n",
    "    with pd.ExcelWriter(f\"{name}.xlsx\") as writer:\n",
    "\n",
    "    # use to_excel function and specify the sheet_name and index \n",
    "    # to store the dataframe in specified sheet\n",
    "\n",
    "        if dataset1 is not None:\n",
    "            if dataset2 is not None:\n",
    "                if dataset3 is not None:\n",
    "                    if dataset4 is not None:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset4.to_excel(writer, sheet_name=f\"4-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                    else:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                else:\n",
    "                    dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "                    dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "            else:\n",
    "                dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                #   index=False\n",
    "                                    )\n",
    "\n",
    "        print('DataFrame is written to Excel File successfully.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716dac9e",
   "metadata": {},
   "source": [
    "# Design\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31429a7",
   "metadata": {},
   "source": [
    "### Choosing the cities and comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385b983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>os_name</th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_id</th>\n",
       "      <th>country_name</th>\n",
       "      <th>filled_flow</th>\n",
       "      <th>show_dt</th>\n",
       "      <th>click_dt</th>\n",
       "      <th>approve_dt</th>\n",
       "      <th>not_approve_dt</th>\n",
       "      <th>is_approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11705385</td>\n",
       "      <td>android</td>\n",
       "      <td>4200</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>2025-06-01 15:39:45.468000+00:00</td>\n",
       "      <td>2025-06-01 15:40:29.446000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31334343</td>\n",
       "      <td>android</td>\n",
       "      <td>4267</td>\n",
       "      <td>Arica</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>2025-06-08 12:52:06.709000+00:00</td>\n",
       "      <td>2025-06-08 12:52:39.417000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41682015</td>\n",
       "      <td>android</td>\n",
       "      <td>4200</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>2025-08-11 09:11:07.273000+00:00</td>\n",
       "      <td>2025-08-11 09:11:59.986000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61387071</td>\n",
       "      <td>android</td>\n",
       "      <td>4267</td>\n",
       "      <td>Arica</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>2025-08-24 12:13:50.675000+00:00</td>\n",
       "      <td>2025-08-24 12:16:05.059000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79273867</td>\n",
       "      <td>android</td>\n",
       "      <td>4200</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>2025-06-13 02:12:15.396000+00:00</td>\n",
       "      <td>2025-06-13 02:13:16.640000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  os_name  city_id city_name  country_id country_name filled_flow    show_dt                         click_dt                       approve_dt not_approve_dt  is_approved\n",
       "0  11705385  android     4200  Santiago          25        Chile    liveness 2025-06-01 2025-06-01 15:39:45.468000+00:00 2025-06-01 15:40:29.446000+00:00            NaT            1\n",
       "1  31334343  android     4267     Arica          25        Chile    liveness 2025-06-08 2025-06-08 12:52:06.709000+00:00 2025-06-08 12:52:39.417000+00:00            NaT            1\n",
       "2  41682015  android     4200  Santiago          25        Chile    liveness 2025-08-11 2025-08-11 09:11:07.273000+00:00 2025-08-11 09:11:59.986000+00:00            NaT            1\n",
       "3  61387071  android     4267     Arica          25        Chile    liveness 2025-08-24 2025-08-24 12:13:50.675000+00:00 2025-08-24 12:16:05.059000+00:00            NaT            1\n",
       "4  79273867  android     4200  Santiago          25        Chile    liveness 2025-06-13 2025-06-13 02:12:15.396000+00:00 2025-06-13 02:13:16.640000+00:00            NaT            1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_metric = read_bq(\"\"\"\n",
    "SELECT user_id,\n",
    "       os_name,\n",
    "       city_id,\n",
    "       city_name,\n",
    "       country_id,\n",
    "       country_name,\n",
    "       COALESCE(filled_flow, 'liveness')                                  AS filled_flow,\n",
    "       COALESCE(MAX(IF(name = 'client.verification_start.show', client_time, NULL)),\n",
    "                MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                        LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                        LOWER(status) != 'approve'), client_time, NULL))) AS show_dt,\n",
    "       COALESCE(MAX(IF(name = 'client.verification_start.click', client_time, NULL)),\n",
    "                MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                        LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                        LOWER(status) != 'approve'), client_time, NULL))) AS click_dt,\n",
    "       MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "               LOWER(status) = 'approve'), client_time, NULL))            AS approve_dt,\n",
    "       MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "               LOWER(status) != 'approve'), client_time, NULL))           AS not_approve_dt\n",
    "FROM (SELECT t1.user_id,\n",
    "             t1.name,\n",
    "             t1.os_name,\n",
    "             DATE(TIMESTAMP_MILLIS(t1.client_time))                  AS event_dt_part,\n",
    "             TIMESTAMP_MILLIS(t1.client_time)                        AS client_time,\n",
    "             t1.city_id,\n",
    "             t2.city_name,\n",
    "             t2.country_id,\n",
    "             t2.country_name,\n",
    "             JSON_EXTRACT_SCALAR(payload, '$.verification_flow')     AS verification_flow,\n",
    "             IF(JSON_EXTRACT_SCALAR(payload, '$.verification_flow') IS NULL,\n",
    "                LAG(JSON_EXTRACT_SCALAR(payload, '$.verification_flow'))\n",
    "                    OVER (PARTITION BY t1.user_id ORDER BY client_time),\n",
    "                JSON_EXTRACT_SCALAR(payload, '$.verification_flow')) AS filled_flow,\n",
    "             JSON_EXTRACT_SCALAR(payload, '$.status')                AS status\n",
    "      FROM (SELECT *\n",
    "            FROM indriver-e6e40.emart.product_event t1\n",
    "            WHERE 1 = 1\n",
    "              AND name IN (\n",
    "                           'client.verification_start.show',\n",
    "                           'client.verification_start.click',\n",
    "                           'client.verification_flow_result_status.show'\n",
    "                )\n",
    "              AND event_dt_part BETWEEN '2025-06-01' AND CURRENT_DATE()\n",
    "              AND city_id IN (4200, 4267, 5596)\n",
    "            QUALIFY\n",
    "                ROW_NUMBER() OVER (PARTITION BY user_id, name, os_name, event_dt_part, JSON_EXTRACT_SCALAR(payload, '$.verification_flow') ORDER BY client_time DESC) =\n",
    "                1) t1\n",
    "               JOIN indriver-e6e40.heap.vw_macroregion_mapping t2\n",
    "                    ON\n",
    "                        t1.city_id = t2.city_id\n",
    "      WHERE 1 = 1\n",
    "        AND name IN (\n",
    "                     'client.verification_start.show', 'client.verification_start.click',\n",
    "                     'client.verification_flow_result_status.show'\n",
    "          ))\n",
    "GROUP BY 1, 2, 3, 4, 5, 6, 7\n",
    "\"\"\")\n",
    "\n",
    "df_metric['show_dt'] = pd.to_datetime(df_metric['show_dt'], errors='coerce')\n",
    "df_metric['show_dt'] = df_metric['show_dt'].dt.date\n",
    "df_metric['show_dt'] = pd.to_datetime(df_metric['show_dt'], errors='coerce')\n",
    "df_metric['is_approved'] = df_metric['approve_dt'].notna().astype(int)\n",
    "\n",
    "df_metric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c3944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Errors (α, β)</th>\n",
       "      <th>N_Total</th>\n",
       "      <th>Allocation_Ratio</th>\n",
       "      <th>Group sizes</th>\n",
       "      <th>MDE_Absolute</th>\n",
       "      <th>MDE_Relative_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.01; 0.2)</td>\n",
       "      <td>362</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 325; Test: 37</td>\n",
       "      <td>0.2002</td>\n",
       "      <td>26.7569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.05; 0.2)</td>\n",
       "      <td>362</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 325; Test: 37</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>23.2608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.01; 0.2)</td>\n",
       "      <td>2534</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 2280; Test: 254</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>12.1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.05; 0.2)</td>\n",
       "      <td>2534</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 2280; Test: 254</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>10.1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.01; 0.2)</td>\n",
       "      <td>5068</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 4561; Test: 507</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>8.8186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.05; 0.2)</td>\n",
       "      <td>5068</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 4561; Test: 507</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>7.3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.01; 0.2)</td>\n",
       "      <td>10860</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 9774; Test: 1086</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>6.1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.05; 0.2)</td>\n",
       "      <td>10860</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 9774; Test: 1086</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>5.0588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Errors (α, β)  N_Total Allocation_Ratio                Group sizes  MDE_Absolute  MDE_Relative_Percentage\n",
       "0   (0.01; 0.2)      362       (0.9, 0.1)     Control: 325; Test: 37        0.2002                  26.7569\n",
       "1   (0.05; 0.2)      362       (0.9, 0.1)     Control: 325; Test: 37        0.1740                  23.2608\n",
       "2   (0.01; 0.2)     2534       (0.9, 0.1)   Control: 2280; Test: 254        0.0910                  12.1595\n",
       "3   (0.05; 0.2)     2534       (0.9, 0.1)   Control: 2280; Test: 254        0.0757                  10.1220\n",
       "4   (0.01; 0.2)     5068       (0.9, 0.1)   Control: 4561; Test: 507        0.0660                   8.8186\n",
       "5   (0.05; 0.2)     5068       (0.9, 0.1)   Control: 4561; Test: 507        0.0546                   7.3024\n",
       "6   (0.01; 0.2)    10860       (0.9, 0.1)  Control: 9774; Test: 1086        0.0459                   6.1312\n",
       "7   (0.05; 0.2)    10860       (0.9, 0.1)  Control: 9774; Test: 1086        0.0378                   5.0588"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "daily = df_metric.groupby(['show_dt'], as_index=False)['user_id'].count()['user_id'].mean().round(0)*0.5\n",
    "\n",
    "effects = [1.01, 1.015, 1.05, 1.1]  # MDE in percents\n",
    "sizes = [int(daily), int(daily*7), int(daily*14), int(daily*30)]  # Size of each group\n",
    "first_type_errors = [0.01, 0.05]\n",
    "second_type_errors = [0.1, 0.2]\n",
    "\n",
    "\n",
    "def calculate_mde_unequal_split(\n",
    "    baseline_conversion_rate: float,\n",
    "    alpha: float = 0.05,\n",
    "    power: float = 0.8,\n",
    "    n_total: int = None,\n",
    "    allocation_ratio: tuple = (0.5, 0.5) # Соотношение (контроль, тест), например (0.7, 0.3)\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Рассчитывает MDE (минимально обнаруживаемый эффект) для A/B-теста\n",
    "    с неравномерным распределением групп.\n",
    "\n",
    "    Args:\n",
    "        baseline_conversion_rate (float): Базовая конверсия контрольной группы (от 0 до 1).\n",
    "        alpha (float): Уровень значимости (ошибка I рода), по умолчанию 0.05.\n",
    "        power (float): Статистическая мощность (1 - ошибка II рода), по умолчанию 0.8.\n",
    "        n_total (int): Общий размер выборки для обеих групп.\n",
    "                       Если не указан, функция вернет ошибку, так как MDE зависит от размера выборки.\n",
    "        allocation_ratio (tuple): Кортеж, представляющий соотношение распределения\n",
    "                                  (доля контрольной группы, доля тестовой группы).\n",
    "                                  Сумма долей должна быть равна 1.0.\n",
    "                                  По умолчанию (0.5, 0.5) - равномерное распределение.\n",
    "\n",
    "    Returns:\n",
    "        dict: Словарь, содержащий рассчитанный MDE (абсолютный и относительный),\n",
    "              а также размеры групп и другие параметры.\n",
    "              Возвращает None, если n_total не указан.\n",
    "    \"\"\"\n",
    "    if n_total is None:\n",
    "        return {\"error\": \"Для расчета MDE необходимо указать общий размер выборки (n_total).\"}\n",
    "\n",
    "    if not (0 < baseline_conversion_rate < 1):\n",
    "        raise ValueError(\"Базовая конверсия должна быть между 0 и 1.\")\n",
    "    if not (0 < alpha < 1):\n",
    "        raise ValueError(\"Уровень значимости (альфа) должен быть между 0 и 1.\")\n",
    "    if not (0 < power < 1):\n",
    "        raise ValueError(\"Мощность должна быть между 0 и 1.\")\n",
    "    if not (np.isclose(sum(allocation_ratio), 1.0) and all(r > 0 for r in allocation_ratio)):\n",
    "        raise ValueError(\"Соотношение распределения должно быть кортежем положительных чисел, сумма которых равна 1.0.\")\n",
    "\n",
    "    # Разделяем общий размер выборки согласно соотношению\n",
    "    n_control = ceil(n_total * allocation_ratio[0])\n",
    "    n_variant = ceil(n_total * allocation_ratio[1])\n",
    "\n",
    "    # Убедимся, что n_control + n_variant не превышает n_total (из-за округления ceil)\n",
    "    # и корректируем, если это так\n",
    "    if n_control + n_variant > n_total:\n",
    "        if allocation_ratio[0] > allocation_ratio[1]:\n",
    "            n_control = n_total - n_variant\n",
    "        else:\n",
    "            n_variant = n_total - n_control\n",
    "    \n",
    "    # Если одна из групп слишком мала после округления, убедимся, что она не 0\n",
    "    if n_control == 0:\n",
    "        n_control = 1\n",
    "        n_variant = n_total - 1\n",
    "    if n_variant == 0:\n",
    "        n_variant = 1\n",
    "        n_control = n_total - 1\n",
    "    \n",
    "    # Рассчитываем отношение размеров групп для NormalIndPower\n",
    "    # NormalIndPower ожидает nobs1 (размер первой группы) и ratio (nobs2 / nobs1)\n",
    "    # Мы используем n_control как nobs1, а n_variant как nobs2\n",
    "    ratio_nobs = n_variant / n_control if n_control > 0 else 1 # Избегаем деления на ноль\n",
    "\n",
    "    # Создаем объект для расчета мощности\n",
    "    power_calculator = NormalIndPower()\n",
    "\n",
    "    # Находим размер эффекта (Cohen's h)\n",
    "    # solve_power возвращает effect_size, если остальные параметры заданы\n",
    "    effect_size_cohen_h = power_calculator.solve_power(\n",
    "        effect_size=None,\n",
    "        nobs1=n_control,\n",
    "        alpha=alpha,\n",
    "        power=power,\n",
    "        ratio=ratio_nobs,\n",
    "        alternative='two-sided' # Двусторонний тест (обнаруживаем как увеличение, так и уменьшение)\n",
    "    )\n",
    "\n",
    "    # Преобразуем Cohen's h обратно в конверсию тестовой группы\n",
    "    # effect_size = 2 * arcsin(sqrt(p2)) - 2 * arcsin(sqrt(p1))\n",
    "    # Мы знаем p1 (baseline_conversion_rate) и effect_size_cohen_h\n",
    "    # Нужно найти p2\n",
    "    arcsin_sqrt_p1 = np.arcsin(np.sqrt(baseline_conversion_rate))\n",
    "    arcsin_sqrt_p2 = arcsin_sqrt_p1 + (effect_size_cohen_h / 2) # Для увеличения\n",
    "    \n",
    "    # Конверсия не может быть больше 1\n",
    "    detectable_conversion_rate_variant = np.sin(arcsin_sqrt_p2)**2\n",
    "    if detectable_conversion_rate_variant > 1:\n",
    "        detectable_conversion_rate_variant = 1.0\n",
    "\n",
    "    # MDE (абсолютная разница)\n",
    "    mde_absolute = detectable_conversion_rate_variant - baseline_conversion_rate\n",
    "\n",
    "    # MDE (относительная разница, в процентах)\n",
    "    mde_relative_percentage = (mde_absolute / baseline_conversion_rate) * 100 if baseline_conversion_rate != 0 else float('inf')\n",
    "\n",
    "    return {\n",
    "        \"baseline_conversion_rate\": baseline_conversion_rate,\n",
    "        \"alpha\": alpha,\n",
    "        \"power\": power,\n",
    "        \"n_total\": n_total,\n",
    "        \"n_control\": int(n_control),\n",
    "        \"n_variant\": int(n_variant),\n",
    "        \"allocation_ratio\": allocation_ratio,\n",
    "        \"effect_size_cohen_h\": effect_size_cohen_h,\n",
    "        \"detectable_conversion_rate_variant\": detectable_conversion_rate_variant,\n",
    "        \"mde_absolute\": mde_absolute,\n",
    "        \"mde_relative_percentage\": mde_relative_percentage\n",
    "    }\n",
    "\n",
    "def analyze_mde_scenarios(\n",
    "    baseline_conversion_rate: float,\n",
    "    alpha_levels: list[float],\n",
    "    power_levels: list[float],\n",
    "    n_total_levels: list[int],\n",
    "    allocation_ratio: tuple = (0.5, 0.5)\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Анализирует MDE для различных сценариев, возвращая результаты в DataFrame.\n",
    "\n",
    "    Args:\n",
    "        baseline_conversion_rate (float): Базовая конверсия контрольной группы (от 0 до 1).\n",
    "        alpha_levels (list[float]): Список уровней значимости (альфа) для тестирования.\n",
    "        power_levels (list[float]): Список уровней статистической мощности для тестирования.\n",
    "        n_total_levels (list[int]): Список общих размеров выборок для тестирования.\n",
    "        allocation_ratio (tuple): Кортеж, представляющий соотношение распределения\n",
    "                                  (доля контрольной группы, доля тестовой группы).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame, содержащий MDE и размеры групп для каждого сценария.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for n_total in n_total_levels:\n",
    "        for alpha in alpha_levels:\n",
    "            for power in power_levels:\n",
    "                beta = 1 - power # Ошибка второго рода\n",
    "                \n",
    "                mde_result = calculate_mde_unequal_split(\n",
    "                    baseline_conversion_rate=baseline_conversion_rate,\n",
    "                    alpha=alpha,\n",
    "                    power=power,\n",
    "                    n_total=n_total,\n",
    "                    allocation_ratio=allocation_ratio\n",
    "                )\n",
    "                \n",
    "                if \"error\" not in mde_result:\n",
    "                    results.append({\n",
    "                        \"Alpha\": alpha,\n",
    "                        \"Beta\": beta,\n",
    "                        \"N_Total\": n_total,\n",
    "                        \"Allocation_Ratio\": allocation_ratio,\n",
    "                        \"N_Control\": mde_result[\"n_control\"],\n",
    "                        \"N_Variant\": mde_result[\"n_variant\"],\n",
    "                        \"MDE_Absolute\": mde_result[\"mde_absolute\"],\n",
    "                        \"MDE_Relative_Percentage\": mde_result[\"mde_relative_percentage\"]\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"Ошибка для N_Total={n_total}, Alpha={alpha}, Power={power}: {mde_result['error']}\")\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Добавляем столбец с форматированной строкой для ошибок\n",
    "    df_results['Errors (α, β)'] = df_results.apply(\n",
    "        lambda row: f\"({row['Alpha']}; {row['Beta']:.1f})\", axis=1\n",
    "    )\n",
    "    \n",
    "    # Добавляем столбец с форматированной строкой для размеров групп\n",
    "    df_results['Group sizes'] = df_results.apply(\n",
    "        lambda row: f\"Control: {row['N_Control']}; Test: {row['N_Variant']}\", axis=1\n",
    "    )\n",
    "\n",
    "    # Переупорядочиваем столбцы для соответствия запрошенному формату\n",
    "    # 'Metric' не является прямым столбцом, это скорее категория.\n",
    "    # Я представлю MDE_Absolute и MDE_Relative_Percentage как отдельные столбцы.\n",
    "    final_columns = [\n",
    "        \"Errors (α, β)\",\n",
    "        \"N_Total\",\n",
    "        \"Allocation_Ratio\",\n",
    "        \"Group sizes\",\n",
    "        \"MDE_Absolute\",\n",
    "        \"MDE_Relative_Percentage\"\n",
    "    ]\n",
    "    \n",
    "    return df_results[final_columns]\n",
    "\n",
    "baseline_cr = df_metric['is_approved'].mean()\n",
    "alpha_levels_to_test = [0.01, 0.05]\n",
    "power_levels_to_test = [0.8] \n",
    "n_total_levels_to_test = [int(daily), int(daily*7), int(daily*14), int(daily*30)]\n",
    "allocation_ratio_to_test = (0.9, 0.1) \n",
    "\n",
    "mde_analysis_df = analyze_mde_scenarios(\n",
    "    baseline_conversion_rate=baseline_cr,\n",
    "    alpha_levels=alpha_levels_to_test,\n",
    "    power_levels=power_levels_to_test,\n",
    "    n_total_levels=n_total_levels_to_test,\n",
    "    allocation_ratio=allocation_ratio_to_test\n",
    ")\n",
    "\n",
    "mde_analysis_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f27b9fa",
   "metadata": {},
   "source": [
    "# Summarising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127f6d2",
   "metadata": {},
   "source": [
    "### Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be557aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>participant_first_toggle_date</th>\n",
       "      <th>os_name</th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_id</th>\n",
       "      <th>country_name</th>\n",
       "      <th>newbie_flag</th>\n",
       "      <th>filled_flow</th>\n",
       "      <th>show_dt</th>\n",
       "      <th>click_dt</th>\n",
       "      <th>approve_dt</th>\n",
       "      <th>approve_flag</th>\n",
       "      <th>not_approve_dt</th>\n",
       "      <th>not_approve_flag</th>\n",
       "      <th>order_timestamp</th>\n",
       "      <th>order_flag</th>\n",
       "      <th>gmv</th>\n",
       "      <th>rides</th>\n",
       "      <th>orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13102195</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>android</td>\n",
       "      <td>4269</td>\n",
       "      <td>Puerto Montt</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-10-01 20:41:30.703000+00:00</td>\n",
       "      <td>2025-10-01 20:41:36.397000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-10-01 20:42:24.407000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117885317</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>android</td>\n",
       "      <td>4269</td>\n",
       "      <td>Puerto Montt</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>1</td>\n",
       "      <td>documents</td>\n",
       "      <td>2025-09-30 00:31:44.470000+00:00</td>\n",
       "      <td>2025-09-30 00:31:48.236000+00:00</td>\n",
       "      <td>2025-09-30 00:34:08.350000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118906827</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>android</td>\n",
       "      <td>4269</td>\n",
       "      <td>Puerto Montt</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-10-01 11:09:34.293000+00:00</td>\n",
       "      <td>2025-10-01 11:09:34.890000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-10-02 19:29:42.065000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>47.4063</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49874414</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>android</td>\n",
       "      <td>4269</td>\n",
       "      <td>Puerto Montt</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>1</td>\n",
       "      <td>documents</td>\n",
       "      <td>2025-09-30 16:34:42.522000+00:00</td>\n",
       "      <td>2025-09-30 16:34:51.189000+00:00</td>\n",
       "      <td>2025-09-30 16:35:30.028000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83012040</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>android</td>\n",
       "      <td>4269</td>\n",
       "      <td>Puerto Montt</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>1</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-10-02 16:59:40.809000+00:00</td>\n",
       "      <td>2025-10-02 16:59:46.580000+00:00</td>\n",
       "      <td>2025-10-02 17:00:20.078000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-10-02 17:00:51+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  group_id participant_first_toggle_date  os_name  city_id     city_name  country_id country_name  newbie_flag filled_flow                          show_dt                         click_dt                       approve_dt  approve_flag                   not_approve_dt  not_approve_flag           order_timestamp  order_flag     gmv  rides  orders\n",
       "0   13102195         1                    2025-10-01  android     4269  Puerto Montt          25        Chile            0    liveness 2025-10-01 20:41:30.703000+00:00 2025-10-01 20:41:36.397000+00:00                              NaT             0 2025-10-01 20:42:24.407000+00:00                 1                       NaT           0     NaN   <NA>    <NA>\n",
       "1  117885317         1                    2025-09-30  android     4269  Puerto Montt          25        Chile            1   documents 2025-09-30 00:31:44.470000+00:00 2025-09-30 00:31:48.236000+00:00 2025-09-30 00:34:08.350000+00:00             1                              NaT                 0                       NaT           0  0.0000      0       2\n",
       "2  118906827         1                    2025-09-30  android     4269  Puerto Montt          25        Chile            0    liveness 2025-10-01 11:09:34.293000+00:00 2025-10-01 11:09:34.890000+00:00                              NaT             0 2025-10-02 19:29:42.065000+00:00                 1                       NaT           0 47.4063     17      33\n",
       "3   49874414         1                    2025-09-30  android     4269  Puerto Montt          25        Chile            1   documents 2025-09-30 16:34:42.522000+00:00 2025-09-30 16:34:51.189000+00:00 2025-09-30 16:35:30.028000+00:00             1                              NaT                 0                       NaT           0  0.0000      0       4\n",
       "4   83012040         0                    2025-10-01  android     4269  Puerto Montt          25        Chile            1    liveness 2025-10-02 16:59:40.809000+00:00 2025-10-02 16:59:46.580000+00:00 2025-10-02 17:00:20.078000+00:00             1                              NaT                 0 2025-10-02 17:00:51+00:00           1     NaN   <NA>    <NA>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_bq(\"\"\"\n",
    "WITH newbies AS (SELECT user_id,\n",
    "                        metric_date\n",
    "                 FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "                 WHERE user_type = 'pass'\n",
    "                   AND rides_count > 0\n",
    "                   AND metric_date >= DATE_ADD(CURRENT_DATE(), INTERVAL -1 YEAR)\n",
    "                   AND country_id = 25),\n",
    "     gmv AS (SELECT user_id,\n",
    "                    SUM(gmv_clean_usd) AS gmv,\n",
    "                    SUM(rides_count)   AS rides,\n",
    "                    SUM(orders_count)  AS orders\n",
    "             FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "             WHERE user_type = 'pass'\n",
    "               AND metric_date BETWEEN '2025-06-01' AND CURRENT_DATE()\n",
    "               AND country_id = 25\n",
    "             GROUP BY 1),\n",
    "     total AS (SELECT t1.user_id,\n",
    "                      t1.city_id,\n",
    "                      geo.city_name,\n",
    "                      geo.country_id,\n",
    "                      geo.country_name,\n",
    "                      IF(group_id = 4552160, 0, 1) AS group_id,\n",
    "                      participant_first_toggle_date,\n",
    "                      t2.metric_date,\n",
    "                      CASE\n",
    "                          WHEN t2.metric_date IS NULL THEN 1\n",
    "                          ELSE 0\n",
    "                          END                         newbie_flag\n",
    "               FROM indrive-core.ab_platform.tbl_ab_experiment_markup t1\n",
    "                        JOIN indriver-e6e40.heap.vw_macroregion_mapping geo\n",
    "                             ON\n",
    "                                 t1.city_id = geo.city_id\n",
    "                        LEFT JOIN newbies t2\n",
    "                                  ON t1.user_id = t2.user_id AND t2.metric_date < t1.participant_first_toggle_date\n",
    "               WHERE experiment_id = 4298\n",
    "               QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY metric_date DESC) = 1),\n",
    "     liveness AS (SELECT user_id,\n",
    "                         os_name,\n",
    "                         city_id,\n",
    "                         city_name,\n",
    "                         country_id,\n",
    "                         country_name,\n",
    "                         COALESCE(filled_flow, 'liveness')                                  AS filled_flow,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.show', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS show_dt,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.click', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS click_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) = 'approve'), client_time, NULL))            AS approve_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) != 'approve'), client_time, NULL))           AS not_approve_dt\n",
    "                  FROM (SELECT t1.user_id,\n",
    "                               t1.name,\n",
    "                               t1.os_name,\n",
    "                               DATE(TIMESTAMP_MILLIS(t1.client_time))                  AS event_dt_part,\n",
    "                               TIMESTAMP_MILLIS(t1.client_time)                        AS client_time,\n",
    "                               t1.city_id,\n",
    "                               t2.city_name,\n",
    "                               t2.country_id,\n",
    "                               t2.country_name,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.verification_flow')     AS verification_flow,\n",
    "                               IF(JSON_EXTRACT_SCALAR(payload, '$.verification_flow') IS NULL,\n",
    "                                  LAG(JSON_EXTRACT_SCALAR(payload, '$.verification_flow'))\n",
    "                                      OVER (PARTITION BY t1.user_id ORDER BY client_time),\n",
    "                                  JSON_EXTRACT_SCALAR(payload, '$.verification_flow')) AS filled_flow,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.status')                AS status\n",
    "                        FROM (SELECT *\n",
    "                              FROM indriver-e6e40.emart.product_event t1\n",
    "                              WHERE 1 = 1\n",
    "                                AND name IN (\n",
    "                                             'client.verification_start.show',\n",
    "                                             'client.verification_start.click',\n",
    "                                             'client.verification_flow_result_status.show'\n",
    "                                  )\n",
    "                                AND event_dt_part BETWEEN '2025-06-01' AND CURRENT_DATE()\n",
    "                                AND country_id IN (25)\n",
    "                              QUALIFY\n",
    "                                  ROW_NUMBER() OVER (PARTITION BY user_id, name, os_name, event_dt_part, JSON_EXTRACT_SCALAR(payload, '$.verification_flow') ORDER BY client_time DESC) =\n",
    "                                  1) t1\n",
    "                                 JOIN indriver-e6e40.heap.vw_macroregion_mapping t2\n",
    "                                      ON\n",
    "                                          t1.city_id = t2.city_id\n",
    "                        WHERE 1 = 1\n",
    "                          AND name IN (\n",
    "                                       'client.verification_start.show', 'client.verification_start.click',\n",
    "                                       'client.verification_flow_result_status.show'\n",
    "                            ))\n",
    "                  GROUP BY 1, 2, 3, 4, 5, 6, 7),\n",
    "     total_liv AS (SELECT t1.user_id,\n",
    "                          t1.city_id,\n",
    "                          t1.city_name,\n",
    "                          t1.country_id,\n",
    "                          t1.country_name,\n",
    "                          t1.group_id,\n",
    "                          t1.participant_first_toggle_date,\n",
    "                          t1.newbie_flag,\n",
    "                          t2.user_id AS user_with_svf,\n",
    "                          t2.os_name,\n",
    "                          t2.filled_flow,\n",
    "                          t2.show_dt,\n",
    "                          t2.click_dt,\n",
    "                          t2.approve_dt,\n",
    "                          t2.not_approve_dt\n",
    "                   FROM total t1\n",
    "                            JOIN liveness t2\n",
    "                                 ON t1.user_id = t2.user_id AND DATE(t2.show_dt) >= t1.participant_first_toggle_date),\n",
    "     rides AS (SELECT order_uuid,\n",
    "                      user_id    AS pass_id,\n",
    "                      driver_id,\n",
    "                      city_id    AS order_city_id,\n",
    "                      country_id AS order_country_id,\n",
    "                      status_order,\n",
    "                      order_timestamp,\n",
    "                      at_pickup_dttm,\n",
    "                      departed_pickup_dttm,\n",
    "                      at_destination_dttm,\n",
    "                      departed_destination_dttm,\n",
    "                      driveraccept_timestamp,\n",
    "                      driverarrived_timestamp,\n",
    "                      driverstarttheride_timestamp,\n",
    "                      driverdone_timestamp,\n",
    "                      clientdone_timestamp,\n",
    "                      clientcancel_timestamp,\n",
    "                      drivercancel_timestamp,\n",
    "                      user_reg_date,\n",
    "                      driver_reg_date,\n",
    "                      stage,\n",
    "                      created_date_order_part,\n",
    "                      duration_in_seconds\n",
    "               FROM indriver-e6e40.imart.incity_detail_new_order\n",
    "               WHERE created_date_order_part BETWEEN '2025-06-01'\n",
    "                   AND CURRENT_DATE()\n",
    "                 AND status_order = 'RIDE_STATUS_DONE'\n",
    "                 AND driveraccept_timestamp IS NOT NULL\n",
    "                 AND (clientcancel_timestamp IS NULL\n",
    "                   AND drivercancel_timestamp IS NULL))\n",
    "SELECT t1.user_id,\n",
    "       t1.group_id,\n",
    "       t1.participant_first_toggle_date,\n",
    "       t1.os_name,\n",
    "       t1.city_id,\n",
    "       t1.city_name,\n",
    "       t1.country_id,\n",
    "       t1.country_name,\n",
    "       t1.newbie_flag,\n",
    "       filled_flow,\n",
    "       show_dt,\n",
    "       click_dt,\n",
    "       approve_dt                                                  AS approve_dt,\n",
    "       IF(approve_dt IS NOT NULL, 1, 0)                            AS approve_flag,\n",
    "       not_approve_dt,\n",
    "       IF(not_approve_dt IS NOT NULL AND approve_dt IS NULL, 1, 0) AS not_approve_flag,\n",
    "       t2.order_timestamp,\n",
    "       IF(t2.order_timestamp IS NOT NULL, 1, 0)                    AS order_flag,\n",
    "       t3.gmv,\n",
    "       t3.rides,\n",
    "       t3.orders\n",
    "FROM total_liv t1\n",
    "         LEFT JOIN rides t2\n",
    "                   ON t1.user_id = t2.pass_id AND\n",
    "                      t2.created_date_order_part >= participant_first_toggle_date\n",
    "         LEFT JOIN gmv t3 ON t1.user_id = t3.user_id\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY t2.order_timestamp) = 1\n",
    "\"\"\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713548f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>newbie_flag</th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_dt</th>\n",
       "      <th>approve_dt</th>\n",
       "      <th>not_approve_dt</th>\n",
       "      <th>order_flag</th>\n",
       "      <th>cr_to_approve</th>\n",
       "      <th>cr_to_ride</th>\n",
       "      <th>cr_to_ride_2</th>\n",
       "      <th>cr_to_not_approve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>142</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>62</td>\n",
       "      <td>55.0336</td>\n",
       "      <td>41.6107</td>\n",
       "      <td>41.6107</td>\n",
       "      <td>12.7517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>142</td>\n",
       "      <td>81</td>\n",
       "      <td>19</td>\n",
       "      <td>59</td>\n",
       "      <td>55.4795</td>\n",
       "      <td>40.4110</td>\n",
       "      <td>40.4110</td>\n",
       "      <td>13.0137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_id  newbie_flag  user_id  click_dt  approve_dt  not_approve_dt  order_flag  cr_to_approve  cr_to_ride  cr_to_ride_2  cr_to_not_approve\n",
       "0         0            1      149       142          82              19          62        55.0336     41.6107       41.6107            12.7517\n",
       "1         1            1      146       142          81              19          59        55.4795     40.4110       40.4110            13.0137"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_grouped = df[(df['newbie_flag']==1)&(~df['show_dt'].isna())].groupby(['group_id', 'newbie_flag'], as_index=False)[['user_id', 'click_dt', 'approve_dt', 'not_approve_dt', 'order_flag']].agg({'user_id':'count', 'click_dt':'count', 'approve_dt':'count', 'not_approve_dt':'count', 'order_flag':'sum'})\n",
    "\n",
    "df_grouped['cr_to_approve'] = df_grouped['approve_dt'] / df_grouped['user_id'] * 100\n",
    "df_grouped['cr_to_ride'] = df_grouped['order_flag'] / df_grouped['user_id'] * 100\n",
    "df_grouped['cr_to_ride_2'] = df_grouped['order_flag'] / df_grouped['user_id'] * 100\n",
    "df_grouped['cr_to_not_approve'] = df_grouped['not_approve_dt'] / df_grouped['user_id'] * 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23c61f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
