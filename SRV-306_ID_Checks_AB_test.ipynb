{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434029ef",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02493ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisation\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Data analysis / Data processing\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "from datetime import time, timedelta, datetime\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "# Maths & Stats\n",
    "import math \n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import statsmodels.stats.weightstats as ws\n",
    "from statsmodels.stats.proportion import test_proportions_2indep\n",
    "import AB_library\n",
    "# from ambrosia.designer import Designer\n",
    "# from ambrosia.tester import Tester\n",
    "import expab\n",
    "from statsmodels.stats.power import NormalIndPower\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "from math import ceil\n",
    "\n",
    "# System library\n",
    "import os\n",
    "import ipywidgets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# from itables import init_notebook_mode\n",
    "# init_notebook_mode(all_interactive=True)\n",
    "import openpyxl\n",
    "\n",
    "# Data connection\n",
    "from google.cloud import bigquery\n",
    "bigquery_client = bigquery.Client(project='analytics-dev-333113')\n",
    "\n",
    "\n",
    "# Useful functions\n",
    "def read_bq(query, project='analytics-dev-333113'):\n",
    "    client = bigquery.Client(project=project)\n",
    "    query_job = client.query(query)\n",
    "    result_df = query_job.to_dataframe()\n",
    "    return result_df\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "\n",
    "    html_str = ''\n",
    "    for df in args:\n",
    "        html_str += df.to_html()\n",
    "    display_html(\n",
    "        html_str.replace('table','table style=\"display:inline\"'), \n",
    "        raw=True\n",
    "    )\n",
    "\n",
    "def cycle_sql(start, end, query, weeks=False):\n",
    "    \"\"\"\n",
    "    You have to use {date} in your script to add cycle date into this backets\n",
    "    \"\"\"\n",
    "    date_start = datetime.strptime(start, '%Y-%m-%d')\n",
    "    date_end = datetime.strptime(end, '%Y-%m-%d')\n",
    "\n",
    "    if weeks == False:\n",
    "        daterange = [(date_start + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days)+1)]\n",
    "    else:\n",
    "        daterange = [(date_start + timedelta(weeks=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days//7)+1)] # weeks dividing days by 7\n",
    "\n",
    "    total_df = pd.DataFrame()\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for date in daterange:\n",
    "        counter+=1\n",
    "        print(f\"{counter}) Uploading - {date}:\", datetime.today().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        script = query.format(date = date)\n",
    "        df_cycle = bigquery_client.query(script).to_dataframe()\n",
    "        if df_cycle.empty == True:\n",
    "            print('Dataframe is empty')\n",
    "        total_df = pd.concat([df_cycle, total_df])\n",
    "    return total_df  \n",
    "\n",
    "def writing_excel(name:str, dataset1=None, dataset2=None, dataset3=None, dataset4=None):\n",
    "    with pd.ExcelWriter(f\"{name}.xlsx\") as writer:\n",
    "\n",
    "    # use to_excel function and specify the sheet_name and index \n",
    "    # to store the dataframe in specified sheet\n",
    "\n",
    "        if dataset1 is not None:\n",
    "            if dataset2 is not None:\n",
    "                if dataset3 is not None:\n",
    "                    if dataset4 is not None:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset4.to_excel(writer, sheet_name=f\"4-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                    else:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                else:\n",
    "                    dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "                    dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "            else:\n",
    "                dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                #   index=False\n",
    "                                    )\n",
    "\n",
    "        print('DataFrame is written to Excel File successfully.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eded89",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e5cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_benjamini_hochberg(\n",
    "    pvalues: np.ndarray,\n",
    "    alpha: float = 0.05\n",
    "    ) -> np.ndarray:\n",
    "    \"\"\"Apply the Benjamini-Hochberg procedure for multiple hypothesis testing.\"\"\"\n",
    "    m = len(pvalues)\n",
    "    array_alpha = np.arange(1, m + 1) * alpha / m\n",
    "    sorted_pvalue_indexes = np.argsort(pvalues)\n",
    "    res = np.zeros(m)\n",
    "    for idx, pvalue_index in enumerate(sorted_pvalue_indexes):\n",
    "        pvalue = pvalues[pvalue_index]\n",
    "        alpha_ = array_alpha[idx]\n",
    "        if pvalue <= alpha_:\n",
    "            res[pvalue_index] = 1\n",
    "        else:\n",
    "            break\n",
    "    return res.astype(int)\n",
    "\n",
    "# Shapiro-Wilk test & Distributions\n",
    "def check_normality(df, group_column, value_column):\n",
    "    groups = df[group_column].unique()\n",
    "\n",
    "    for group in groups:\n",
    "        group_data = df[df[group_column] == group][value_column].dropna() \n",
    "        stat, p = stats.shapiro(group_data)\n",
    "        print(f'Group {group}: W={stat:.4f}, p-value={p:.4f}')\n",
    "        if p > 0.05:\n",
    "            print(f'Group {group}, Metric: {value_column}: Data is normal distributed')\n",
    "        else:\n",
    "            print(f'Group {group}, Metric: {value_column}: Data is not normal distributed')\n",
    "\n",
    "def plot_distribution(df, group_column, value_column):\n",
    "\n",
    "    groups = df[group_column].unique()\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10), gridspec_kw={'height_ratios': [1, 1.5]})\n",
    "\n",
    "    sns.histplot(data=df, x=value_column, hue=group_column, kde=True, bins=30, alpha=0.4, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title(\"Graph + KDE\")\n",
    "    axes[0, 0].set_xlabel(value_column)\n",
    "    axes[0, 0].set_ylabel(\"Frequence\")\n",
    "\n",
    "    sns.boxplot(data=df, x=group_column, y=value_column, ax=axes[0, 1])\n",
    "    axes[0, 1].set_title(\"Boxplot grouped\")\n",
    "    axes[0, 1].set_xlabel(group_column)\n",
    "    axes[0, 1].set_ylabel(value_column)\n",
    "\n",
    "    sns.histplot(df[df[group_column] == groups[0]][value_column], bins=30, kde=True, color='blue', alpha=0.5, ax=axes[1, 0])\n",
    "    axes[1, 0].set_title(f'Hist for the {groups[0]}')\n",
    "    axes[1, 0].set_xlabel(value_column)\n",
    "    axes[1, 0].set_ylabel(\"frequence\")\n",
    "\n",
    "    sns.histplot(df[df[group_column] == groups[1]][value_column], bins=30, kde=True, color='orange', alpha=0.5, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title(f'Hist for the {groups[1]}')\n",
    "    axes[1, 1].set_xlabel(value_column)\n",
    "    axes[1, 1].set_ylabel(\"Frequence\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Levene's & Bartlet's test\n",
    "def levene(df, indicator, metric):\n",
    "    w_stats, p_value = st.levene(\n",
    "        df[df['group_name'] == 0][indicator], \n",
    "        df[df['group_name'] == 1][indicator],\n",
    "                            center=metric)\n",
    "    \n",
    "    alpha = 0.05\n",
    "    \n",
    "    if p_value > alpha:\n",
    "        print(f\"Variance are from the same population on {metric}\")\n",
    "    else:\n",
    "        print(f\"Variance are from the different population on {metric}\")\n",
    "    \n",
    "# Cohen's D\n",
    "def cohens_d(df, metric):\n",
    "    group1 = df[df['group_name']==1][metric]\n",
    "    group2 = df[df['group_name']==0][metric]\n",
    "    mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "     \n",
    "    std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    pooled_std = np.sqrt(((n1 - 1) * std1 ** 2 + (n2 - 1) * std2 ** 2) / (n1 + n2 - 2))\n",
    "     \n",
    "    d = (mean1 - mean2) / pooled_std\n",
    "     \n",
    "    # if d <= 0.3:\n",
    "    #     print(f'Small effect: d ≈ 0-0.3 ({d:.3f})')\n",
    "    # elif 0.31 <= d <= 0.8:\n",
    "    #     print(f'Medium effect: d ≈ 0.3-0.8 ({d:.3f})')\n",
    "    # elif 0.81 <= d <= 1:\n",
    "    #     print(f'Large effect: d ≈ 0.8-1 ({d:.3f})')\n",
    "\n",
    "    return d\n",
    "\n",
    "# SRM\n",
    "def srm(df):\n",
    "    srm_df = pd.DataFrame()\n",
    "\n",
    "    for city in df['city_name'].unique():\n",
    "        \n",
    "        observed = [\n",
    "            (df.query(f'group_name == 0 and city_name == \"{city}\"')['user_id'].count()), \n",
    "            (df.query(f'group_name == 1 and city_name == \"{city}\"')['user_id'].count())\n",
    "            ]\n",
    "\n",
    "        total_traffic = sum(observed)\n",
    "\n",
    "        expected = [total_traffic/2, total_traffic/2]\n",
    "\n",
    "        chi = st.chisquare(observed, f_exp = expected)\n",
    "\n",
    "        if chi[1] < 0.01:\n",
    "            conclusion = \"Sample ratio mismatch (SRM) may be present\"\n",
    "        else:\n",
    "            conclusion = \"Sample ratio mismatch (SRM) probably not present\"\n",
    "            print(f\"{city}, {chi[1]}\")\n",
    "\n",
    "        \n",
    "        new_srm_df = pd.DataFrame(\n",
    "            [[city, observed, total_traffic, expected, round(chi[1], 3), conclusion]], \n",
    "            columns=['city_name',  'sample_sizes', 'total_size', 'expected_sizes', 'chi_value', 'conclusion']\n",
    "            )\n",
    "\n",
    "        srm_df = pd.concat([srm_df, new_srm_df]).sort_values(['city_name', 'total_size'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return srm_df\n",
    "\n",
    "# Calcualting the significance by cities\n",
    "def calcualate_result(df_cr, df_abs):\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    for city in df_cr['city_name'].unique():\n",
    "\n",
    "        absolute_values_keys_result = df_abs[df_abs['city_name']==f'{city}'].copy()\n",
    "\n",
    "        cr_df = ztest_proportion(df_cr[df_cr['city_name']==f'{city}'], 'has_ride', 'group_name')\n",
    "        cr_df['metric'] = 'Conversion'\n",
    "        cr_df['cohen_d'] = cohens_d(df_cr[df_cr['city_name']==f'{city}'], 'has_ride')\n",
    "\n",
    "        rides_df = ttest(absolute_values_keys_result, 'rides', 'group_name')\n",
    "        rides_df['metric'] = 'Quantitive'\n",
    "        rides_df['cohen_d'] = cohens_d(absolute_values_keys_result, 'rides')\n",
    "\n",
    "        gmv_df = ttest(absolute_values_keys_result, 'gmv', 'group_name')\n",
    "        gmv_df['metric'] = 'Quantitive'\n",
    "        gmv_df['cohen_d'] = cohens_d(absolute_values_keys_result, 'gmv')\n",
    "\n",
    "        orders_df = ttest(absolute_values_keys_result, 'orders', 'group_name')\n",
    "        orders_df['metric'] = 'Quantitive'\n",
    "        orders_df['cohen_d'] = cohens_d(absolute_values_keys_result, 'orders')\n",
    "\n",
    "        df_total = pd.concat([cr_df, rides_df, gmv_df, orders_df])\n",
    "\n",
    "        df_total['region'] = city\n",
    "        df_total['segment'] = 'By city'\n",
    "        df_total['significance'] = (df_total['pvalue']<0.05)*1\n",
    "        df_total['corrected_pvalue'] = method_benjamini_hochberg(df_total['pvalue'].values)\n",
    "\n",
    "        df_results = pd.concat([df_results, df_total])\n",
    "\n",
    "    total_cr_df = ztest_proportion(df_cr, 'has_ride', 'group_name')\n",
    "    total_cr_df['metric'] = 'Conversion'\n",
    "    total_cr_df['cohen_d'] = cohens_d(df_cr, 'has_ride')\n",
    "\n",
    "    total_rides_df = ttest(df_abs, 'rides', 'group_name')\n",
    "    total_rides_df['metric'] = 'Quantitive'\n",
    "    total_rides_df['cohen_d'] = cohens_d(df_abs, 'rides')\n",
    "\n",
    "    total_gmv_df = ttest(df_abs, 'gmv', 'group_name')\n",
    "    total_gmv_df['metric'] = 'Quantitive'\n",
    "    total_gmv_df['cohen_d'] = cohens_d(df_abs, 'gmv')\n",
    "\n",
    "    total_orders_df = ttest(df_abs, 'orders', 'group_name')\n",
    "    total_orders_df['metric'] = 'Quantitive'\n",
    "    total_orders_df['cohen_d'] = cohens_d(df_abs, 'orders')\n",
    "\n",
    "\n",
    "    total_total_df = pd.concat([total_cr_df, total_rides_df, total_gmv_df, total_orders_df])\n",
    "    total_total_df['region'] = 'All'\n",
    "    total_total_df['segment'] = 'Total'\n",
    "    total_total_df['significance'] = (df_total['pvalue']<0.05)*1\n",
    "    total_total_df['corrected_pvalue'] = method_benjamini_hochberg(df_total['pvalue'].values)\n",
    "\n",
    "    df_results = pd.concat([df_results, total_total_df])\n",
    "\n",
    "    df_results\n",
    "\n",
    "    return df_results\n",
    "\n",
    "def sequential_wald_test(df, date_col, metric_col, group_col, user_col, alpha=0.05, beta=0.2):\n",
    "    \n",
    "    A = np.round(np.log(beta / (1 - alpha)), 2)   \n",
    "    B = np.round(np.log((1 - beta) / alpha), 2) \n",
    "    \n",
    "    df_grouped = df.groupby([date_col, group_col]).agg(\n",
    "        users=(user_col, 'nunique'), \n",
    "        conversions=(metric_col, 'sum') \n",
    "    ).reset_index()\n",
    "\n",
    "    df_grouped[\"cum_users\"] = df_grouped.groupby(group_col)[\"users\"].cumsum()\n",
    "    df_grouped[\"cum_conversions\"] = df_grouped.groupby(group_col)[\"conversions\"].cumsum()\n",
    "\n",
    "    df_A = df_grouped[df_grouped[group_col] == 0].drop(columns=[group_col]).rename(\n",
    "        columns={\"users\": \"users_A\", \"conversions\": \"conv_A\", \"cum_users\": \"cum_users_A\", \"cum_conversions\": \"cum_conv_A\"}\n",
    "    )\n",
    "    df_B = df_grouped[df_grouped[group_col] == 1].drop(columns=[group_col]).rename(\n",
    "        columns={\"users\": \"users_B\", \"conversions\": \"conv_B\", \"cum_users\": \"cum_users_B\", \"cum_conversions\": \"cum_conv_B\"}\n",
    "    )\n",
    "\n",
    "    df_merged = pd.merge(df_A, df_B, on=date_col, how=\"outer\").fillna(0)\n",
    "\n",
    "    print(\"Колонки в df_merged:\", df_merged.columns)\n",
    "\n",
    "    p_values, llr_values = [], []\n",
    "    stop_day = None\n",
    "\n",
    "    for i in range(len(df_merged)):\n",
    "        try:\n",
    "            users_A, conv_A = df_merged.loc[i, [\"cum_users_A\", \"cum_conv_A\"]]\n",
    "            users_B, conv_B = df_merged.loc[i, [\"cum_users_B\", \"cum_conv_B\"]]\n",
    "\n",
    "            p_A = conv_A / users_A if users_A > 0 else 0\n",
    "            p_B = conv_B / users_B if users_B > 0 else 0\n",
    "\n",
    "            r = test_proportions_2indep(\n",
    "                conv_A, users_A,\n",
    "                conv_B, users_B,\n",
    "                value=0,\n",
    "                method='wald',\n",
    "                compare='diff',\n",
    "                alternative='two-sided',\n",
    "                return_results=True\n",
    "            )\n",
    "\n",
    "            p_value = r.pvalue\n",
    "            p_values.append(p_value)\n",
    "\n",
    "            llr = np.log(p_B / p_A) if p_B > 0 and p_A > 0 else 0\n",
    "            llr_values.append(llr)\n",
    "\n",
    "            if llr <= A:\n",
    "                stop_day = df_merged.loc[i, date_col]\n",
    "                print(f\"On {stop_day} might be stopped: LLR={llr:.3f} <= {A:.3f} (Accept H0)\")\n",
    "                break\n",
    "            elif llr >= B:\n",
    "                stop_day = df_merged.loc[i, date_col]\n",
    "                print(f\"On {stop_day} might be stopped: LLR={llr:.3f} >= {B:.3f} (Accept H1)\")\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Ошибка на дне {df_merged.loc[i, date_col]}: {e}\")\n",
    "            p_values.append(np.nan)\n",
    "            llr_values.append(np.nan)\n",
    "\n",
    "    # Создаем DataFrame с результатами\n",
    "    df_results = df_merged.iloc[:len(p_values)].copy()\n",
    "    df_results[\"p_value\"] = p_values\n",
    "    df_results[\"LLR\"] = llr_values\n",
    "    df_results[\"A/B\"] = str([A, B])\n",
    "    df_results[\"alpha_threshold\"] = np.linspace(alpha, alpha / np.sqrt(len(df_results)), len(p_values))  # Коррекция alpha\n",
    "\n",
    "    # Визуализация результатов\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df_results[date_col], df_results[\"p_value\"], label=\"P-value\", marker=\"o\")\n",
    "    plt.plot(df_results[date_col], df_results[\"alpha_threshold\"], label=\"Corrected Alpha\", linestyle=\"dashed\")\n",
    "    plt.axhline(y=alpha, color=\"red\", linestyle=\"--\", label=\"Standard Alpha (0.05)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"P-Value\")\n",
    "    plt.title(\"P-value daily vs. Corrected Alpha\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return df_results\n",
    "\n",
    "def calculate_criteria(df):\n",
    "    df_res_1 = pd.DataFrame()\n",
    "    indicators = ['has_ride', 'rides', 'gmv']\n",
    "\n",
    "    total_res_z = expab.ztest_proportion(df, 'has_ride', 'group_name')\n",
    "    total_res_z['city_name'] = 'all the cities together'\n",
    "    total_res_t = expab.ttest(df, 'gmv', 'group_name')\n",
    "    total_res_t['city_name'] = 'all the cities together'\n",
    "    total_res_t2 = expab.ttest(df, 'rides', 'group_name')\n",
    "    total_res_t2['city_name'] = 'all the cities together'\n",
    "\n",
    "    df_res_1 = pd.concat([df_res_1, total_res_z, total_res_t, total_res_t2])\n",
    "\n",
    "    for city in df['city_name'].unique():\n",
    "        \n",
    "        for metric in indicators:\n",
    "            if metric == 'has_ride':\n",
    "                city_df_z = expab.ztest_proportion(df.query(f\"city_name == '{city}'\"), metric, 'group_name')\n",
    "                city_df_z['city_name'] = city\n",
    "\n",
    "                df_res_1 = pd.concat([df_res_1, city_df_z])\n",
    "\n",
    "            else:\n",
    "                city_df_t = expab.ttest(df.query(f\"city_name == '{city}'\"), metric, 'group_name')\n",
    "                city_df_t['city_name'] = city\n",
    "\n",
    "                df_res_1 = pd.concat([df_res_1, city_df_t])\n",
    "\n",
    "    df_res_1['corrected_pvalue'] = expab.method_benjamini_hochberg(df_res_1['pvalue'].values)\n",
    "    df_res_1['significance'] = (df_res_1['pvalue']<0.05)*1\n",
    "\n",
    "\n",
    "    return df_res_1\n",
    "\n",
    "def calculate_numbers(df):\n",
    "\n",
    "    df_agg = df.groupby(['group_name', 'city_name'], as_index=False)[['user_id', 'has_ride', 'rides', 'orders', 'gmv']].agg(\n",
    "        {'user_id':'count', \n",
    "        'has_ride':'sum', \n",
    "        'rides':'sum', \n",
    "        'gmv':'sum'}\n",
    "        ).sort_values(['city_name', 'group_name', 'user_id'], ascending=True)\n",
    "\n",
    "    df_agg['group_name'] = df_agg['group_name'].astype(str)\n",
    "\n",
    "    df_agg['group_name'] = df_agg['group_name'].replace({'0':'Control', '1':'Treatment'})\n",
    "\n",
    "    df_agg['cr_ride_%'] = np.round(df_agg['has_ride'] / df_agg['user_id'] * 100,2)\n",
    "    df_agg['cr_ride'] = np.round(df_agg['has_ride'] / df_agg['user_id'],5)\n",
    "    df_agg['cr_ride_%'] = df_agg['cr_ride_%'].astype(str)\n",
    "    df_agg['cr_ride_%'] = df_agg['cr_ride_%'] + '%'\n",
    "\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73507f",
   "metadata": {},
   "source": [
    "# Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7232be77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>participant_first_toggle_date</th>\n",
       "      <th>registration_date</th>\n",
       "      <th>os_name</th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_id</th>\n",
       "      <th>country_name</th>\n",
       "      <th>newbie_flag</th>\n",
       "      <th>reg_same_day_flag</th>\n",
       "      <th>filled_flow</th>\n",
       "      <th>registration_dt</th>\n",
       "      <th>show_dt</th>\n",
       "      <th>click_dt</th>\n",
       "      <th>approve_dt</th>\n",
       "      <th>approve_flag</th>\n",
       "      <th>not_approve_dt</th>\n",
       "      <th>not_approve_flag</th>\n",
       "      <th>order_timestamp</th>\n",
       "      <th>order_flag</th>\n",
       "      <th>gmv</th>\n",
       "      <th>rides</th>\n",
       "      <th>orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230148120</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-07-29</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>android</td>\n",
       "      <td>4200</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-07-29 18:17:23.807000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304889087</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-08-02</td>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>ios</td>\n",
       "      <td>4200</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-08-02 18:30:09.670000+00:00</td>\n",
       "      <td>2025-08-02 18:36:52.791000+00:00</td>\n",
       "      <td>2025-08-02 18:36:53.540000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-08-02 18:37:12.366000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>305079415</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>2025-07-13</td>\n",
       "      <td>android</td>\n",
       "      <td>4267</td>\n",
       "      <td>Arica</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-07-31 23:57:00.446000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307494834</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-30</td>\n",
       "      <td>2025-07-27</td>\n",
       "      <td>android</td>\n",
       "      <td>4200</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-07-30 15:42:02.807000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307652767</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-28</td>\n",
       "      <td>2025-07-28</td>\n",
       "      <td>android</td>\n",
       "      <td>4200</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>25</td>\n",
       "      <td>Chile</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-07-28 01:59:21.729000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  group_id participant_first_toggle_date registration_date  os_name  city_id city_name  country_id country_name  newbie_flag  reg_same_day_flag filled_flow                  registration_dt                          show_dt                         click_dt approve_dt  approve_flag                   not_approve_dt  not_approve_flag order_timestamp  order_flag  gmv  rides  orders\n",
       "0  230148120         1                    2025-07-29        2024-04-25  android     4200  Santiago          25        Chile            1                  0    liveness 2025-07-29 18:17:23.807000+00:00                              NaT                              NaT        NaT             0                              NaT                 0             NaT           0  NaN   <NA>    <NA>\n",
       "1  304889087         0                    2025-08-02        2025-07-11      ios     4200  Santiago          25        Chile            1                  0    liveness 2025-08-02 18:30:09.670000+00:00 2025-08-02 18:36:52.791000+00:00 2025-08-02 18:36:53.540000+00:00        NaT             0 2025-08-02 18:37:12.366000+00:00                 1             NaT           0  NaN   <NA>    <NA>\n",
       "2  305079415         0                    2025-07-31        2025-07-13  android     4267     Arica          25        Chile            1                  0    liveness 2025-07-31 23:57:00.446000+00:00                              NaT                              NaT        NaT             0                              NaT                 0             NaT           0  NaN   <NA>    <NA>\n",
       "3  307494834         0                    2025-07-30        2025-07-27  android     4200  Santiago          25        Chile            1                  0    liveness 2025-07-30 15:42:02.807000+00:00                              NaT                              NaT        NaT             0                              NaT                 0             NaT           0  NaN   <NA>    <NA>\n",
       "4  307652767         0                    2025-07-28        2025-07-28  android     4200  Santiago          25        Chile            1                  1    liveness 2025-07-28 01:59:21.729000+00:00                              NaT                              NaT        NaT             0                              NaT                 0             NaT           0  NaN   <NA>    <NA>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_bq(\"\"\"\n",
    "WITH newbies AS (SELECT user_id,\n",
    "                        metric_date\n",
    "                 FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "                 WHERE user_type = 'pass'\n",
    "                   AND rides_count > 0\n",
    "                   AND metric_date >= DATE_ADD(CURRENT_DATE(), INTERVAL -1 YEAR)\n",
    "                   AND country_id = 25),\n",
    "     registered AS (SELECT id, DATE(created) AS created\n",
    "                    FROM dwh-storage-327422.personal_data.tbl_user_act\n",
    "                    WHERE DATE(created) BETWEEN '2020-01-01' AND CURRENT_DATE()\n",
    "                      AND country_id IN (25)),\n",
    "     gmv AS (SELECT user_id,\n",
    "                    SUM(gmv_clean_usd) AS gmv,\n",
    "                    SUM(rides_count)   AS rides,\n",
    "                    SUM(orders_count)  AS orders\n",
    "             FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "             WHERE user_type = 'pass'\n",
    "               AND metric_date BETWEEN '2025-06-01' AND CURRENT_DATE()\n",
    "               AND country_id = 25\n",
    "             GROUP BY 1),\n",
    "     total AS (SELECT t1.user_id,\n",
    "                      t1.city_id,\n",
    "                      geo.city_name,\n",
    "                      geo.country_id,\n",
    "                      geo.country_name,\n",
    "                      IF(group_id = 4546283, 0, 1) AS group_id,\n",
    "                      participant_first_toggle_date,\n",
    "                      t2.metric_date,\n",
    "                      t3.created                   AS registration_date,\n",
    "                      CASE\n",
    "                          WHEN t2.metric_date IS NULL THEN 1\n",
    "                          ELSE 0\n",
    "                          END                         newbie_flag,\n",
    "                      CASE\n",
    "                          WHEN t3.created = t1.participant_first_toggle_date THEN 1\n",
    "                          ELSE 0\n",
    "                          END                         reg_same_day_flag\n",
    "               FROM indrive-core.ab_platform.tbl_ab_experiment_markup t1\n",
    "                        JOIN indriver-e6e40.heap.vw_macroregion_mapping geo\n",
    "                             ON\n",
    "                                 t1.city_id = geo.city_id\n",
    "                        LEFT JOIN newbies t2\n",
    "                                  ON t1.user_id = t2.user_id AND t2.metric_date < t1.participant_first_toggle_date\n",
    "                        LEFT JOIN registered t3\n",
    "                                  ON t1.user_id = t3.id\n",
    "               WHERE experiment_id = 3684\n",
    "               QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY metric_date DESC) = 1),\n",
    "     liveness AS (SELECT user_id,\n",
    "                         os_name,\n",
    "                         city_id,\n",
    "                         city_name,\n",
    "                         country_id,\n",
    "                         country_name,\n",
    "                         COALESCE(filled_flow, 'liveness')                                  AS filled_flow,\n",
    "                         MAX(IF(name = 'registration.success', client_time, NULL))          AS registration_dt,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.show', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS show_dt,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.click', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS click_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) = 'approve'), client_time, NULL))            AS approve_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) != 'approve'), client_time, NULL))           AS not_approve_dt\n",
    "                  FROM (SELECT t1.user_id,\n",
    "                               t1.name,\n",
    "                               t1.os_name,\n",
    "                               DATE(TIMESTAMP_MILLIS(t1.client_time))                  AS event_dt_part,\n",
    "                               TIMESTAMP_MILLIS(t1.client_time)                        AS client_time,\n",
    "                               t1.city_id,\n",
    "                               t2.city_name,\n",
    "                               t2.country_id,\n",
    "                               t2.country_name,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.verification_flow')     AS verification_flow,\n",
    "                               IF(JSON_EXTRACT_SCALAR(payload, '$.verification_flow') IS NULL,\n",
    "                                  LAG(JSON_EXTRACT_SCALAR(payload, '$.verification_flow'))\n",
    "                                      OVER (PARTITION BY t1.user_id ORDER BY client_time),\n",
    "                                  JSON_EXTRACT_SCALAR(payload, '$.verification_flow')) AS filled_flow,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.status')                AS status\n",
    "                        FROM (SELECT *\n",
    "                              FROM indriver-e6e40.emart.product_event t1\n",
    "                              WHERE 1 = 1\n",
    "                                AND name IN ('registration.success',\n",
    "                                             'client.verification_start.show',\n",
    "                                             'client.verification_start.click',\n",
    "                                             'client.verification_flow_result_status.show'\n",
    "                                  )\n",
    "                                AND event_dt_part BETWEEN '2025-06-01' AND CURRENT_DATE()\n",
    "                                AND country_id IN (25)\n",
    "                              QUALIFY\n",
    "                                  ROW_NUMBER() OVER (PARTITION BY user_id, name, os_name, event_dt_part, JSON_EXTRACT_SCALAR(payload, '$.verification_flow') ORDER BY client_time DESC) =\n",
    "                                  1) t1\n",
    "                                 JOIN indriver-e6e40.heap.vw_macroregion_mapping t2\n",
    "                                      ON\n",
    "                                          t1.city_id = t2.city_id\n",
    "                        WHERE 1 = 1\n",
    "                          AND name IN ('registration.success',\n",
    "                                       'client.verification_start.show', 'client.verification_start.click',\n",
    "                                       'client.verification_flow_result_status.show'\n",
    "                            ))\n",
    "                  GROUP BY 1, 2, 3, 4, 5, 6, 7),\n",
    "     total_liv AS (SELECT t1.user_id,\n",
    "                          t1.city_id,\n",
    "                          t1.city_name,\n",
    "                          t1.country_id,\n",
    "                          t1.country_name,\n",
    "                          t1.group_id,\n",
    "                          t1.participant_first_toggle_date,\n",
    "                          t1.registration_date,\n",
    "                          t1.newbie_flag,\n",
    "                          t1.reg_same_day_flag,\n",
    "                          t2.user_id AS user_with_svf,\n",
    "                          t2.os_name,\n",
    "                          t2.filled_flow,\n",
    "                          t2.registration_dt,\n",
    "                          t2.show_dt,\n",
    "                          t2.click_dt,\n",
    "                          t2.approve_dt,\n",
    "                          t2.not_approve_dt\n",
    "                   FROM total t1\n",
    "                            JOIN liveness t2\n",
    "                                 ON t1.user_id = t2.user_id AND\n",
    "                                    DATE(t2.registration_dt) >= t1.participant_first_toggle_date),\n",
    "     rides AS (SELECT order_uuid,\n",
    "                      user_id    AS pass_id,\n",
    "                      driver_id,\n",
    "                      city_id    AS order_city_id,\n",
    "                      country_id AS order_country_id,\n",
    "                      status_order,\n",
    "                      order_timestamp,\n",
    "                      at_pickup_dttm,\n",
    "                      departed_pickup_dttm,\n",
    "                      at_destination_dttm,\n",
    "                      departed_destination_dttm,\n",
    "                      driveraccept_timestamp,\n",
    "                      driverarrived_timestamp,\n",
    "                      driverstarttheride_timestamp,\n",
    "                      driverdone_timestamp,\n",
    "                      clientdone_timestamp,\n",
    "                      clientcancel_timestamp,\n",
    "                      drivercancel_timestamp,\n",
    "                      user_reg_date,\n",
    "                      driver_reg_date,\n",
    "                      stage,\n",
    "                      created_date_order_part,\n",
    "                      duration_in_seconds\n",
    "               FROM indriver-e6e40.imart.incity_detail_new_order\n",
    "               WHERE created_date_order_part BETWEEN '2025-06-01'\n",
    "                   AND CURRENT_DATE()\n",
    "                 AND status_order = 'RIDE_STATUS_DONE'\n",
    "                 AND driveraccept_timestamp IS NOT NULL\n",
    "                 AND (clientcancel_timestamp IS NULL\n",
    "                   AND drivercancel_timestamp IS NULL))\n",
    "SELECT t1.user_id,\n",
    "       t1.group_id,\n",
    "       t1.participant_first_toggle_date,\n",
    "       t1.registration_date,\n",
    "       t1.os_name,\n",
    "       t1.city_id,\n",
    "       t1.city_name,\n",
    "       t1.country_id,\n",
    "       t1.country_name,\n",
    "       t1.newbie_flag,\n",
    "       t1.reg_same_day_flag,\n",
    "       filled_flow,\n",
    "       registration_dt,\n",
    "       show_dt,\n",
    "       click_dt,\n",
    "       approve_dt                                                  AS approve_dt,\n",
    "       IF(approve_dt IS NOT NULL, 1, 0)                            AS approve_flag,\n",
    "       not_approve_dt,\n",
    "       IF(not_approve_dt IS NOT NULL AND approve_dt IS NULL, 1, 0) AS not_approve_flag,\n",
    "       t2.order_timestamp,\n",
    "       IF(t2.order_timestamp IS NOT NULL, 1, 0)                    AS order_flag,\n",
    "       t3.gmv,\n",
    "       t3.rides,\n",
    "       t3.orders\n",
    "FROM total_liv t1\n",
    "         LEFT JOIN rides t2\n",
    "                   ON t1.user_id = t2.pass_id AND\n",
    "                      t2.created_date_order_part >= participant_first_toggle_date\n",
    "         LEFT JOIN gmv t3 ON t1.user_id = t3.user_id\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY t2.order_timestamp) = 1\n",
    "\"\"\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "365a8849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>newbie_flag</th>\n",
       "      <th>registration_dt</th>\n",
       "      <th>show_dt</th>\n",
       "      <th>click_dt</th>\n",
       "      <th>approve_dt</th>\n",
       "      <th>not_approve_dt</th>\n",
       "      <th>order_flag</th>\n",
       "      <th>cr_to_show</th>\n",
       "      <th>cr_to_approve</th>\n",
       "      <th>cr_to_ride</th>\n",
       "      <th>cr_to_ride_2</th>\n",
       "      <th>cr_to_not_approve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8169</td>\n",
       "      <td>5179</td>\n",
       "      <td>5052</td>\n",
       "      <td>2856</td>\n",
       "      <td>722</td>\n",
       "      <td>1903</td>\n",
       "      <td>63.40</td>\n",
       "      <td>56.53</td>\n",
       "      <td>66.63</td>\n",
       "      <td>23.30</td>\n",
       "      <td>14.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>966</td>\n",
       "      <td>851</td>\n",
       "      <td>788</td>\n",
       "      <td>409</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>88.10</td>\n",
       "      <td>51.90</td>\n",
       "      <td>62.59</td>\n",
       "      <td>26.50</td>\n",
       "      <td>13.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_id  newbie_flag  registration_dt  show_dt  click_dt  approve_dt  not_approve_dt  order_flag  cr_to_show  cr_to_approve  cr_to_ride  cr_to_ride_2  cr_to_not_approve\n",
       "0         0            1             8169     5179      5052        2856             722        1903       63.40          56.53       66.63         23.30              14.29\n",
       "1         1            1              966      851       788         409             106         256       88.10          51.90       62.59         26.50              13.45"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = df[(df['newbie_flag']==1)&(df['reg_same_day_flag']==1)].groupby(['group_id', 'newbie_flag'], as_index=False)[['registration_dt', 'show_dt', 'click_dt', 'approve_dt', 'not_approve_dt', 'order_flag']].agg({'registration_dt':'count', 'show_dt':'count', 'click_dt':'count', 'approve_dt':'count', 'not_approve_dt':'count', 'order_flag':'sum'})\n",
    "\n",
    "df_grouped['cr_to_show'] = df_grouped['show_dt'] / df_grouped['registration_dt'] * 100\n",
    "df_grouped['cr_to_approve'] = df_grouped['approve_dt'] / df_grouped['click_dt'] * 100\n",
    "df_grouped['cr_to_ride'] = df_grouped['order_flag'] / df_grouped['approve_dt'] * 100\n",
    "df_grouped['cr_to_ride_2'] = df_grouped['order_flag'] / df_grouped['registration_dt'] * 100\n",
    "df_grouped['cr_to_not_approve'] = df_grouped['not_approve_dt'] / df_grouped['click_dt'] * 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a9a1a812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>minutes</th>\n",
       "      <th>minutes_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>295.00</td>\n",
       "      <td>11,347.13</td>\n",
       "      <td>4.92</td>\n",
       "      <td>189.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.00</td>\n",
       "      <td>7,892.66</td>\n",
       "      <td>0.33</td>\n",
       "      <td>131.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_id  median      mean  minutes  minutes_2\n",
       "0         0  295.00 11,347.13     4.92     189.12\n",
       "1         1   20.00  7,892.66     0.33     131.54"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_anal = df.query(\"reg_same_day_flag == 1 and newbie_flag == 1\")[['group_id', 'registration_dt', 'show_dt']]\n",
    "\n",
    "time_anal['registration_dt'] = pd.to_datetime(time_anal['registration_dt'])\n",
    "time_anal['show_dt'] = pd.to_datetime(time_anal['show_dt'])\n",
    "\n",
    "time_anal['time_diff'] = (time_anal['show_dt'] - time_anal['registration_dt']).dt.seconds\n",
    "\n",
    "time_anal = time_anal.groupby(['group_id'], as_index=False)['time_diff'].agg(['median', 'mean'])\n",
    "\n",
    "time_anal['minutes'] = time_anal['median']/60\n",
    "time_anal['minutes_2'] = time_anal['mean']/60\n",
    "\n",
    "time_anal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f494c502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5600.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8000*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6d874fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.878947368421052"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2257/19000*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a15c5",
   "metadata": {},
   "source": [
    "# Summarising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3786b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>newbie_flag</th>\n",
       "      <th>registration_dt</th>\n",
       "      <th>show_dt</th>\n",
       "      <th>click_dt</th>\n",
       "      <th>approve_dt</th>\n",
       "      <th>not_approve_dt</th>\n",
       "      <th>order_flag</th>\n",
       "      <th>cr_to_approve</th>\n",
       "      <th>cr_to_ride</th>\n",
       "      <th>cr_to_not_approve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8169</td>\n",
       "      <td>5179</td>\n",
       "      <td>5052</td>\n",
       "      <td>2856</td>\n",
       "      <td>722</td>\n",
       "      <td>1903</td>\n",
       "      <td>34.96</td>\n",
       "      <td>23.30</td>\n",
       "      <td>8.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>966</td>\n",
       "      <td>851</td>\n",
       "      <td>788</td>\n",
       "      <td>409</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>42.34</td>\n",
       "      <td>26.50</td>\n",
       "      <td>10.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_id  newbie_flag  registration_dt  show_dt  click_dt  approve_dt  not_approve_dt  order_flag  cr_to_approve  cr_to_ride  cr_to_not_approve\n",
       "1         0            1             8169     5179      5052        2856             722        1903          34.96       23.30               8.84\n",
       "3         1            1              966      851       788         409             106         256          42.34       26.50              10.97"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rides'] = df['rides'].fillna(0)\n",
    "df['gmv'] = df['gmv'].fillna(0)\n",
    "\n",
    "df_grouped = df.query(\"reg_same_day_flag == 1\").groupby(['group_id', 'newbie_flag'], as_index=False)[['registration_dt', 'show_dt', 'click_dt', 'approve_dt', 'not_approve_dt', 'order_flag']].agg({'registration_dt':'count', 'show_dt':'count', 'click_dt':'count', 'approve_dt':'count', 'not_approve_dt':'count', 'order_flag':'sum'})\n",
    "\n",
    "df_grouped['cr_to_approve'] = df_grouped['approve_dt'] / df_grouped['registration_dt'] * 100\n",
    "df_grouped['cr_to_ride'] = df_grouped['order_flag'] / df_grouped['registration_dt'] * 100\n",
    "df_grouped['cr_to_not_approve'] = df_grouped['not_approve_dt'] / df_grouped['registration_dt'] * 100\n",
    "\n",
    "\n",
    "df_grouped.query(\"newbie_flag == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e92dcd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>group0_sample_size</th>\n",
       "      <th>group1_sample_size</th>\n",
       "      <th>group0</th>\n",
       "      <th>group1</th>\n",
       "      <th>statistic</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>diff_mean</th>\n",
       "      <th>diff_mean_%</th>\n",
       "      <th>lb</th>\n",
       "      <th>ub</th>\n",
       "      <th>lb_%</th>\n",
       "      <th>ub_%</th>\n",
       "      <th>criteria</th>\n",
       "      <th>significance</th>\n",
       "      <th>result_with_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approve_flag</td>\n",
       "      <td>8169</td>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>21.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.71</td>\n",
       "      <td>30.49</td>\n",
       "      <td>ztest</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_approve_flag</td>\n",
       "      <td>8169</td>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>16.81</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>40.10</td>\n",
       "      <td>ztest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_flag</td>\n",
       "      <td>8169</td>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.03</td>\n",
       "      <td>13.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.18</td>\n",
       "      <td>26.34</td>\n",
       "      <td>ztest</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rides</td>\n",
       "      <td>8169</td>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.16</td>\n",
       "      <td>28.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.79</td>\n",
       "      <td>52.23</td>\n",
       "      <td>ttest</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gmv</td>\n",
       "      <td>8169</td>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3.03</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>20.72</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>41.96</td>\n",
       "      <td>ttest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        metric_name group0_sample_size group1_sample_size group0 group1  statistic  pvalue  mean0  mean1  diff_mean  diff_mean_%    lb   ub  lb_%  ub_% criteria  significance  result_with_corr\n",
       "0      approve_flag               8169                966      0      1      -4.40    0.00   0.35   0.42       0.07        21.10  0.04 0.11 11.71 30.49    ztest             1                 1\n",
       "0  not_approve_flag               8169                966      0      1      -1.41    0.16   0.09   0.10       0.01        16.81 -0.01 0.03 -6.48 40.10    ztest             0                 0\n",
       "0        order_flag               8169                966      0      1      -2.14    0.03   0.23   0.27       0.03        13.76  0.00 0.06  1.18 26.34    ztest             1                 0\n",
       "0             rides               8169                966      0      1      -2.27    0.02   0.57   0.74       0.16        28.01  0.02 0.30  3.79 52.23    ttest             1                 0\n",
       "0               gmv               8169                966      0      1      -1.91    0.06   3.03   3.66       0.63        20.72 -0.02 1.27 -0.51 41.96    ttest             0                 0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicators = ['approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']\n",
    "res_df = pd.DataFrame()\n",
    "\n",
    "for metric in indicators:\n",
    "\n",
    "    if metric in ['rides', 'gmv']:\n",
    "        ttest = expab.ttest(\n",
    "            df[(df['newbie_flag']==1)&(df['reg_same_day_flag']==1)][['user_id', 'group_id', 'os_name', 'approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']],\n",
    "            metric,\n",
    "            'group_id'\n",
    "            )\n",
    "        ttest['criteria'] = 'ttest'\n",
    "        res_df = pd.concat([res_df, ttest])\n",
    "\n",
    "    else:\n",
    "        ztest = expab.ztest_proportion(\n",
    "            df[(df['newbie_flag']==1)&(df['reg_same_day_flag']==1)][['user_id', 'group_id', 'os_name', 'approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']],\n",
    "            metric,\n",
    "            'group_id'\n",
    "            )\n",
    "        ztest['criteria'] = 'ztest'\n",
    "        res_df = pd.concat([res_df, ztest])\n",
    "\n",
    "    res_df['significance'] = (res_df['pvalue']<0.05)*1\n",
    "    res_df['result_with_corr'] = method_benjamini_hochberg(res_df['pvalue'].values)\n",
    "\n",
    "res_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
