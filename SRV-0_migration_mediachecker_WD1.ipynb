{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bab03d4",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "951b32c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisation\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Data analysis / Data processing\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "from datetime import time, timedelta, datetime\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "# Maths & Stats\n",
    "import math \n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import statsmodels.stats.weightstats as ws\n",
    "from statsmodels.stats.proportion import test_proportions_2indep\n",
    "import AB_library\n",
    "# from ambrosia.designer import Designer\n",
    "# from ambrosia.tester import Tester\n",
    "import expab\n",
    "from statsmodels.stats.power import NormalIndPower\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "from math import ceil\n",
    "\n",
    "# System library\n",
    "import os\n",
    "import ipywidgets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# from itables import init_notebook_mode\n",
    "# init_notebook_mode(all_interactive=True)\n",
    "import openpyxl\n",
    "\n",
    "# Data connection\n",
    "from google.cloud import bigquery\n",
    "bigquery_client = bigquery.Client(project='analytics-dev-333113')\n",
    "\n",
    "\n",
    "# Useful functions\n",
    "def read_bq(query, project='analytics-dev-333113'):\n",
    "    client = bigquery.Client(project=project)\n",
    "    query_job = client.query(query)\n",
    "    result_df = query_job.to_dataframe()\n",
    "    return result_df\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "\n",
    "    html_str = ''\n",
    "    for df in args:\n",
    "        html_str += df.to_html()\n",
    "    display_html(\n",
    "        html_str.replace('table','table style=\"display:inline\"'), \n",
    "        raw=True\n",
    "    )\n",
    "\n",
    "def cycle_sql(start, end, query, weeks=False):\n",
    "    \"\"\"\n",
    "    You have to use {date} in your script to add cycle date into this backets\n",
    "    \"\"\"\n",
    "    date_start = datetime.strptime(start, '%Y-%m-%d')\n",
    "    date_end = datetime.strptime(end, '%Y-%m-%d')\n",
    "\n",
    "    if weeks == False:\n",
    "        daterange = [(date_start + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days)+1)]\n",
    "    else:\n",
    "        daterange = [(date_start + timedelta(weeks=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days//7)+1)] # weeks dividing days by 7\n",
    "\n",
    "    total_df = pd.DataFrame()\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for date in daterange:\n",
    "        counter+=1\n",
    "        print(f\"{counter}) Uploading - {date}:\", datetime.today().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        script = query.format(date = date)\n",
    "        df_cycle = bigquery_client.query(script).to_dataframe()\n",
    "        if df_cycle.empty == True:\n",
    "            print('Dataframe is empty')\n",
    "        total_df = pd.concat([df_cycle, total_df])\n",
    "    return total_df  \n",
    "\n",
    "def writing_excel(name:str, dataset1=None, dataset2=None, dataset3=None, dataset4=None):\n",
    "    with pd.ExcelWriter(f\"{name}.xlsx\") as writer:\n",
    "\n",
    "    # use to_excel function and specify the sheet_name and index \n",
    "    # to store the dataframe in specified sheet\n",
    "\n",
    "        if dataset1 is not None:\n",
    "            if dataset2 is not None:\n",
    "                if dataset3 is not None:\n",
    "                    if dataset4 is not None:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset4.to_excel(writer, sheet_name=f\"4-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                    else:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                else:\n",
    "                    dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "                    dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "            else:\n",
    "                dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                #   index=False\n",
    "                                    )\n",
    "\n",
    "        print('DataFrame is written to Excel File successfully.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b10c6",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c6c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "garage = \"\"\"\n",
    "WITH wd1_doc AS (SELECT *\n",
    "                 FROM (SELECT dd.user_id,\n",
    "                              dd.request_id,\n",
    "                              title,\n",
    "                              value\n",
    "                       FROM `dwh-storage-327422.ods_watchdocs.document_data` AS dd\n",
    "                                LEFT JOIN indriver-e6e40.ods_watchdocs.document_object AS do\n",
    "                                          ON dd.document_object_id = do.id\n",
    "                       WHERE 1 = 1\n",
    "                         AND TRIM(do.title) IN (\n",
    "                           'MSG_PHOTO_OF_YOUR_CAR' --  тут можно будет докинуть еще вариации, если они есть\n",
    "                           )\n",
    "                         AND dd.value != ''\n",
    "                         AND dd.value IS NOT NULL\n",
    "                       QUALIFY\n",
    "                           ROW_NUMBER() OVER (PARTITION BY dd.user_id, dd.request_id, do.title ORDER BY CASE WHEN CAST(do.is_required AS STRING) = 'true' THEN 1 ELSE 0 END DESC,\n",
    "                               CASE WHEN dd.status = 10 THEN 1 ELSE 0 END DESC,\n",
    "                               COALESCE(dd.update_date, dd.create_date, TIMESTAMP(\"1900-01-01 00:00:00+00\")) DESC,\n",
    "                               COALESCE(dd.create_date, TIMESTAMP(\"1900-01-01 00:00:00+00\")) DESC, dd.id DESC) = 1) AS q\n",
    "                     PIVOT (ANY_VALUE(value) FOR title IN ('MSG_PHOTO_OF_YOUR_CAR')) -- сюда тоже их докинуть, чтобы развернуть в горизонтальную структуру\n",
    "),\n",
    "     wd1_req AS ( -- заявки вд1\n",
    "         SELECT user_id,\n",
    "                id,\n",
    "                CASE WHEN state IN (20, 40) THEN 'approved' ELSE 'declined' END AS state -- упростил статусную модель\n",
    "         FROM dwh-storage-327422.ods_watchdocs.user_request),\n",
    "     profile AS ( -- профили вд2\n",
    "         SELECT *\n",
    "         FROM (SELECT dpg.*,\n",
    "                      CAST(CONCAT('0x', SUBSTR(dpg.user_id, 25, 12)) AS INT64)   AS driver_id,\n",
    "                      LOWER(REPLACE(dpg.status, 'DOCUMENT_PROFILE_STATUS_', '')) AS new_status,\n",
    "                      nos.source_id\n",
    "               FROM `indriver-e6e40.ods_watchdocs.document_profile_act_global` AS dpg\n",
    "                        INNER JOIN `indriver-e6e40.mdict.new_order_source_nm_to_source_id` AS nos\n",
    "                                   ON dpg.source_nm = nos.source_nm\n",
    "                                       AND nos.table_nm = 'indriver-e6e40.ods_watchdocs.document_profile_global'\n",
    "               WHERE 1 = 1) AS q\n",
    "         WHERE 1 = 1\n",
    "           AND q.driver_id NOT IN (259949038) -- тестовый юзер с слов бэка\n",
    "         QUALIFY DENSE_RANK() OVER (PARTITION BY driver_id, service_id ORDER BY IF(source_id = 11, 0, 1) DESC) = 1)\n",
    "        ,\n",
    "     doc_profile AS ( -- документы профилей вд2\n",
    "         SELECT *\n",
    "         FROM (SELECT dpdg.*,\n",
    "                      REPLACE(dpdg.status, 'DOCUMENT_PROFILE_DOCUMENT_STATUS_', '') AS new_status,\n",
    "                      nos.source_id\n",
    "               FROM `indriver-e6e40.ods_watchdocs.document_profile_documents_act_global` AS dpdg\n",
    "                        INNER JOIN indriver-e6e40.mdict.new_order_source_nm_to_source_id AS nos\n",
    "                                   ON dpdg.source_nm = nos.source_nm\n",
    "                                       AND nos.table_nm =\n",
    "                                           'indriver-e6e40.ods_watchdocs.document_profile_documents_global') AS q\n",
    "         WHERE 1 = 1),\n",
    "     wd2_doc AS ( -- документы вд2 со значениями\n",
    "         SELECT document_id,\n",
    "                value,\n",
    "                document_kind_nm,\n",
    "                field_kind_nm,\n",
    "                nos.source_id\n",
    "         FROM dwh-storage-327422.ods_watchdocs.wd2_document_data_act_global ddg\n",
    "                  JOIN indriver-e6e40.mdict.new_order_source_nm_to_source_id AS nos ON nos.source_nm = ddg.source_nm\n",
    "             AND nos.table_nm = 'dwh-storage-327422.ods_watchdocs.wd2_document_data_global'\n",
    "         WHERE 1 = 1\n",
    "           AND document_kind_nm = 'Vehicle information'\n",
    "           AND field_kind_nm = 'Vehicle picture'),\n",
    "     wd2_all AS ( -- собираем доки и профили в 1 месте\n",
    "         SELECT *\n",
    "         FROM (SELECT dp.document_id,\n",
    "                      p.new_status      AS driver_status, -- здесь для вд2 статусы не упрощал, вывел что есть, они хотя бы строкой идут, а не цифрами\n",
    "                      p.source_id,\n",
    "                      p.updated_at      AS profile_update,\n",
    "                      p.source_nm,\n",
    "                      CASE\n",
    "                          WHEN p.service_name LIKE '%appcity%' THEN 'APPLICATION_VERTICAL_CITY'\n",
    "                          WHEN p.service_name LIKE '%courier%' THEN 'APPLICATION_VERTICAL_COURIER'\n",
    "                          ELSE NULL END AS service_name,  -- это для упрощения, чтобы джойнить по вертикали, которая пишется в гараж, пока вертикалей в вд2 только 2, потом будет больше\n",
    "                      wdd.value\n",
    "               FROM profile p\n",
    "                        LEFT JOIN doc_profile dp ON p.id = dp.document_profile_id\n",
    "                   AND p.source_id = dp.source_id\n",
    "                        LEFT JOIN wd2_doc wdd ON wdd.document_id = dp.document_id\n",
    "                   AND wdd.source_id = dp.source_id)\n",
    "         QUALIFY ROW_NUMBER() OVER (PARTITION BY document_id, service_name, source_nm ORDER BY profile_update DESC) =\n",
    "                 1 -- один документ может быть на куче профилей, пришлось схлопывать до последнего обновленного (это не прям супер точная выборка получается, но в целом думаю ок)\n",
    "     )\n",
    "SELECT *\n",
    "FROM (SELECT 'auto'                                                      AS import_type,\n",
    "             driver_id                                                   AS user_id,\n",
    "             uuid                                                        AS external_id,\n",
    "             JSON_OBJECT(\"source_id\", COALESCE(CAST(document_id AS string), CAST(request_id AS string), source_id),\n",
    "                         \"file_storage_id\",\n",
    "                         photo_car, \"color\", color, \"model\", model_name) AS metadata,\n",
    "             COALESCE(t1.country_id, t2.country_id)                      AS country_id,\n",
    "             agglomeration_id,\n",
    "             COALESCE(t1.city_id, t2.city_id)                            AS city_id\n",
    "      FROM (SELECT DISTINCT g.*,\n",
    "                            wd1.request_id,\n",
    "                            wd2.document_id,\n",
    "                            COALESCE(wd2.value, wd1.MSG_PHOTO_OF_YOUR_CAR, wd2_mx.value, wd2_co.value,\n",
    "                                     wd2_lt.value)         AS photo_car,\n",
    "                            COALESCE(wd2.driver_status, wd1r.state, wd2_mx.driver_status, wd2_co.driver_status,\n",
    "                                     wd2_lt.driver_status) AS driver_status\n",
    "            FROM `indriver-e6e40.ods_garage.garage_vehicles_global` g\n",
    "                     JOIN indriver-e6e40.mdict.new_order_source_nm_to_source_id AS nos\n",
    "                          ON nos.source_nm = g.source_nm -- это нужно для того чтобы джойнить данные в нужных кластерах\n",
    "                              AND nos.table_nm = 'indriver-e6e40.ods_garage.garage_vehicles_global'\n",
    "                     LEFT JOIN wd1_doc wd1 ON g.source_id = CAST(wd1.request_id AS string)\n",
    "                     LEFT JOIN wd1_req wd1r\n",
    "                               ON CAST(wd1r.id AS string) = g.source_id -- это source_id который с гаража как документ\n",
    "                     LEFT JOIN wd2_all wd2 ON wd2.document_id = g.source_id\n",
    "                AND wd2.source_id = nos.source_id -- а этот для матчинга кластера (сори за путаницу)\n",
    "                AND wd2.service_name = g.application_vertical\n",
    "\n",
    "-- из-за прошлых миграций придется делать вот такой костыль ниже для 3 кластеров\n",
    "                     LEFT JOIN wd2_all wd2_mx ON wd2_mx.document_id = g.source_id\n",
    "                AND wd2_mx.source_nm =\n",
    "                    'projects/709531919733/subscriptions/usea1-latam-mx.wd2-application.document-profile.v1.prod.bq_push'\n",
    "                AND g.source_nm = 'projects/709531919733/subscriptions/euce1-cis.garage.vehicles.v1.prod.bq'\n",
    "                AND wd2_mx.service_name = g.application_vertical\n",
    "                     LEFT JOIN wd2_all wd2_co ON wd2_co.document_id = g.source_id\n",
    "                AND wd2_co.source_nm =\n",
    "                    'projects/709531919733/subscriptions/saea1-latam-co.wd2-application.document-profile.v1.prod.bq_push'\n",
    "                AND g.source_nm = 'projects/709531919733/subscriptions/euce1-cis.garage.vehicles.v1.prod.bq'\n",
    "                AND wd2_co.service_name = g.application_vertical\n",
    "                     LEFT JOIN wd2_all wd2_lt ON wd2_lt.document_id = g.source_id\n",
    "                AND wd2_lt.source_nm =\n",
    "                    'projects/709531919733/subscriptions/saea1-latam.wd2-application.document-profile.v1.prod.bq_push'\n",
    "                AND g.source_nm = 'projects/709531919733/subscriptions/euce1-cis.garage.vehicles.v1.prod.bq'\n",
    "                AND wd2_lt.service_name = g.application_vertical) t1\n",
    "               LEFT JOIN dwh-storage-327422.personal_data.tbl_user_act t2 ON t1.driver_id = t2.id\n",
    "      WHERE driver_status = 'approved'\n",
    "        AND photo_car IS NOT NULL\n",
    "        AND type_id = 1\n",
    "        AND t1.country_id IN (SELECT DISTINCT (cr.country_id)\n",
    "                              FROM `dwh-storage-327422.emart_cdp.dim_cities` cr\n",
    "                              WHERE cr.region_nm = 'saea1-latam-co')) -- choosing the region\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "query_wd1 = \"\"\"\n",
    "WITH main_req AS\n",
    "         (SELECT COALESCE(l.user_id, f.user_id)         AS driver_id,\n",
    "                 COALESCE(l.user_request_id, f.id)      AS request_id,\n",
    "                 COALESCE(l.create_date, f.update_date) AS cr_up_date,\n",
    "                 f.country_id,\n",
    "                 f.city_id\n",
    "          FROM indriver-e6e40.ods_watchdocs.user_request_log l\n",
    "                   FULL JOIN dwh-storage-327422.ods_watchdocs.user_request f ON l.user_request_id = f.id\n",
    "          WHERE (l.action = 'accept' OR f.state IN (20, 40)) -- if there is a row with accepted record and 20,40 - request is approved\n",
    "          QUALIFY\n",
    "              ROW_NUMBER() OVER (PARTITION BY COALESCE(l.user_id, f.user_id) ORDER BY COALESCE(l.create_date, f.update_date) DESC) =\n",
    "              1),\n",
    "     grouped AS (SELECT main_req.*,\n",
    "                        dd.document_object_id,\n",
    "                        do.title,\n",
    "                        dd.value,\n",
    "                        COALESCE(dd.update_date, dd.create_date) AS doc_update_date\n",
    "                 FROM main_req\n",
    "                          JOIN dwh-storage-327422.watchdocs.document_data dd ON main_req.request_id = dd.request_id\n",
    "                          JOIN indriver-e6e40.watchdocs.document_object do ON dd.document_object_id = do.id\n",
    "                 WHERE do.title = 'PHOTO'\n",
    "                   AND NOT dd.value LIKE 'https://%'\n",
    "                   AND\n",
    "                   AND main_req.country_id IN (SELECT DISTINCT(cr.country_id)\n",
    "                                               FROM `dwh-storage-327422.emart_cdp.dim_cities` cr\n",
    "                                               WHERE cr.region_nm LIKE '%{region}%'),\n",
    "     res AS (SELECT 'contractor'                                                   AS import_type,\n",
    "                    driver_id                                                      AS user_id,\n",
    "                    driver_id                                                      AS external_id,\n",
    "                    JSON_OBJECT('source_id', request_id, 'file_storage_id', VALUE) AS metadata,\n",
    "                    country_id                                                     AS country_id,\n",
    "                    0                                                              AS agglomeration_id,\n",
    "                    city_id                                                        AS city_id\n",
    "             FROM grouped),\n",
    "     mc AS (SELECT user_id\n",
    "            FROM `indriver-e6e40.ods_media_checker.entity` AS e\n",
    "            WHERE source_nm LIKE '%{region}%'\n",
    "              AND e.entity_type = 'contractor')\n",
    "SELECT *\n",
    "FROM res\n",
    "WHERE res.user_id NOT IN (SELECT user_id FROM mc)\n",
    "\"\"\"\n",
    "\n",
    "query_wd2 = \"\"\"\n",
    "WITH raw AS (SELECT dd.document_id                                                                  AS source_id,\n",
    "                    CAST(`indriver-e6e40.de_functions.convert_uuid_to_id`(dd.user_uuid) AS INTEGER) AS user_id,\n",
    "                    dd.value                                                                        AS file_storage_id,\n",
    "                    d.country_id                                                                    AS country_id,\n",
    "                    d.state_id                                                                      AS agglomeration_id,\n",
    "                    d.city_id                                                                       AS city_id,\n",
    "                    dd.updated_at                                                                   AS updated_at\n",
    "             FROM `dwh-storage-327422.ods_watchdocs.wd2_document_data_global` dd\n",
    "                      INNER JOIN `indriver-e6e40.ods_watchdocs.document_global` d ON dd.document_id = d.id\n",
    "             WHERE dd.field_kind_uuid = '5099bd41-2d67-11ef-a465-da0741c8f290'\n",
    "               AND dd.source_nm like '%{region}%'\n",
    "             QUALIFY ROW_NUMBER() OVER (PARTITION BY dd.user_uuid ORDER BY dd.updated_at DESC) = 1),\n",
    "     res AS (SELECT 'contractor'                                                                AS import_type,\n",
    "                    r.user_id                                                                   AS user_id,\n",
    "                    r.user_id                                                                   AS external_id,\n",
    "                    JSON_OBJECT(\"source_id\", r.source_id, \"file_storage_id\", r.file_storage_id) AS metadata,\n",
    "                    r.country_id                                                                AS country_id,\n",
    "                    r.agglomeration_id                                                          AS agglomeration_id,\n",
    "                    r.city_id                                                                   AS city_id\n",
    "             FROM raw r\n",
    "             WHERE r.updated_at >= '2025-06-17 05:50:17'\n",
    "             ORDER BY r.user_id),\n",
    "     mc AS (SELECT user_id\n",
    "            FROM `indriver-e6e40.ods_media_checker.entity` AS e\n",
    "            WHERE source_nm like '%{region}%'\n",
    "              AND e.entity_type = 'contractor')\n",
    "SELECT res.*\n",
    "FROM res\n",
    "WHERE res.user_id NOT IN (SELECT user_id FROM mc)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a069fe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading the cis\n",
      "(16096, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/cis\n",
      "Uploading the africa\n",
      "(11165, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/africa\n",
      "Uploading the sea\n",
      "(428830, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/sea\n",
      "Uploading the sa\n",
      "(258328, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/sa\n",
      "Uploading the sa_in\n",
      "(29867, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/sa_in\n",
      "Uploading the eu\n",
      "(15266, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/eu\n",
      "Uploading the mena\n",
      "(369183, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/mena\n",
      "Uploading the mena_eg\n",
      "(350846, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/mena_eg\n",
      "Uploading the latam\n",
      "(114624, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/latam\n",
      "Uploading the latam_br\n",
      "(31883, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/latam_br\n",
      "Uploading the latam_pe\n",
      "(16972, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/latam_pe\n",
      "Uploading the latam_mx\n",
      "(38, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/latam_mx\n",
      "Uploading the latam_co\n",
      "(25346, 7)\n",
      "Files were saved to: /Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/latam_co\n",
      "Uploading the eu_central1\n",
      "(0, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_bq(query, project='analytics-dev-333113'):\n",
    "    client = bigquery.Client(project=project)\n",
    "    query_job = client.query(query)\n",
    "    result_df = query_job.to_dataframe()\n",
    "    return result_df\n",
    "\n",
    "sources = [\n",
    "    'cis', 'africa', \n",
    "    'sea', 'sa', 'sa_in', \n",
    "    'eu', 'mena', 'mena_eg', \n",
    "    'latam', 'latam_br', \n",
    "    'latam_pe', 'latam_mx', 'latam_co', 'eu_central1'\n",
    "    ]\n",
    "\n",
    "\n",
    "for region in sources:\n",
    "\n",
    "    print(f\"Uploading the {region}\")\n",
    "\n",
    "    df_code = read_bq(f\"\"\"\n",
    "WITH main_req AS\n",
    "         (SELECT COALESCE(l.user_id, f.user_id)         AS driver_id,\n",
    "                 COALESCE(l.user_request_id, f.id)      AS request_id,\n",
    "                 COALESCE(l.create_date, f.update_date) AS cr_up_date,\n",
    "                 f.country_id,\n",
    "                 f.city_id\n",
    "          FROM indriver-e6e40.ods_watchdocs.user_request_log l\n",
    "                   FULL JOIN dwh-storage-327422.ods_watchdocs.user_request f ON l.user_request_id = f.id\n",
    "          WHERE (l.action = 'accept' OR f.state IN (20, 40)) -- if there is a row with accepted record and 20,40 - request is approved\n",
    "          QUALIFY\n",
    "              ROW_NUMBER() OVER (PARTITION BY COALESCE(l.user_id, f.user_id) ORDER BY COALESCE(l.create_date, f.update_date) DESC) =\n",
    "              1),\n",
    "     grouped AS (SELECT main_req.*,\n",
    "                        dd.document_object_id,\n",
    "                        do.title,\n",
    "                        dd.value,\n",
    "                        COALESCE(dd.update_date, dd.create_date) AS doc_update_date\n",
    "                 FROM main_req\n",
    "                          JOIN dwh-storage-327422.watchdocs.document_data dd ON main_req.request_id = dd.request_id\n",
    "                          JOIN indriver-e6e40.watchdocs.document_object do ON dd.document_object_id = do.id\n",
    "                 WHERE do.title = 'PHOTO'\n",
    "                   AND NOT dd.value LIKE 'https://%'\n",
    "                   AND main_req.country_id IN (SELECT DISTINCT(cr.country_id)\n",
    "                                               FROM `dwh-storage-327422.emart_cdp.dim_cities` cr\n",
    "                                               WHERE cr.region_nm LIKE '%{region}%')),\n",
    "     res AS (SELECT 'contractor'                                                   AS import_type,\n",
    "                    driver_id                                                      AS user_id,\n",
    "                    driver_id                                                      AS external_id,\n",
    "                    JSON_OBJECT('source_id', request_id, 'file_storage_id', VALUE) AS metadata,\n",
    "                    country_id                                                     AS country_id,\n",
    "                    0                                                              AS agglomeration_id,\n",
    "                    city_id                                                        AS city_id\n",
    "             FROM grouped),\n",
    "     mc AS (SELECT user_id\n",
    "            FROM `indriver-e6e40.ods_media_checker.entity` AS e\n",
    "            WHERE source_nm LIKE '%{region}%'\n",
    "              AND e.entity_type = 'contractor')\n",
    "SELECT *\n",
    "FROM res\n",
    "WHERE res.user_id NOT IN (SELECT user_id FROM mc)\n",
    "    \"\"\")\n",
    "\n",
    "    print(df_code.shape)\n",
    "    \n",
    "    df_code['metadata'] = df_code['metadata'].astype('str')\n",
    "    df_code = df_code.drop_duplicates()\n",
    "    folder_path = f'/Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD1_migration_to_mediachecker_lost_users/{region}'\n",
    "    # folder_path = f'/Users/renatyunison/Library/CloudStorage/GoogleDrive-renat.yunisov@indriver.com/My Drive/WD2_migration_to_mediachecker_lost_users/{region}'\n",
    "\n",
    "    try:\n",
    "        chunks = np.array_split(df_code, math.ceil(df_code.shape[0]/9000))\n",
    "    \n",
    "        for i, chunk in enumerate(chunks):\n",
    "\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "            file_name = f'{region}-{i}.csv'\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            chunk.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"Files were saved to: {folder_path}\")\n",
    "    except ValueError:\n",
    "        continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
