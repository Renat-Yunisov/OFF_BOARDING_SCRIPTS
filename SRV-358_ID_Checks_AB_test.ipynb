{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434029ef",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02493ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisation\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Data analysis / Data processing\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "from datetime import time, timedelta, datetime\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "# Maths & Stats\n",
    "import math \n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import statsmodels.stats.weightstats as ws\n",
    "from statsmodels.stats.proportion import test_proportions_2indep\n",
    "import AB_library\n",
    "# from ambrosia.designer import Designer\n",
    "# from ambrosia.tester import Tester\n",
    "import expab\n",
    "from statsmodels.stats.power import NormalIndPower\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "from math import ceil\n",
    "\n",
    "# System library\n",
    "import os\n",
    "import ipywidgets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# from itables import init_notebook_mode\n",
    "# init_notebook_mode(all_interactive=True)\n",
    "import openpyxl\n",
    "\n",
    "# Data connection\n",
    "from google.cloud import bigquery\n",
    "bigquery_client = bigquery.Client(project='analytics-dev-333113')\n",
    "\n",
    "\n",
    "# Useful functions\n",
    "def read_bq(query, project='analytics-dev-333113'):\n",
    "    client = bigquery.Client(project=project)\n",
    "    query_job = client.query(query)\n",
    "    result_df = query_job.to_dataframe()\n",
    "    return result_df\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "\n",
    "    html_str = ''\n",
    "    for df in args:\n",
    "        html_str += df.to_html()\n",
    "    display_html(\n",
    "        html_str.replace('table','table style=\"display:inline\"'), \n",
    "        raw=True\n",
    "    )\n",
    "\n",
    "def cycle_sql(start, end, query, weeks=False):\n",
    "    \"\"\"\n",
    "    You have to use {date} in your script to add cycle date into this backets\n",
    "    \"\"\"\n",
    "    date_start = datetime.strptime(start, '%Y-%m-%d')\n",
    "    date_end = datetime.strptime(end, '%Y-%m-%d')\n",
    "\n",
    "    if weeks == False:\n",
    "        daterange = [(date_start + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days)+1)]\n",
    "    else:\n",
    "        daterange = [(date_start + timedelta(weeks=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days//7)+1)] # weeks dividing days by 7\n",
    "\n",
    "    total_df = pd.DataFrame()\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for date in daterange:\n",
    "        counter+=1\n",
    "        print(f\"{counter}) Uploading - {date}:\", datetime.today().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        script = query.format(date = date)\n",
    "        df_cycle = bigquery_client.query(script).to_dataframe()\n",
    "        if df_cycle.empty == True:\n",
    "            print('Dataframe is empty')\n",
    "        total_df = pd.concat([df_cycle, total_df])\n",
    "    return total_df  \n",
    "\n",
    "def writing_excel(name:str, dataset1=None, dataset2=None, dataset3=None, dataset4=None):\n",
    "    with pd.ExcelWriter(f\"{name}.xlsx\") as writer:\n",
    "\n",
    "    # use to_excel function and specify the sheet_name and index \n",
    "    # to store the dataframe in specified sheet\n",
    "\n",
    "        if dataset1 is not None:\n",
    "            if dataset2 is not None:\n",
    "                if dataset3 is not None:\n",
    "                    if dataset4 is not None:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset4.to_excel(writer, sheet_name=f\"4-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                    else:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                else:\n",
    "                    dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "                    dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "            else:\n",
    "                dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                #   index=False\n",
    "                                    )\n",
    "\n",
    "        print('DataFrame is written to Excel File successfully.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eded89",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "73e5cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_benjamini_hochberg(\n",
    "    pvalues: np.ndarray,\n",
    "    alpha: float = 0.05\n",
    "    ) -> np.ndarray:\n",
    "    \"\"\"Apply the Benjamini-Hochberg procedure for multiple hypothesis testing.\"\"\"\n",
    "    m = len(pvalues)\n",
    "    array_alpha = np.arange(1, m + 1) * alpha / m\n",
    "    sorted_pvalue_indexes = np.argsort(pvalues)\n",
    "    res = np.zeros(m)\n",
    "    for idx, pvalue_index in enumerate(sorted_pvalue_indexes):\n",
    "        pvalue = pvalues[pvalue_index]\n",
    "        alpha_ = array_alpha[idx]\n",
    "        if pvalue <= alpha_:\n",
    "            res[pvalue_index] = 1\n",
    "        else:\n",
    "            break\n",
    "    return res.astype(int)\n",
    "\n",
    "# Shapiro-Wilk test & Distributions\n",
    "def check_normality(df, group_column, value_column):\n",
    "    groups = df[group_column].unique()\n",
    "\n",
    "    for group in groups:\n",
    "        group_data = df[df[group_column] == group][value_column].dropna() \n",
    "        stat, p = stats.shapiro(group_data)\n",
    "        print(f'Group {group}: W={stat:.4f}, p-value={p:.4f}')\n",
    "        if p > 0.05:\n",
    "            print(f'Group {group}, Metric: {value_column}: Data is normal distributed')\n",
    "        else:\n",
    "            print(f'Group {group}, Metric: {value_column}: Data is not normal distributed')\n",
    "\n",
    "def plot_distribution(df, group_column, value_column):\n",
    "\n",
    "    groups = df[group_column].unique()\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10), gridspec_kw={'height_ratios': [1, 1.5]})\n",
    "\n",
    "    sns.histplot(data=df, x=value_column, hue=group_column, kde=True, bins=30, alpha=0.4, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title(\"Graph + KDE\")\n",
    "    axes[0, 0].set_xlabel(value_column)\n",
    "    axes[0, 0].set_ylabel(\"Frequence\")\n",
    "\n",
    "    sns.boxplot(data=df, x=group_column, y=value_column, ax=axes[0, 1])\n",
    "    axes[0, 1].set_title(\"Boxplot grouped\")\n",
    "    axes[0, 1].set_xlabel(group_column)\n",
    "    axes[0, 1].set_ylabel(value_column)\n",
    "\n",
    "    sns.histplot(df[df[group_column] == groups[0]][value_column], bins=30, kde=True, color='blue', alpha=0.5, ax=axes[1, 0])\n",
    "    axes[1, 0].set_title(f'Hist for the {groups[0]}')\n",
    "    axes[1, 0].set_xlabel(value_column)\n",
    "    axes[1, 0].set_ylabel(\"frequence\")\n",
    "\n",
    "    sns.histplot(df[df[group_column] == groups[1]][value_column], bins=30, kde=True, color='orange', alpha=0.5, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title(f'Hist for the {groups[1]}')\n",
    "    axes[1, 1].set_xlabel(value_column)\n",
    "    axes[1, 1].set_ylabel(\"Frequence\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Levene's & Bartlet's test\n",
    "def levene(df, indicator, metric):\n",
    "    w_stats, p_value = st.levene(\n",
    "        df[df['group_name'] == 0][indicator], \n",
    "        df[df['group_name'] == 1][indicator],\n",
    "                            center=metric)\n",
    "    \n",
    "    alpha = 0.05\n",
    "    \n",
    "    if p_value > alpha:\n",
    "        print(f\"Variance are from the same population on {metric}\")\n",
    "    else:\n",
    "        print(f\"Variance are from the different population on {metric}\")\n",
    "    \n",
    "# Cohen's D\n",
    "def cohens_d(df, metric):\n",
    "    group1 = df[df['group_name']==1][metric]\n",
    "    group2 = df[df['group_name']==0][metric]\n",
    "    mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "     \n",
    "    std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    pooled_std = np.sqrt(((n1 - 1) * std1 ** 2 + (n2 - 1) * std2 ** 2) / (n1 + n2 - 2))\n",
    "     \n",
    "    d = (mean1 - mean2) / pooled_std\n",
    "     \n",
    "    # if d <= 0.3:\n",
    "    #     print(f'Small effect: d ≈ 0-0.3 ({d:.3f})')\n",
    "    # elif 0.31 <= d <= 0.8:\n",
    "    #     print(f'Medium effect: d ≈ 0.3-0.8 ({d:.3f})')\n",
    "    # elif 0.81 <= d <= 1:\n",
    "    #     print(f'Large effect: d ≈ 0.8-1 ({d:.3f})')\n",
    "\n",
    "    return d\n",
    "\n",
    "# SRM\n",
    "def srm(df):\n",
    "    srm_df = pd.DataFrame()\n",
    "\n",
    "    for city in df['city_name'].unique():\n",
    "        \n",
    "        observed = [\n",
    "            (df.query(f'group_name == 0 and city_name == \"{city}\"')['user_id'].count()), \n",
    "            (df.query(f'group_name == 1 and city_name == \"{city}\"')['user_id'].count())\n",
    "            ]\n",
    "\n",
    "        total_traffic = sum(observed)\n",
    "\n",
    "        expected = [total_traffic/2, total_traffic/2]\n",
    "\n",
    "        chi = st.chisquare(observed, f_exp = expected)\n",
    "\n",
    "        if chi[1] < 0.01:\n",
    "            conclusion = \"Sample ratio mismatch (SRM) may be present\"\n",
    "        else:\n",
    "            conclusion = \"Sample ratio mismatch (SRM) probably not present\"\n",
    "            print(f\"{city}, {chi[1]}\")\n",
    "\n",
    "        \n",
    "        new_srm_df = pd.DataFrame(\n",
    "            [[city, observed, total_traffic, expected, round(chi[1], 3), conclusion]], \n",
    "            columns=['city_name',  'sample_sizes', 'total_size', 'expected_sizes', 'chi_value', 'conclusion']\n",
    "            )\n",
    "\n",
    "        srm_df = pd.concat([srm_df, new_srm_df]).sort_values(['city_name', 'total_size'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return srm_df\n",
    "\n",
    "# Calcualting the significance by cities\n",
    "def calcualate_result(df_cr, df_abs):\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    for city in df_cr['city_name'].unique():\n",
    "\n",
    "        absolute_values_keys_result = df_abs[df_abs['city_name']==f'{city}'].copy()\n",
    "\n",
    "        cr_df = ztest_proportion(df_cr[df_cr['city_name']==f'{city}'], 'has_ride', 'group_name')\n",
    "        cr_df['metric'] = 'Conversion'\n",
    "        cr_df['cohen_d'] = cohens_d(df_cr[df_cr['city_name']==f'{city}'], 'has_ride')\n",
    "\n",
    "        rides_df = ttest(absolute_values_keys_result, 'rides', 'group_name')\n",
    "        rides_df['metric'] = 'Quantitive'\n",
    "        rides_df['cohen_d'] = cohens_d(absolute_values_keys_result, 'rides')\n",
    "\n",
    "        gmv_df = ttest(absolute_values_keys_result, 'gmv', 'group_name')\n",
    "        gmv_df['metric'] = 'Quantitive'\n",
    "        gmv_df['cohen_d'] = cohens_d(absolute_values_keys_result, 'gmv')\n",
    "\n",
    "        orders_df = ttest(absolute_values_keys_result, 'orders', 'group_name')\n",
    "        orders_df['metric'] = 'Quantitive'\n",
    "        orders_df['cohen_d'] = cohens_d(absolute_values_keys_result, 'orders')\n",
    "\n",
    "        df_total = pd.concat([cr_df, rides_df, gmv_df, orders_df])\n",
    "\n",
    "        df_total['region'] = city\n",
    "        df_total['segment'] = 'By city'\n",
    "        df_total['significance'] = (df_total['pvalue']<0.05)*1\n",
    "        df_total['corrected_pvalue'] = method_benjamini_hochberg(df_total['pvalue'].values)\n",
    "\n",
    "        df_results = pd.concat([df_results, df_total])\n",
    "\n",
    "    total_cr_df = ztest_proportion(df_cr, 'has_ride', 'group_name')\n",
    "    total_cr_df['metric'] = 'Conversion'\n",
    "    total_cr_df['cohen_d'] = cohens_d(df_cr, 'has_ride')\n",
    "\n",
    "    total_rides_df = ttest(df_abs, 'rides', 'group_name')\n",
    "    total_rides_df['metric'] = 'Quantitive'\n",
    "    total_rides_df['cohen_d'] = cohens_d(df_abs, 'rides')\n",
    "\n",
    "    total_gmv_df = ttest(df_abs, 'gmv', 'group_name')\n",
    "    total_gmv_df['metric'] = 'Quantitive'\n",
    "    total_gmv_df['cohen_d'] = cohens_d(df_abs, 'gmv')\n",
    "\n",
    "    total_orders_df = ttest(df_abs, 'orders', 'group_name')\n",
    "    total_orders_df['metric'] = 'Quantitive'\n",
    "    total_orders_df['cohen_d'] = cohens_d(df_abs, 'orders')\n",
    "\n",
    "\n",
    "    total_total_df = pd.concat([total_cr_df, total_rides_df, total_gmv_df, total_orders_df])\n",
    "    total_total_df['region'] = 'All'\n",
    "    total_total_df['segment'] = 'Total'\n",
    "    total_total_df['significance'] = (df_total['pvalue']<0.05)*1\n",
    "    total_total_df['corrected_pvalue'] = method_benjamini_hochberg(df_total['pvalue'].values)\n",
    "\n",
    "    df_results = pd.concat([df_results, total_total_df])\n",
    "\n",
    "    df_results\n",
    "\n",
    "    return df_results\n",
    "\n",
    "def sequential_wald_test(df, date_col, metric_col, group_col, user_col, alpha=0.05, beta=0.2):\n",
    "    \n",
    "    A = np.round(np.log(beta / (1 - alpha)), 2)   \n",
    "    B = np.round(np.log((1 - beta) / alpha), 2) \n",
    "    \n",
    "    df_grouped = df.groupby([date_col, group_col]).agg(\n",
    "        users=(user_col, 'nunique'), \n",
    "        conversions=(metric_col, 'sum') \n",
    "    ).reset_index()\n",
    "\n",
    "    df_grouped[\"cum_users\"] = df_grouped.groupby(group_col)[\"users\"].cumsum()\n",
    "    df_grouped[\"cum_conversions\"] = df_grouped.groupby(group_col)[\"conversions\"].cumsum()\n",
    "\n",
    "    df_A = df_grouped[df_grouped[group_col] == 0].drop(columns=[group_col]).rename(\n",
    "        columns={\"users\": \"users_A\", \"conversions\": \"conv_A\", \"cum_users\": \"cum_users_A\", \"cum_conversions\": \"cum_conv_A\"}\n",
    "    )\n",
    "    df_B = df_grouped[df_grouped[group_col] == 1].drop(columns=[group_col]).rename(\n",
    "        columns={\"users\": \"users_B\", \"conversions\": \"conv_B\", \"cum_users\": \"cum_users_B\", \"cum_conversions\": \"cum_conv_B\"}\n",
    "    )\n",
    "\n",
    "    df_merged = pd.merge(df_A, df_B, on=date_col, how=\"outer\").fillna(0)\n",
    "\n",
    "    print(\"Колонки в df_merged:\", df_merged.columns)\n",
    "\n",
    "    p_values, llr_values = [], []\n",
    "    stop_day = None\n",
    "\n",
    "    for i in range(len(df_merged)):\n",
    "        try:\n",
    "            users_A, conv_A = df_merged.loc[i, [\"cum_users_A\", \"cum_conv_A\"]]\n",
    "            users_B, conv_B = df_merged.loc[i, [\"cum_users_B\", \"cum_conv_B\"]]\n",
    "\n",
    "            p_A = conv_A / users_A if users_A > 0 else 0\n",
    "            p_B = conv_B / users_B if users_B > 0 else 0\n",
    "\n",
    "            r = test_proportions_2indep(\n",
    "                conv_A, users_A,\n",
    "                conv_B, users_B,\n",
    "                value=0,\n",
    "                method='wald',\n",
    "                compare='diff',\n",
    "                alternative='two-sided',\n",
    "                return_results=True\n",
    "            )\n",
    "\n",
    "            p_value = r.pvalue\n",
    "            p_values.append(p_value)\n",
    "\n",
    "            llr = np.log(p_B / p_A) if p_B > 0 and p_A > 0 else 0\n",
    "            llr_values.append(llr)\n",
    "\n",
    "            if llr <= A:\n",
    "                stop_day = df_merged.loc[i, date_col]\n",
    "                print(f\"On {stop_day} might be stopped: LLR={llr:.3f} <= {A:.3f} (Accept H0)\")\n",
    "                break\n",
    "            elif llr >= B:\n",
    "                stop_day = df_merged.loc[i, date_col]\n",
    "                print(f\"On {stop_day} might be stopped: LLR={llr:.3f} >= {B:.3f} (Accept H1)\")\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Ошибка на дне {df_merged.loc[i, date_col]}: {e}\")\n",
    "            p_values.append(np.nan)\n",
    "            llr_values.append(np.nan)\n",
    "\n",
    "    # Создаем DataFrame с результатами\n",
    "    df_results = df_merged.iloc[:len(p_values)].copy()\n",
    "    df_results[\"p_value\"] = p_values\n",
    "    df_results[\"LLR\"] = llr_values\n",
    "    df_results[\"A/B\"] = str([A, B])\n",
    "    df_results[\"alpha_threshold\"] = np.linspace(alpha, alpha / np.sqrt(len(df_results)), len(p_values))  # Коррекция alpha\n",
    "\n",
    "    # Визуализация результатов\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df_results[date_col], df_results[\"p_value\"], label=\"P-value\", marker=\"o\")\n",
    "    plt.plot(df_results[date_col], df_results[\"alpha_threshold\"], label=\"Corrected Alpha\", linestyle=\"dashed\")\n",
    "    plt.axhline(y=alpha, color=\"red\", linestyle=\"--\", label=\"Standard Alpha (0.05)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"P-Value\")\n",
    "    plt.title(\"P-value daily vs. Corrected Alpha\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return df_results\n",
    "\n",
    "def calculate_criteria(df):\n",
    "    df_res_1 = pd.DataFrame()\n",
    "    indicators = ['has_ride', 'rides', 'gmv']\n",
    "\n",
    "    total_res_z = expab.ztest_proportion(df, 'has_ride', 'group_name')\n",
    "    total_res_z['city_name'] = 'all the cities together'\n",
    "    total_res_t = expab.ttest(df, 'gmv', 'group_name')\n",
    "    total_res_t['city_name'] = 'all the cities together'\n",
    "    total_res_t2 = expab.ttest(df, 'rides', 'group_name')\n",
    "    total_res_t2['city_name'] = 'all the cities together'\n",
    "\n",
    "    df_res_1 = pd.concat([df_res_1, total_res_z, total_res_t, total_res_t2])\n",
    "\n",
    "    for city in df['city_name'].unique():\n",
    "        \n",
    "        for metric in indicators:\n",
    "            if metric == 'has_ride':\n",
    "                city_df_z = expab.ztest_proportion(df.query(f\"city_name == '{city}'\"), metric, 'group_name')\n",
    "                city_df_z['city_name'] = city\n",
    "\n",
    "                df_res_1 = pd.concat([df_res_1, city_df_z])\n",
    "\n",
    "            else:\n",
    "                city_df_t = expab.ttest(df.query(f\"city_name == '{city}'\"), metric, 'group_name')\n",
    "                city_df_t['city_name'] = city\n",
    "\n",
    "                df_res_1 = pd.concat([df_res_1, city_df_t])\n",
    "\n",
    "    df_res_1['corrected_pvalue'] = expab.method_benjamini_hochberg(df_res_1['pvalue'].values)\n",
    "    df_res_1['significance'] = (df_res_1['pvalue']<0.05)*1\n",
    "\n",
    "\n",
    "    return df_res_1\n",
    "\n",
    "def calculate_numbers(df):\n",
    "\n",
    "    df_agg = df.groupby(['group_name', 'city_name'], as_index=False)[['user_id', 'has_ride', 'rides', 'orders', 'gmv']].agg(\n",
    "        {'user_id':'count', \n",
    "        'has_ride':'sum', \n",
    "        'rides':'sum', \n",
    "        'gmv':'sum'}\n",
    "        ).sort_values(['city_name', 'group_name', 'user_id'], ascending=True)\n",
    "\n",
    "    df_agg['group_name'] = df_agg['group_name'].astype(str)\n",
    "\n",
    "    df_agg['group_name'] = df_agg['group_name'].replace({'0':'Control', '1':'Treatment'})\n",
    "\n",
    "    df_agg['cr_ride_%'] = np.round(df_agg['has_ride'] / df_agg['user_id'] * 100,2)\n",
    "    df_agg['cr_ride'] = np.round(df_agg['has_ride'] / df_agg['user_id'],5)\n",
    "    df_agg['cr_ride_%'] = df_agg['cr_ride_%'].astype(str)\n",
    "    df_agg['cr_ride_%'] = df_agg['cr_ride_%'] + '%'\n",
    "\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca176aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6074f174",
   "metadata": {},
   "source": [
    "# Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7673ddbc",
   "metadata": {},
   "source": [
    "### Test in Colombia, Ecuador, Peru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d626184",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_to_ride = read_bq(\"\"\"\n",
    "WITH newbies AS (SELECT user_id,\n",
    "                        metric_date\n",
    "                 FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "                 WHERE user_type = 'pass'\n",
    "                   AND rides_count > 0\n",
    "                   AND metric_date >= DATE_ADD(CURRENT_DATE(), INTERVAL -1 YEAR)\n",
    "                   AND country_id = 25),\n",
    "     gmv AS (SELECT user_id,\n",
    "                    SUM(gmv_clean_usd) AS gmv,\n",
    "                    SUM(rides_count)   AS rides,\n",
    "                    SUM(orders_count)  AS orders\n",
    "             FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "             WHERE user_type = 'pass'\n",
    "               AND metric_date BETWEEN '2025-04-01' AND DATE_ADD(CURRENT_DATE(), INTERVAL -1 DAY)\n",
    "               AND country_id = 25\n",
    "             GROUP BY 1),\n",
    "     total AS (SELECT t1.user_id,\n",
    "                      t1.city_id,\n",
    "                      geo.city_name,\n",
    "                      geo.country_id,\n",
    "                      geo.country_name,\n",
    "                      IF(group_id = 4540557, 0, 1) AS group_id,\n",
    "                      created_dt_part,\n",
    "                      t2.metric_date,\n",
    "                      CASE\n",
    "                          WHEN t2.metric_date IS NULL THEN 1\n",
    "                          ELSE 0\n",
    "                          END                         newbie_flag\n",
    "               FROM indriver-e6e40.ss_ab_platform_mart.markup_users t1\n",
    "                        JOIN indriver-e6e40.heap.vw_macroregion_mapping geo\n",
    "                             ON\n",
    "                                 t1.city_id = geo.city_id\n",
    "                        LEFT JOIN newbies t2 ON t1.user_id = t2.user_id AND t2.metric_date < t1.created_dt_part\n",
    "               WHERE test_id = 3139\n",
    "               QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY metric_date DESC) = 1),\n",
    "     liveness AS (SELECT user_id,\n",
    "                         os_name,\n",
    "                         city_id,\n",
    "                         city_name,\n",
    "                         country_id,\n",
    "                         country_name,\n",
    "                         COALESCE(filled_flow, 'liveness')                                  AS filled_flow,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.show', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS show_dt,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.click', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS click_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) = 'approve'), client_time, NULL))            AS approve_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) != 'approve'), client_time, NULL))           AS not_approve_dt\n",
    "                  FROM (SELECT t1.user_id,\n",
    "                               t1.name,\n",
    "                               t1.os_name,\n",
    "                               DATE(TIMESTAMP_MILLIS(t1.client_time))                  AS event_dt_part,\n",
    "                               TIMESTAMP_MILLIS(t1.client_time)                        AS client_time,\n",
    "                               t1.city_id,\n",
    "                               t2.city_name,\n",
    "                               t2.country_id,\n",
    "                               t2.country_name,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.verification_flow')     AS verification_flow,\n",
    "                               IF(JSON_EXTRACT_SCALAR(payload, '$.verification_flow') IS NULL,\n",
    "                                  LAG(JSON_EXTRACT_SCALAR(payload, '$.verification_flow'))\n",
    "                                      OVER (PARTITION BY t1.user_id ORDER BY client_time),\n",
    "                                  JSON_EXTRACT_SCALAR(payload, '$.verification_flow')) AS filled_flow,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.status')                AS status\n",
    "                        FROM (SELECT *\n",
    "                              FROM indriver-e6e40.emart.product_event t1\n",
    "                              WHERE 1 = 1\n",
    "                                AND name IN (\n",
    "                                             'client.verification_start.show',\n",
    "                                             'client.verification_start.click',\n",
    "                                             'client.verification_flow_result_status.show'\n",
    "                                  )\n",
    "                                AND event_dt_part BETWEEN '2025-04-01' AND DATE_ADD(CURRENT_DATE(), INTERVAL -1 DAY)\n",
    "                                AND city_id IN (4231, 4242, 4226, 4255, 4278)\n",
    "                              QUALIFY\n",
    "                                  ROW_NUMBER() OVER (PARTITION BY user_id, name, os_name, event_dt_part, JSON_EXTRACT_SCALAR(payload, '$.verification_flow') ORDER BY client_time DESC) =\n",
    "                                  1) t1\n",
    "                                 JOIN indriver-e6e40.heap.vw_macroregion_mapping t2\n",
    "                                      ON\n",
    "                                          t1.city_id = t2.city_id\n",
    "                        WHERE 1 = 1\n",
    "                          AND name IN (\n",
    "                                       'client.verification_start.show', 'client.verification_start.click',\n",
    "                                       'client.verification_flow_result_status.show'\n",
    "                            ))\n",
    "                  GROUP BY 1, 2, 3, 4, 5, 6, 7),\n",
    "     total_liv AS (SELECT t1.user_id,\n",
    "                          CASE\n",
    "                              WHEN t2.metric_date IS NULL THEN 1\n",
    "                              ELSE 0\n",
    "                              END newbie_flag,\n",
    "                          t1.os_name,\n",
    "                          t1.city_id,\n",
    "                          t1.city_name,\n",
    "                          t1.country_id,\n",
    "                          t1.country_name,\n",
    "                          t1.filled_flow,\n",
    "                          t1.show_dt,\n",
    "                          t1.click_dt,\n",
    "                          t1.approve_dt,\n",
    "                          t1.not_approve_dt\n",
    "                   FROM liveness t1\n",
    "                            LEFT JOIN newbies t2 ON t1.user_id = t2.user_id AND t2.metric_date < DATE(t1.show_dt)\n",
    "                   QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY t2.metric_date DESC) = 1),\n",
    "     rides AS (SELECT order_uuid,\n",
    "                      user_id    AS pass_id,\n",
    "                      driver_id,\n",
    "                      city_id    AS order_city_id,\n",
    "                      country_id AS order_country_id,\n",
    "                      status_order,\n",
    "                      order_timestamp,\n",
    "                      at_pickup_dttm,\n",
    "                      departed_pickup_dttm,\n",
    "                      at_destination_dttm,\n",
    "                      departed_destination_dttm,\n",
    "                      driveraccept_timestamp,\n",
    "                      driverarrived_timestamp,\n",
    "                      driverstarttheride_timestamp,\n",
    "                      driverdone_timestamp,\n",
    "                      clientdone_timestamp,\n",
    "                      clientcancel_timestamp,\n",
    "                      drivercancel_timestamp,\n",
    "                      user_reg_date,\n",
    "                      driver_reg_date,\n",
    "                      stage,\n",
    "                      created_date_order_part,\n",
    "                      duration_in_seconds\n",
    "               FROM indriver-e6e40.imart.incity_detail_new_order\n",
    "               WHERE created_date_order_part BETWEEN '2025-04-01'\n",
    "                   AND DATE_ADD(CURRENT_DATE(), INTERVAL -1 DAY)\n",
    "                 AND status_order = 'RIDE_STATUS_DONE'\n",
    "                 AND driveraccept_timestamp IS NOT NULL\n",
    "                 AND (clientcancel_timestamp IS NULL\n",
    "                   AND drivercancel_timestamp IS NULL))\n",
    "SELECT t1.user_id,\n",
    "       t1.os_name,\n",
    "       t1.city_id,\n",
    "       t1.city_name,\n",
    "       t1.country_id,\n",
    "       t1.country_name,\n",
    "       t1.newbie_flag,\n",
    "       filled_flow,\n",
    "       show_dt,\n",
    "       click_dt,\n",
    "       COALESCE(approve_dt, t2.order_timestamp)                    AS approve_dt,\n",
    "       IF(approve_dt IS NOT NULL, 1, 0)                            AS approve_flag,\n",
    "       not_approve_dt,\n",
    "       IF(not_approve_dt IS NOT NULL AND approve_dt IS NULL, 1, 0) AS not_approve_flag,\n",
    "       t2.order_timestamp,\n",
    "       IF(t2.order_timestamp IS NOT NULL, 1, 0)                    AS order_flag,\n",
    "       t3.gmv,\n",
    "       t3.rides,\n",
    "       t3.orders\n",
    "FROM total_liv t1\n",
    "         LEFT JOIN rides t2\n",
    "                   ON t1.user_id = t2.pass_id AND\n",
    "                      t2.created_date_order_part BETWEEN DATE(show_dt) AND DATE_ADD(DATE(show_dt), INTERVAL +3 DAY)\n",
    "         LEFT JOIN gmv t3 ON t1.user_id = t3.user_id\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY t2.order_timestamp) = 1\n",
    "\"\"\")\n",
    "\n",
    "# CR to order upon check\n",
    "\n",
    "cr_to_order = read_bq(\"\"\"\n",
    "WITH newbies AS (SELECT user_id,\n",
    "                        metric_date\n",
    "                 FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "                 WHERE user_type = 'pass'\n",
    "                   AND rides_count > 0\n",
    "                   AND metric_date >= DATE_ADD(CURRENT_DATE(), INTERVAL -1 YEAR)\n",
    "                   AND country_id = 25),\n",
    "     gmv AS (SELECT user_id,\n",
    "                    SUM(gmv_clean_usd) AS gmv,\n",
    "                    SUM(rides_count)   AS rides,\n",
    "                    SUM(orders_count)  AS orders\n",
    "             FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "             WHERE user_type = 'pass'\n",
    "               AND metric_date BETWEEN '2025-04-01' AND DATE_ADD(CURRENT_DATE(), INTERVAL -1 DAY)\n",
    "               AND country_id = 25\n",
    "             GROUP BY 1),\n",
    "     total AS (SELECT t1.user_id,\n",
    "                      t1.city_id,\n",
    "                      geo.city_name,\n",
    "                      geo.country_id,\n",
    "                      geo.country_name,\n",
    "                      IF(group_id = 4540557, 0, 1) AS group_id,\n",
    "                      created_dt_part,\n",
    "                      t2.metric_date,\n",
    "                      CASE\n",
    "                          WHEN t2.metric_date IS NULL THEN 1\n",
    "                          ELSE 0\n",
    "                          END                         newbie_flag\n",
    "               FROM indriver-e6e40.ss_ab_platform_mart.markup_users t1\n",
    "                        JOIN indriver-e6e40.heap.vw_macroregion_mapping geo\n",
    "                             ON\n",
    "                                 t1.city_id = geo.city_id\n",
    "                        LEFT JOIN newbies t2 ON t1.user_id = t2.user_id AND t2.metric_date < t1.created_dt_part\n",
    "               WHERE test_id = 3139\n",
    "               QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY metric_date DESC) = 1),\n",
    "     liveness AS (SELECT user_id,\n",
    "                         os_name,\n",
    "                         city_id,\n",
    "                         city_name,\n",
    "                         country_id,\n",
    "                         country_name,\n",
    "                         COALESCE(filled_flow, 'liveness')                                  AS filled_flow,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.show', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS show_dt,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.click', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS click_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) = 'approve'), client_time, NULL))            AS approve_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) != 'approve'), client_time, NULL))           AS not_approve_dt\n",
    "                  FROM (SELECT t1.user_id,\n",
    "                               t1.name,\n",
    "                               t1.os_name,\n",
    "                               DATE(TIMESTAMP_MILLIS(t1.client_time))                  AS event_dt_part,\n",
    "                               TIMESTAMP_MILLIS(t1.client_time)                        AS client_time,\n",
    "                               t1.city_id,\n",
    "                               t2.city_name,\n",
    "                               t2.country_id,\n",
    "                               t2.country_name,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.verification_flow')     AS verification_flow,\n",
    "                               IF(JSON_EXTRACT_SCALAR(payload, '$.verification_flow') IS NULL,\n",
    "                                  LAG(JSON_EXTRACT_SCALAR(payload, '$.verification_flow'))\n",
    "                                      OVER (PARTITION BY t1.user_id ORDER BY client_time),\n",
    "                                  JSON_EXTRACT_SCALAR(payload, '$.verification_flow')) AS filled_flow,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.status')                AS status\n",
    "                        FROM (SELECT *\n",
    "                              FROM indriver-e6e40.emart.product_event t1\n",
    "                              WHERE 1 = 1\n",
    "                                AND name IN (\n",
    "                                             'client.verification_start.show',\n",
    "                                             'client.verification_start.click',\n",
    "                                             'client.verification_flow_result_status.show'\n",
    "                                  )\n",
    "                                AND event_dt_part BETWEEN '2025-04-01' AND DATE_ADD(CURRENT_DATE(), INTERVAL -1 DAY)\n",
    "                                AND city_id IN (4231, 4242, 4226, 4255, 4278)\n",
    "                              QUALIFY\n",
    "                                  ROW_NUMBER() OVER (PARTITION BY user_id, name, os_name, event_dt_part, JSON_EXTRACT_SCALAR(payload, '$.verification_flow') ORDER BY client_time DESC) =\n",
    "                                  1) t1\n",
    "                                 JOIN indriver-e6e40.heap.vw_macroregion_mapping t2\n",
    "                                      ON\n",
    "                                          t1.city_id = t2.city_id\n",
    "                        WHERE 1 = 1\n",
    "                          AND name IN (\n",
    "                                       'client.verification_start.show', 'client.verification_start.click',\n",
    "                                       'client.verification_flow_result_status.show'\n",
    "                            ))\n",
    "                  GROUP BY 1, 2, 3, 4, 5, 6, 7),\n",
    "     total_liv AS (SELECT t1.user_id,\n",
    "                          CASE\n",
    "                              WHEN t2.metric_date IS NULL THEN 1\n",
    "                              ELSE 0\n",
    "                              END newbie_flag,\n",
    "                          t1.os_name,\n",
    "                          t1.city_id,\n",
    "                          t1.city_name,\n",
    "                          t1.country_id,\n",
    "                          t1.country_name,\n",
    "                          t1.filled_flow,\n",
    "                          t1.show_dt,\n",
    "                          t1.click_dt,\n",
    "                          t1.approve_dt,\n",
    "                          t1.not_approve_dt\n",
    "                   FROM liveness t1\n",
    "                            LEFT JOIN newbies t2 ON t1.user_id = t2.user_id AND t2.metric_date < DATE(t1.show_dt)\n",
    "                   QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY t2.metric_date DESC) = 1),\n",
    "     rides AS (SELECT order_uuid,\n",
    "                      user_id    AS pass_id,\n",
    "                      driver_id,\n",
    "                      city_id    AS order_city_id,\n",
    "                      country_id AS order_country_id,\n",
    "                      status_order,\n",
    "                      order_timestamp,\n",
    "                      at_pickup_dttm,\n",
    "                      departed_pickup_dttm,\n",
    "                      at_destination_dttm,\n",
    "                      departed_destination_dttm,\n",
    "                      driveraccept_timestamp,\n",
    "                      driverarrived_timestamp,\n",
    "                      driverstarttheride_timestamp,\n",
    "                      driverdone_timestamp,\n",
    "                      clientdone_timestamp,\n",
    "                      clientcancel_timestamp,\n",
    "                      drivercancel_timestamp,\n",
    "                      user_reg_date,\n",
    "                      driver_reg_date,\n",
    "                      stage,\n",
    "                      created_date_order_part,\n",
    "                      duration_in_seconds\n",
    "               FROM indriver-e6e40.imart.incity_detail_new_order\n",
    "               WHERE created_date_order_part BETWEEN '2025-04-01'\n",
    "                         AND DATE_ADD(CURRENT_DATE(), INTERVAL -1 DAY))\n",
    "SELECT t1.user_id,\n",
    "       t1.os_name,\n",
    "       t1.city_id,\n",
    "       t1.city_name,\n",
    "       t1.country_id,\n",
    "       t1.country_name,\n",
    "       t1.newbie_flag,\n",
    "       filled_flow,\n",
    "       show_dt,\n",
    "       click_dt,\n",
    "       COALESCE(approve_dt, t2.order_timestamp)                    AS approve_dt,\n",
    "       IF(approve_dt IS NOT NULL, 1, 0)                            AS approve_flag,\n",
    "       not_approve_dt,\n",
    "       IF(not_approve_dt IS NOT NULL AND approve_dt IS NULL, 1, 0) AS not_approve_flag,\n",
    "       t2.order_timestamp,\n",
    "       IF(t2.order_timestamp IS NOT NULL, 1, 0)                    AS order_flag,\n",
    "       t3.gmv,\n",
    "       t3.rides,\n",
    "       t3.orders\n",
    "FROM total_liv t1\n",
    "         LEFT JOIN rides t2\n",
    "                   ON t1.user_id = t2.pass_id AND\n",
    "                      t2.created_date_order_part BETWEEN DATE(show_dt) AND DATE_ADD(DATE(show_dt), INTERVAL +3 DAY)\n",
    "         LEFT JOIN gmv t3 ON t1.user_id = t3.user_id\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY t2.order_timestamp) = 1\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b706e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_size_id = read_bq(\"\"\"\n",
    "  SELECT name,\n",
    "       event_dt_part,\n",
    "       DATE_TRUNC(event_dt_part, WEEK)  AS weekly,\n",
    "       DATE_TRUNC(event_dt_part, MONTH) AS monthly,\n",
    "       t1.city_id,\n",
    "       t2.city_name,\n",
    "       t2.country_id,\n",
    "       t2.country_name,\n",
    "       COUNT(DISTINCT user_id)          AS users\n",
    "FROM indriver-e6e40.ods_event_tracker.event t1\n",
    "         JOIN indriver-e6e40.heap.vw_macroregion_mapping t2\n",
    "              ON\n",
    "                  t1.city_id = t2.city_id\n",
    "WHERE 1 = 1\n",
    "  AND name IN (\n",
    "    'client.verification_start.click'\n",
    "    )\n",
    "  AND event_dt_part >= '2025-04-01'\n",
    "  AND t1.city_id IN\n",
    "      (4231, 4242, 4226, 4255, 4278)\n",
    "GROUP BY 1, 2, 3, 4, 5, 6, 7, 8\n",
    "\"\"\")\n",
    "\n",
    "df_sample_size_id['event_dt_part'] = pd.to_datetime(df_sample_size_id['event_dt_part'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2213c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_to_ride_newbies = cr_to_ride[cr_to_ride['newbie_flag']==1].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3397e59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "approve_flag       0.82\n",
       "not_approve_flag   0.01\n",
       "order_flag         0.57\n",
       "dtype: Float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_to_ride_newbies[['approve_flag', 'not_approve_flag', 'order_flag']].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b28ab07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Errors (α, β)</th>\n",
       "      <th>N_Total</th>\n",
       "      <th>Allocation_Ratio</th>\n",
       "      <th>Group sizes</th>\n",
       "      <th>MDE_Absolute</th>\n",
       "      <th>MDE_Relative_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.01; 0.2)</td>\n",
       "      <td>44784</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 40305; Test: 4479</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.05; 0.2)</td>\n",
       "      <td>44784</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 40305; Test: 4479</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.01; 0.2)</td>\n",
       "      <td>89568</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 80611; Test: 8957</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.05; 0.2)</td>\n",
       "      <td>89568</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 80611; Test: 8957</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.01; 0.2)</td>\n",
       "      <td>179139</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 161225; Test: 17914</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.05; 0.2)</td>\n",
       "      <td>179139</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>Control: 161225; Test: 17914</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Errors (α, β)  N_Total Allocation_Ratio                   Group sizes  MDE_Absolute  MDE_Relative_Percentage\n",
       "0   (0.01; 0.2)    44784       (0.9, 0.1)    Control: 40305; Test: 4479          0.03                     4.65\n",
       "1   (0.05; 0.2)    44784       (0.9, 0.1)    Control: 40305; Test: 4479          0.02                     3.82\n",
       "2   (0.01; 0.2)    89568       (0.9, 0.1)    Control: 80611; Test: 8957          0.02                     3.30\n",
       "3   (0.05; 0.2)    89568       (0.9, 0.1)    Control: 80611; Test: 8957          0.02                     2.70\n",
       "4   (0.01; 0.2)   179139       (0.9, 0.1)  Control: 161225; Test: 17914          0.01                     2.33\n",
       "5   (0.05; 0.2)   179139       (0.9, 0.1)  Control: 161225; Test: 17914          0.01                     1.91"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "daily = df_sample_size_id.groupby(['event_dt_part'], as_index=False)['users'].sum()['users'].mean().round(0)*0.5\n",
    "weekly = df_sample_size_id.groupby(['weekly'], as_index=False)['users'].sum()['users'].mean().round(0)*0.5\n",
    "month = df_sample_size_id.groupby(['monthly'], as_index=False)['users'].sum()['users'].mean().round(0)*0.5\n",
    "\n",
    "effects = [1.01, 1.015, 1.05, 1.1]  # MDE in percents\n",
    "sizes = [int(daily), int(weekly), int(weekly)*2, int(month)]  # Size of each group\n",
    "first_type_errors = [0.01, 0.05]\n",
    "second_type_errors = [0.1, 0.2]\n",
    "\n",
    "\n",
    "def calculate_mde_unequal_split(\n",
    "    baseline_conversion_rate: float,\n",
    "    alpha: float = 0.05,\n",
    "    power: float = 0.8,\n",
    "    n_total: int = None,\n",
    "    allocation_ratio: tuple = (0.5, 0.5) # Соотношение (контроль, тест), например (0.7, 0.3)\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Рассчитывает MDE (минимально обнаруживаемый эффект) для A/B-теста\n",
    "    с неравномерным распределением групп.\n",
    "\n",
    "    Args:\n",
    "        baseline_conversion_rate (float): Базовая конверсия контрольной группы (от 0 до 1).\n",
    "        alpha (float): Уровень значимости (ошибка I рода), по умолчанию 0.05.\n",
    "        power (float): Статистическая мощность (1 - ошибка II рода), по умолчанию 0.8.\n",
    "        n_total (int): Общий размер выборки для обеих групп.\n",
    "                       Если не указан, функция вернет ошибку, так как MDE зависит от размера выборки.\n",
    "        allocation_ratio (tuple): Кортеж, представляющий соотношение распределения\n",
    "                                  (доля контрольной группы, доля тестовой группы).\n",
    "                                  Сумма долей должна быть равна 1.0.\n",
    "                                  По умолчанию (0.5, 0.5) - равномерное распределение.\n",
    "\n",
    "    Returns:\n",
    "        dict: Словарь, содержащий рассчитанный MDE (абсолютный и относительный),\n",
    "              а также размеры групп и другие параметры.\n",
    "              Возвращает None, если n_total не указан.\n",
    "    \"\"\"\n",
    "    if n_total is None:\n",
    "        return {\"error\": \"Для расчета MDE необходимо указать общий размер выборки (n_total).\"}\n",
    "\n",
    "    if not (0 < baseline_conversion_rate < 1):\n",
    "        raise ValueError(\"Базовая конверсия должна быть между 0 и 1.\")\n",
    "    if not (0 < alpha < 1):\n",
    "        raise ValueError(\"Уровень значимости (альфа) должен быть между 0 и 1.\")\n",
    "    if not (0 < power < 1):\n",
    "        raise ValueError(\"Мощность должна быть между 0 и 1.\")\n",
    "    if not (np.isclose(sum(allocation_ratio), 1.0) and all(r > 0 for r in allocation_ratio)):\n",
    "        raise ValueError(\"Соотношение распределения должно быть кортежем положительных чисел, сумма которых равна 1.0.\")\n",
    "\n",
    "    # Разделяем общий размер выборки согласно соотношению\n",
    "    n_control = ceil(n_total * allocation_ratio[0])\n",
    "    n_variant = ceil(n_total * allocation_ratio[1])\n",
    "\n",
    "    # Убедимся, что n_control + n_variant не превышает n_total (из-за округления ceil)\n",
    "    # и корректируем, если это так\n",
    "    if n_control + n_variant > n_total:\n",
    "        if allocation_ratio[0] > allocation_ratio[1]:\n",
    "            n_control = n_total - n_variant\n",
    "        else:\n",
    "            n_variant = n_total - n_control\n",
    "    \n",
    "    # Если одна из групп слишком мала после округления, убедимся, что она не 0\n",
    "    if n_control == 0:\n",
    "        n_control = 1\n",
    "        n_variant = n_total - 1\n",
    "    if n_variant == 0:\n",
    "        n_variant = 1\n",
    "        n_control = n_total - 1\n",
    "    \n",
    "    # Рассчитываем отношение размеров групп для NormalIndPower\n",
    "    # NormalIndPower ожидает nobs1 (размер первой группы) и ratio (nobs2 / nobs1)\n",
    "    # Мы используем n_control как nobs1, а n_variant как nobs2\n",
    "    ratio_nobs = n_variant / n_control if n_control > 0 else 1 # Избегаем деления на ноль\n",
    "\n",
    "    # Создаем объект для расчета мощности\n",
    "    power_calculator = NormalIndPower()\n",
    "\n",
    "    # Находим размер эффекта (Cohen's h)\n",
    "    # solve_power возвращает effect_size, если остальные параметры заданы\n",
    "    effect_size_cohen_h = power_calculator.solve_power(\n",
    "        effect_size=None,\n",
    "        nobs1=n_control,\n",
    "        alpha=alpha,\n",
    "        power=power,\n",
    "        ratio=ratio_nobs,\n",
    "        alternative='two-sided' # Двусторонний тест (обнаруживаем как увеличение, так и уменьшение)\n",
    "    )\n",
    "\n",
    "    # Преобразуем Cohen's h обратно в конверсию тестовой группы\n",
    "    # effect_size = 2 * arcsin(sqrt(p2)) - 2 * arcsin(sqrt(p1))\n",
    "    # Мы знаем p1 (baseline_conversion_rate) и effect_size_cohen_h\n",
    "    # Нужно найти p2\n",
    "    arcsin_sqrt_p1 = np.arcsin(np.sqrt(baseline_conversion_rate))\n",
    "    arcsin_sqrt_p2 = arcsin_sqrt_p1 + (effect_size_cohen_h / 2) # Для увеличения\n",
    "    \n",
    "    # Конверсия не может быть больше 1\n",
    "    detectable_conversion_rate_variant = np.sin(arcsin_sqrt_p2)**2\n",
    "    if detectable_conversion_rate_variant > 1:\n",
    "        detectable_conversion_rate_variant = 1.0\n",
    "\n",
    "    # MDE (абсолютная разница)\n",
    "    mde_absolute = detectable_conversion_rate_variant - baseline_conversion_rate\n",
    "\n",
    "    # MDE (относительная разница, в процентах)\n",
    "    mde_relative_percentage = (mde_absolute / baseline_conversion_rate) * 100 if baseline_conversion_rate != 0 else float('inf')\n",
    "\n",
    "    return {\n",
    "        \"baseline_conversion_rate\": baseline_conversion_rate,\n",
    "        \"alpha\": alpha,\n",
    "        \"power\": power,\n",
    "        \"n_total\": n_total,\n",
    "        \"n_control\": int(n_control),\n",
    "        \"n_variant\": int(n_variant),\n",
    "        \"allocation_ratio\": allocation_ratio,\n",
    "        \"effect_size_cohen_h\": effect_size_cohen_h,\n",
    "        \"detectable_conversion_rate_variant\": detectable_conversion_rate_variant,\n",
    "        \"mde_absolute\": mde_absolute,\n",
    "        \"mde_relative_percentage\": mde_relative_percentage\n",
    "    }\n",
    "\n",
    "def analyze_mde_scenarios(\n",
    "    baseline_conversion_rate: float,\n",
    "    alpha_levels: list[float],\n",
    "    power_levels: list[float],\n",
    "    n_total_levels: list[int],\n",
    "    allocation_ratio: tuple = (0.5, 0.5)\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Анализирует MDE для различных сценариев, возвращая результаты в DataFrame.\n",
    "\n",
    "    Args:\n",
    "        baseline_conversion_rate (float): Базовая конверсия контрольной группы (от 0 до 1).\n",
    "        alpha_levels (list[float]): Список уровней значимости (альфа) для тестирования.\n",
    "        power_levels (list[float]): Список уровней статистической мощности для тестирования.\n",
    "        n_total_levels (list[int]): Список общих размеров выборок для тестирования.\n",
    "        allocation_ratio (tuple): Кортеж, представляющий соотношение распределения\n",
    "                                  (доля контрольной группы, доля тестовой группы).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame, содержащий MDE и размеры групп для каждого сценария.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for n_total in n_total_levels:\n",
    "        for alpha in alpha_levels:\n",
    "            for power in power_levels:\n",
    "                beta = 1 - power # Ошибка второго рода\n",
    "                \n",
    "                mde_result = calculate_mde_unequal_split(\n",
    "                    baseline_conversion_rate=baseline_conversion_rate,\n",
    "                    alpha=alpha,\n",
    "                    power=power,\n",
    "                    n_total=n_total,\n",
    "                    allocation_ratio=allocation_ratio\n",
    "                )\n",
    "                \n",
    "                if \"error\" not in mde_result:\n",
    "                    results.append({\n",
    "                        \"Alpha\": alpha,\n",
    "                        \"Beta\": beta,\n",
    "                        \"N_Total\": n_total,\n",
    "                        \"Allocation_Ratio\": allocation_ratio,\n",
    "                        \"N_Control\": mde_result[\"n_control\"],\n",
    "                        \"N_Variant\": mde_result[\"n_variant\"],\n",
    "                        \"MDE_Absolute\": mde_result[\"mde_absolute\"],\n",
    "                        \"MDE_Relative_Percentage\": mde_result[\"mde_relative_percentage\"]\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"Ошибка для N_Total={n_total}, Alpha={alpha}, Power={power}: {mde_result['error']}\")\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Добавляем столбец с форматированной строкой для ошибок\n",
    "    df_results['Errors (α, β)'] = df_results.apply(\n",
    "        lambda row: f\"({row['Alpha']}; {row['Beta']:.1f})\", axis=1\n",
    "    )\n",
    "    \n",
    "    # Добавляем столбец с форматированной строкой для размеров групп\n",
    "    df_results['Group sizes'] = df_results.apply(\n",
    "        lambda row: f\"Control: {row['N_Control']}; Test: {row['N_Variant']}\", axis=1\n",
    "    )\n",
    "\n",
    "    # Переупорядочиваем столбцы для соответствия запрошенному формату\n",
    "    # 'Metric' не является прямым столбцом, это скорее категория.\n",
    "    # Я представлю MDE_Absolute и MDE_Relative_Percentage как отдельные столбцы.\n",
    "    final_columns = [\n",
    "        \"Errors (α, β)\",\n",
    "        \"N_Total\",\n",
    "        \"Allocation_Ratio\",\n",
    "        \"Group sizes\",\n",
    "        \"MDE_Absolute\",\n",
    "        \"MDE_Relative_Percentage\"\n",
    "    ]\n",
    "    \n",
    "    return df_results[final_columns]\n",
    "\n",
    "baseline_cr = 0.57\n",
    "alpha_levels_to_test = [0.01, 0.05]\n",
    "power_levels_to_test = [0.8] \n",
    "n_total_levels_to_test = [int(weekly), int(weekly)*2, int(month)]\n",
    "allocation_ratio_to_test = (0.9, 0.1) \n",
    "\n",
    "mde_analysis_df = analyze_mde_scenarios(\n",
    "    baseline_conversion_rate=baseline_cr,\n",
    "    alpha_levels=alpha_levels_to_test,\n",
    "    power_levels=power_levels_to_test,\n",
    "    n_total_levels=n_total_levels_to_test,\n",
    "    allocation_ratio=allocation_ratio_to_test\n",
    ")\n",
    "\n",
    "mde_analysis_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c8d44",
   "metadata": {},
   "source": [
    "# Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07164972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peru = read_bq(\"\"\"\n",
    "WITH newbies AS (SELECT user_id,\n",
    "                        metric_date\n",
    "                 FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "                 WHERE user_type = 'pass'\n",
    "                   AND rides_count > 0\n",
    "                   AND metric_date >= DATE_ADD(CURRENT_DATE(), INTERVAL -1 YEAR)\n",
    "                   AND country_id = 24),\n",
    "     gmv AS (SELECT user_id,\n",
    "                    SUM(gmv_clean_usd) AS gmv,\n",
    "                    SUM(rides_count)   AS rides,\n",
    "                    SUM(orders_count)  AS orders\n",
    "             FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "             WHERE user_type = 'pass'\n",
    "               AND metric_date BETWEEN '2025-04-01' AND CURRENT_DATE()\n",
    "               AND country_id = 24\n",
    "             GROUP BY 1),\n",
    "     total AS (SELECT t1.user_id,\n",
    "                      t1.city_id,\n",
    "                      geo.city_name,\n",
    "                      geo.country_id,\n",
    "                      geo.country_name,\n",
    "                      IF(group_id = 4541490, 0, 1) AS group_id,\n",
    "                      created_dt_part,\n",
    "                      t2.metric_date,\n",
    "                      CASE\n",
    "                          WHEN t2.metric_date IS NULL THEN 1\n",
    "                          ELSE 0\n",
    "                          END                         newbie_flag\n",
    "               FROM indriver-e6e40.ss_ab_platform_mart.markup_users t1\n",
    "                        JOIN indriver-e6e40.heap.vw_macroregion_mapping geo\n",
    "                             ON\n",
    "                                 t1.city_id = geo.city_id\n",
    "                        LEFT JOIN newbies t2 ON t1.user_id = t2.user_id AND t2.metric_date < t1.created_dt_part\n",
    "               WHERE test_id = 3206\n",
    "               QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY metric_date DESC) = 1),\n",
    "     liveness AS (SELECT user_id,\n",
    "                         os_name,\n",
    "                         city_id,\n",
    "                         city_name,\n",
    "                         country_id,\n",
    "                         country_name,\n",
    "                         COALESCE(filled_flow, 'liveness')                                  AS filled_flow,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.show', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS show_dt,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.click', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS click_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) = 'approve'), client_time, NULL))            AS approve_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) != 'approve'), client_time, NULL))           AS not_approve_dt\n",
    "                  FROM (SELECT t1.user_id,\n",
    "                               t1.name,\n",
    "                               t1.os_name,\n",
    "                               DATE(TIMESTAMP_MILLIS(t1.client_time))                  AS event_dt_part,\n",
    "                               TIMESTAMP_MILLIS(t1.client_time)                        AS client_time,\n",
    "                               t1.city_id,\n",
    "                               t2.city_name,\n",
    "                               t2.country_id,\n",
    "                               t2.country_name,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.verification_flow')     AS verification_flow,\n",
    "                               IF(JSON_EXTRACT_SCALAR(payload, '$.verification_flow') IS NULL,\n",
    "                                  LAG(JSON_EXTRACT_SCALAR(payload, '$.verification_flow'))\n",
    "                                      OVER (PARTITION BY t1.user_id ORDER BY client_time),\n",
    "                                  JSON_EXTRACT_SCALAR(payload, '$.verification_flow')) AS filled_flow,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.status')                AS status\n",
    "                        FROM (SELECT *\n",
    "                              FROM indriver-e6e40.emart.product_event t1\n",
    "                              WHERE 1 = 1\n",
    "                                AND name IN (\n",
    "                                             'client.verification_start.show',\n",
    "                                             'client.verification_start.click',\n",
    "                                             'client.verification_flow_result_status.show'\n",
    "                                  )\n",
    "                                AND event_dt_part BETWEEN '2025-05-01' AND CURRENT_DATE()\n",
    "                                AND country_id IN (24)\n",
    "                              QUALIFY\n",
    "                                  ROW_NUMBER() OVER (PARTITION BY user_id, name, os_name, event_dt_part, JSON_EXTRACT_SCALAR(payload, '$.verification_flow') ORDER BY client_time DESC) =\n",
    "                                  1) t1\n",
    "                                 JOIN indriver-e6e40.heap.vw_macroregion_mapping t2\n",
    "                                      ON\n",
    "                                          t1.city_id = t2.city_id\n",
    "                        WHERE 1 = 1\n",
    "                          AND name IN (\n",
    "                                       'client.verification_start.show', 'client.verification_start.click',\n",
    "                                       'client.verification_flow_result_status.show'\n",
    "                            ))\n",
    "                  GROUP BY 1, 2, 3, 4, 5, 6, 7),\n",
    "     total_liv AS (SELECT t1.user_id,\n",
    "                          t1.city_id,\n",
    "                          t1.city_name,\n",
    "                          t1.country_id,\n",
    "                          t1.country_name,\n",
    "                          t1.group_id,\n",
    "                          t1.created_dt_part,\n",
    "                          t1.newbie_flag,\n",
    "                          t2.user_id AS user_with_svf,\n",
    "                          t2.os_name,\n",
    "                          t2.filled_flow,\n",
    "                          t2.show_dt,\n",
    "                          t2.click_dt,\n",
    "                          t2.approve_dt,\n",
    "                          t2.not_approve_dt\n",
    "                   FROM total t1\n",
    "                            JOIN liveness t2\n",
    "                                 ON t1.user_id = t2.user_id AND DATE(t2.show_dt) >= t1.created_dt_part),\n",
    "     rides AS (SELECT order_uuid,\n",
    "                      user_id    AS pass_id,\n",
    "                      driver_id,\n",
    "                      city_id    AS order_city_id,\n",
    "                      country_id AS order_country_id,\n",
    "                      status_order,\n",
    "                      order_timestamp,\n",
    "                      at_pickup_dttm,\n",
    "                      departed_pickup_dttm,\n",
    "                      at_destination_dttm,\n",
    "                      departed_destination_dttm,\n",
    "                      driveraccept_timestamp,\n",
    "                      driverarrived_timestamp,\n",
    "                      driverstarttheride_timestamp,\n",
    "                      driverdone_timestamp,\n",
    "                      clientdone_timestamp,\n",
    "                      clientcancel_timestamp,\n",
    "                      drivercancel_timestamp,\n",
    "                      user_reg_date,\n",
    "                      driver_reg_date,\n",
    "                      stage,\n",
    "                      created_date_order_part,\n",
    "                      duration_in_seconds\n",
    "               FROM indriver-e6e40.imart.incity_detail_new_order\n",
    "               WHERE created_date_order_part BETWEEN '2025-05-01'\n",
    "                   AND CURRENT_DATE()\n",
    "                 AND status_order = 'RIDE_STATUS_DONE'\n",
    "                 AND driveraccept_timestamp IS NOT NULL\n",
    "                 AND (clientcancel_timestamp IS NULL\n",
    "                   AND drivercancel_timestamp IS NULL))\n",
    "SELECT t1.user_id,\n",
    "       t1.group_id,\n",
    "       t1.created_dt_part,\n",
    "       t1.os_name,\n",
    "       t1.city_id,\n",
    "       t1.city_name,\n",
    "       t1.country_id,\n",
    "       t1.country_name,\n",
    "       t1.newbie_flag,\n",
    "       filled_flow,\n",
    "       show_dt,\n",
    "       click_dt,\n",
    "       approve_dt                                                  AS approve_dt,\n",
    "       IF(approve_dt IS NOT NULL, 1, 0)                            AS approve_flag,\n",
    "       not_approve_dt,\n",
    "       IF(not_approve_dt IS NOT NULL AND approve_dt IS NULL, 1, 0) AS not_approve_flag,\n",
    "       t2.order_timestamp,\n",
    "       IF(t2.order_timestamp IS NOT NULL, 1, 0)                    AS order_flag,\n",
    "       t3.gmv,\n",
    "       t3.rides,\n",
    "       t3.orders\n",
    "FROM total_liv t1\n",
    "         LEFT JOIN rides t2\n",
    "                   ON t1.user_id = t2.pass_id AND\n",
    "                      t2.created_date_order_part >= created_dt_part\n",
    "         LEFT JOIN gmv t3 ON t1.user_id = t3.user_id\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY t2.order_timestamp) = 1\n",
    "\"\"\")\n",
    "\n",
    "df_colombia = read_bq(\"\"\"\n",
    "WITH newbies AS (SELECT user_id,\n",
    "                        metric_date\n",
    "                 FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "                 WHERE user_type = 'pass'\n",
    "                   AND rides_count > 0\n",
    "                   AND metric_date >= DATE_ADD(CURRENT_DATE(), INTERVAL -1 YEAR)\n",
    "                   AND country_id = 22),\n",
    "     gmv AS (SELECT user_id,\n",
    "                    SUM(gmv_clean_usd) AS gmv,\n",
    "                    SUM(rides_count)   AS rides,\n",
    "                    SUM(orders_count)  AS orders\n",
    "             FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "             WHERE user_type = 'pass'\n",
    "               AND metric_date BETWEEN '2025-05-01' AND CURRENT_DATE()\n",
    "               AND country_id = 22\n",
    "             GROUP BY 1),\n",
    "     total AS (SELECT t1.user_id,\n",
    "                      t1.city_id,\n",
    "                      geo.city_name,\n",
    "                      geo.country_id,\n",
    "                      geo.country_name,\n",
    "                      IF(group_id = 4541552, 0, 1) AS group_id,\n",
    "                      created_dt_part,\n",
    "                      t2.metric_date,\n",
    "                      CASE\n",
    "                          WHEN t2.metric_date IS NULL THEN 1\n",
    "                          ELSE 0\n",
    "                          END                         newbie_flag\n",
    "               FROM indriver-e6e40.ss_ab_platform_mart.markup_users t1\n",
    "                        JOIN indriver-e6e40.heap.vw_macroregion_mapping geo\n",
    "                             ON\n",
    "                                 t1.city_id = geo.city_id\n",
    "                        LEFT JOIN newbies t2 ON t1.user_id = t2.user_id AND t2.metric_date < t1.created_dt_part\n",
    "               WHERE test_id = 3223\n",
    "               QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY metric_date DESC) = 1),\n",
    "     liveness AS (SELECT user_id,\n",
    "                         os_name,\n",
    "                         city_id,\n",
    "                         city_name,\n",
    "                         country_id,\n",
    "                         country_name,\n",
    "                         COALESCE(filled_flow, 'liveness')                                  AS filled_flow,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.show', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS show_dt,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.click', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS click_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) = 'approve'), client_time, NULL))            AS approve_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) != 'approve'), client_time, NULL))           AS not_approve_dt\n",
    "                  FROM (SELECT t1.user_id,\n",
    "                               t1.name,\n",
    "                               t1.os_name,\n",
    "                               DATE(TIMESTAMP_MILLIS(t1.client_time))                  AS event_dt_part,\n",
    "                               TIMESTAMP_MILLIS(t1.client_time)                        AS client_time,\n",
    "                               t1.city_id,\n",
    "                               t2.city_name,\n",
    "                               t2.country_id,\n",
    "                               t2.country_name,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.verification_flow')     AS verification_flow,\n",
    "                               IF(JSON_EXTRACT_SCALAR(payload, '$.verification_flow') IS NULL,\n",
    "                                  LAG(JSON_EXTRACT_SCALAR(payload, '$.verification_flow'))\n",
    "                                      OVER (PARTITION BY t1.user_id ORDER BY client_time),\n",
    "                                  JSON_EXTRACT_SCALAR(payload, '$.verification_flow')) AS filled_flow,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.status')                AS status\n",
    "                        FROM (SELECT *\n",
    "                              FROM indriver-e6e40.emart.product_event t1\n",
    "                              WHERE 1 = 1\n",
    "                                AND name IN (\n",
    "                                             'client.verification_start.show',\n",
    "                                             'client.verification_start.click',\n",
    "                                             'client.verification_flow_result_status.show'\n",
    "                                  )\n",
    "                                AND event_dt_part BETWEEN '2025-05-01' AND CURRENT_DATE()\n",
    "                                AND country_id IN (22)\n",
    "                              QUALIFY\n",
    "                                  ROW_NUMBER() OVER (PARTITION BY user_id, name, os_name, event_dt_part, JSON_EXTRACT_SCALAR(payload, '$.verification_flow') ORDER BY client_time DESC) =\n",
    "                                  1) t1\n",
    "                                 JOIN indriver-e6e40.heap.vw_macroregion_mapping t2\n",
    "                                      ON\n",
    "                                          t1.city_id = t2.city_id\n",
    "                        WHERE 1 = 1\n",
    "                          AND name IN (\n",
    "                                       'client.verification_start.show', 'client.verification_start.click',\n",
    "                                       'client.verification_flow_result_status.show'\n",
    "                            ))\n",
    "                  GROUP BY 1, 2, 3, 4, 5, 6, 7),\n",
    "     total_liv AS (SELECT t1.user_id,\n",
    "                          t1.city_id,\n",
    "                          t1.city_name,\n",
    "                          t1.country_id,\n",
    "                          t1.country_name,\n",
    "                          t1.group_id,\n",
    "                          t1.created_dt_part,\n",
    "                          t1.newbie_flag,\n",
    "                          t2.user_id AS user_with_svf,\n",
    "                          t2.os_name,\n",
    "                          t2.filled_flow,\n",
    "                          t2.show_dt,\n",
    "                          t2.click_dt,\n",
    "                          t2.approve_dt,\n",
    "                          t2.not_approve_dt\n",
    "                   FROM total t1\n",
    "                            JOIN liveness t2\n",
    "                                 ON t1.user_id = t2.user_id AND DATE(t2.show_dt) >= t1.created_dt_part),\n",
    "     rides AS (SELECT order_uuid,\n",
    "                      user_id    AS pass_id,\n",
    "                      driver_id,\n",
    "                      city_id    AS order_city_id,\n",
    "                      country_id AS order_country_id,\n",
    "                      status_order,\n",
    "                      order_timestamp,\n",
    "                      at_pickup_dttm,\n",
    "                      departed_pickup_dttm,\n",
    "                      at_destination_dttm,\n",
    "                      departed_destination_dttm,\n",
    "                      driveraccept_timestamp,\n",
    "                      driverarrived_timestamp,\n",
    "                      driverstarttheride_timestamp,\n",
    "                      driverdone_timestamp,\n",
    "                      clientdone_timestamp,\n",
    "                      clientcancel_timestamp,\n",
    "                      drivercancel_timestamp,\n",
    "                      user_reg_date,\n",
    "                      driver_reg_date,\n",
    "                      stage,\n",
    "                      created_date_order_part,\n",
    "                      duration_in_seconds\n",
    "               FROM indriver-e6e40.imart.incity_detail_new_order\n",
    "               WHERE created_date_order_part BETWEEN '2025-05-01'\n",
    "                   AND CURRENT_DATE()\n",
    "                 AND status_order = 'RIDE_STATUS_DONE'\n",
    "                 AND driveraccept_timestamp IS NOT NULL\n",
    "                 AND (clientcancel_timestamp IS NULL\n",
    "                   AND drivercancel_timestamp IS NULL))\n",
    "SELECT t1.user_id,\n",
    "       t1.group_id,\n",
    "       t1.created_dt_part,\n",
    "       t1.os_name,\n",
    "       t1.city_id,\n",
    "       t1.city_name,\n",
    "       t1.country_id,\n",
    "       t1.country_name,\n",
    "       t1.newbie_flag,\n",
    "       filled_flow,\n",
    "       show_dt,\n",
    "       click_dt,\n",
    "       approve_dt                                                  AS approve_dt,\n",
    "       IF(approve_dt IS NOT NULL, 1, 0)                            AS approve_flag,\n",
    "       not_approve_dt,\n",
    "       IF(not_approve_dt IS NOT NULL AND approve_dt IS NULL, 1, 0) AS not_approve_flag,\n",
    "       t2.order_timestamp,\n",
    "       IF(t2.order_timestamp IS NOT NULL, 1, 0)                    AS order_flag,\n",
    "       t3.gmv,\n",
    "       t3.rides,\n",
    "       t3.orders\n",
    "FROM total_liv t1\n",
    "         LEFT JOIN rides t2\n",
    "                   ON t1.user_id = t2.pass_id AND\n",
    "                      t2.created_date_order_part >= created_dt_part\n",
    "         LEFT JOIN gmv t3 ON t1.user_id = t3.user_id\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY t2.order_timestamp) = 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ff91b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>newbie_flag</th>\n",
       "      <th>show_dt</th>\n",
       "      <th>click_dt</th>\n",
       "      <th>approve_dt</th>\n",
       "      <th>not_approve_dt</th>\n",
       "      <th>order_flag</th>\n",
       "      <th>cr_to_approve</th>\n",
       "      <th>cr_to_ride</th>\n",
       "      <th>cr_to_not_approve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>722</td>\n",
       "      <td>718</td>\n",
       "      <td>655</td>\n",
       "      <td>9</td>\n",
       "      <td>646</td>\n",
       "      <td>91.23</td>\n",
       "      <td>98.63</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1704</td>\n",
       "      <td>1664</td>\n",
       "      <td>1408</td>\n",
       "      <td>5</td>\n",
       "      <td>915</td>\n",
       "      <td>84.62</td>\n",
       "      <td>64.99</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>92.50</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>213</td>\n",
       "      <td>202</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "      <td>83</td>\n",
       "      <td>63.37</td>\n",
       "      <td>64.84</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_id  newbie_flag  show_dt  click_dt  approve_dt  not_approve_dt  order_flag  cr_to_approve  cr_to_ride  cr_to_not_approve\n",
       "0         0            0      722       718         655               9         646          91.23       98.63               1.25\n",
       "1         0            1     1704      1664        1408               5         915          84.62       64.99               0.30\n",
       "2         1            0       80        80          74               1          74          92.50      100.00               1.25\n",
       "3         1            1      213       202         128               6          83          63.37       64.84               2.97"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = df_peru[~df_peru['show_dt'].isna()].groupby(['group_id', 'newbie_flag'], as_index=False)[['show_dt', 'click_dt', 'approve_dt', 'not_approve_dt', 'order_flag']].agg({'show_dt':'count', 'click_dt':'count', 'approve_dt':'count', 'not_approve_dt':'count', 'order_flag':'sum'})\n",
    "\n",
    "df_grouped['cr_to_approve'] = df_grouped['approve_dt'] / df_grouped['click_dt'] * 100\n",
    "df_grouped['cr_to_ride'] = df_grouped['order_flag'] / df_grouped['approve_dt'] * 100\n",
    "df_grouped['cr_to_not_approve'] = df_grouped['not_approve_dt'] / df_grouped['click_dt'] * 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3059df1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6700000000000004"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.97-0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4d37238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>newbie_flag</th>\n",
       "      <th>show_dt</th>\n",
       "      <th>click_dt</th>\n",
       "      <th>approve_dt</th>\n",
       "      <th>not_approve_dt</th>\n",
       "      <th>order_flag</th>\n",
       "      <th>cr_to_approve</th>\n",
       "      <th>cr_to_ride</th>\n",
       "      <th>cr_to_not_approve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54594</td>\n",
       "      <td>53750</td>\n",
       "      <td>41336</td>\n",
       "      <td>1686</td>\n",
       "      <td>30596</td>\n",
       "      <td>76.90</td>\n",
       "      <td>74.02</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14704</td>\n",
       "      <td>14228</td>\n",
       "      <td>11620</td>\n",
       "      <td>116</td>\n",
       "      <td>7577</td>\n",
       "      <td>81.67</td>\n",
       "      <td>65.21</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5950</td>\n",
       "      <td>5821</td>\n",
       "      <td>3162</td>\n",
       "      <td>1556</td>\n",
       "      <td>2098</td>\n",
       "      <td>54.32</td>\n",
       "      <td>66.35</td>\n",
       "      <td>26.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2133</td>\n",
       "      <td>2045</td>\n",
       "      <td>626</td>\n",
       "      <td>525</td>\n",
       "      <td>433</td>\n",
       "      <td>30.61</td>\n",
       "      <td>69.17</td>\n",
       "      <td>25.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_id  newbie_flag  show_dt  click_dt  approve_dt  not_approve_dt  order_flag  cr_to_approve  cr_to_ride  cr_to_not_approve\n",
       "0         0            0    54594     53750       41336            1686       30596          76.90       74.02               3.14\n",
       "1         0            1    14704     14228       11620             116        7577          81.67       65.21               0.82\n",
       "2         1            0     5950      5821        3162            1556        2098          54.32       66.35              26.73\n",
       "3         1            1     2133      2045         626             525         433          30.61       69.17              25.67"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = df_colombia[~df_colombia['show_dt'].isna()].groupby(['group_id', 'newbie_flag'], as_index=False)[['show_dt', 'click_dt', 'approve_dt', 'not_approve_dt', 'order_flag']].agg({'show_dt':'count', 'click_dt':'count', 'approve_dt':'count', 'not_approve_dt':'count', 'order_flag':'sum'})\n",
    "\n",
    "df_grouped['cr_to_approve'] = df_grouped['approve_dt'] / df_grouped['click_dt'] * 100\n",
    "df_grouped['cr_to_ride'] = df_grouped['order_flag'] / df_grouped['approve_dt'] * 100\n",
    "df_grouped['cr_to_not_approve'] = df_grouped['not_approve_dt'] / df_grouped['click_dt'] * 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a15c5",
   "metadata": {},
   "source": [
    "# Summarising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41505fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>created_dt_part</th>\n",
       "      <th>os_name</th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_id</th>\n",
       "      <th>country_name</th>\n",
       "      <th>newbie_flag</th>\n",
       "      <th>filled_flow</th>\n",
       "      <th>show_dt</th>\n",
       "      <th>click_dt</th>\n",
       "      <th>approve_dt</th>\n",
       "      <th>approve_flag</th>\n",
       "      <th>not_approve_dt</th>\n",
       "      <th>not_approve_flag</th>\n",
       "      <th>order_timestamp</th>\n",
       "      <th>order_flag</th>\n",
       "      <th>gmv</th>\n",
       "      <th>rides</th>\n",
       "      <th>orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12587106</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>ios</td>\n",
       "      <td>4272</td>\n",
       "      <td>Chiclayo</td>\n",
       "      <td>24</td>\n",
       "      <td>Peru</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-05-31 14:18:52.214000+00:00</td>\n",
       "      <td>2025-05-31 14:18:57.129000+00:00</td>\n",
       "      <td>2025-05-31 14:19:44.223000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-28 01:46:07+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>72.59</td>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13837432</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>ios</td>\n",
       "      <td>4272</td>\n",
       "      <td>Chiclayo</td>\n",
       "      <td>24</td>\n",
       "      <td>Peru</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-02 08:56:49.763000+00:00</td>\n",
       "      <td>2025-06-02 08:56:51.131000+00:00</td>\n",
       "      <td>2025-06-02 08:57:22.166000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-01 00:38:49+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>101.50</td>\n",
       "      <td>42</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148377114</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>android</td>\n",
       "      <td>4272</td>\n",
       "      <td>Chiclayo</td>\n",
       "      <td>24</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-01 08:22:31.072000+00:00</td>\n",
       "      <td>2025-06-01 08:22:32.725000+00:00</td>\n",
       "      <td>2025-06-01 08:23:14.108000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-01 08:23:17+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169355421</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>ios</td>\n",
       "      <td>4272</td>\n",
       "      <td>Chiclayo</td>\n",
       "      <td>24</td>\n",
       "      <td>Peru</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-01 23:23:14.911000+00:00</td>\n",
       "      <td>2025-06-01 23:23:16.460000+00:00</td>\n",
       "      <td>2025-06-01 23:23:49.105000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-01 18:19:39+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>15.86</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169896480</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>android</td>\n",
       "      <td>4272</td>\n",
       "      <td>Chiclayo</td>\n",
       "      <td>24</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-02 20:23:53.598000+00:00</td>\n",
       "      <td>2025-06-02 20:24:07.055000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  group_id created_dt_part  os_name  city_id city_name  country_id country_name  newbie_flag filled_flow                          show_dt                         click_dt                       approve_dt  approve_flag not_approve_dt  not_approve_flag           order_timestamp  order_flag    gmv  rides  orders\n",
       "0   12587106         1      2025-05-28      ios     4272  Chiclayo          24         Peru            0    liveness 2025-05-31 14:18:52.214000+00:00 2025-05-31 14:18:57.129000+00:00 2025-05-31 14:19:44.223000+00:00             1            NaT                 0 2025-05-28 01:46:07+00:00           1  72.59     33      54\n",
       "1   13837432         0      2025-06-01      ios     4272  Chiclayo          24         Peru            0    liveness 2025-06-02 08:56:49.763000+00:00 2025-06-02 08:56:51.131000+00:00 2025-06-02 08:57:22.166000+00:00             1            NaT                 0 2025-06-01 00:38:49+00:00           1 101.50     42      53\n",
       "2  148377114         0      2025-06-01  android     4272  Chiclayo          24         Peru            1    liveness 2025-06-01 08:22:31.072000+00:00 2025-06-01 08:22:32.725000+00:00 2025-06-01 08:23:14.108000+00:00             1            NaT                 0 2025-06-01 08:23:17+00:00           1   3.29      1       1\n",
       "3  169355421         0      2025-05-28      ios     4272  Chiclayo          24         Peru            0    liveness 2025-06-01 23:23:14.911000+00:00 2025-06-01 23:23:16.460000+00:00 2025-06-01 23:23:49.105000+00:00             1            NaT                 0 2025-06-01 18:19:39+00:00           1  15.86      8      10\n",
       "4  169896480         0      2025-06-02  android     4272  Chiclayo          24         Peru            1    liveness 2025-06-02 20:23:53.598000+00:00 2025-06-02 20:24:07.055000+00:00                              NaT             0            NaT                 0                       NaT           0   0.00      0    <NA>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_peru['rides'] = df_peru['rides'].fillna(0)\n",
    "df_peru['gmv'] = df_peru['gmv'].fillna(0)\n",
    "df_peru.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77fdd806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>created_dt_part</th>\n",
       "      <th>os_name</th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_id</th>\n",
       "      <th>country_name</th>\n",
       "      <th>newbie_flag</th>\n",
       "      <th>filled_flow</th>\n",
       "      <th>show_dt</th>\n",
       "      <th>click_dt</th>\n",
       "      <th>approve_dt</th>\n",
       "      <th>approve_flag</th>\n",
       "      <th>not_approve_dt</th>\n",
       "      <th>not_approve_flag</th>\n",
       "      <th>order_timestamp</th>\n",
       "      <th>order_flag</th>\n",
       "      <th>gmv</th>\n",
       "      <th>rides</th>\n",
       "      <th>orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36150212</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-29</td>\n",
       "      <td>android</td>\n",
       "      <td>4242</td>\n",
       "      <td>Medellin</td>\n",
       "      <td>22</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-05-29 20:01:32.623000+00:00</td>\n",
       "      <td>2025-05-29 20:01:35.955000+00:00</td>\n",
       "      <td>2025-05-29 20:02:24.344000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-29 20:02:38+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>46.04</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76732329</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>android</td>\n",
       "      <td>4242</td>\n",
       "      <td>Medellin</td>\n",
       "      <td>22</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-05-28 22:36:56.904000+00:00</td>\n",
       "      <td>2025-05-28 22:36:58.282000+00:00</td>\n",
       "      <td>2025-05-28 22:37:26.393000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-28 22:37:30+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>160.59</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107662317</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>ios</td>\n",
       "      <td>4242</td>\n",
       "      <td>Medellin</td>\n",
       "      <td>22</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-05-29 19:30:09.213000+00:00</td>\n",
       "      <td>2025-05-29 19:30:16.496000+00:00</td>\n",
       "      <td>2025-05-29 19:30:44.855000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-28 19:39:47+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>98.47</td>\n",
       "      <td>46</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125849185</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>ios</td>\n",
       "      <td>4242</td>\n",
       "      <td>Medellin</td>\n",
       "      <td>22</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-02 23:49:55.078000+00:00</td>\n",
       "      <td>2025-06-02 23:49:56.154000+00:00</td>\n",
       "      <td>2025-06-02 23:50:37.699000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-31 14:02:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>26.62</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164040409</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>ios</td>\n",
       "      <td>4242</td>\n",
       "      <td>Medellin</td>\n",
       "      <td>22</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-01 02:00:00.198000+00:00</td>\n",
       "      <td>2025-06-01 02:00:01.595000+00:00</td>\n",
       "      <td>2025-06-01 02:00:43.179000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-01 02:12:26+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>42.78</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  group_id created_dt_part  os_name  city_id city_name  country_id country_name  newbie_flag filled_flow                          show_dt                         click_dt                       approve_dt  approve_flag not_approve_dt  not_approve_flag           order_timestamp  order_flag    gmv  rides  orders\n",
       "0   36150212         0      2025-05-29  android     4242  Medellin          22     Colombia            0    liveness 2025-05-29 20:01:32.623000+00:00 2025-05-29 20:01:35.955000+00:00 2025-05-29 20:02:24.344000+00:00             1            NaT                 0 2025-05-29 20:02:38+00:00           1  46.04     10      12\n",
       "1   76732329         0      2025-05-28  android     4242  Medellin          22     Colombia            0    liveness 2025-05-28 22:36:56.904000+00:00 2025-05-28 22:36:58.282000+00:00 2025-05-28 22:37:26.393000+00:00             1            NaT                 0 2025-05-28 22:37:30+00:00           1 160.59     40      65\n",
       "2  107662317         0      2025-05-28      ios     4242  Medellin          22     Colombia            0    liveness 2025-05-29 19:30:09.213000+00:00 2025-05-29 19:30:16.496000+00:00 2025-05-29 19:30:44.855000+00:00             1            NaT                 0 2025-05-28 19:39:47+00:00           1  98.47     46      91\n",
       "3  125849185         0      2025-05-31      ios     4242  Medellin          22     Colombia            0    liveness 2025-06-02 23:49:55.078000+00:00 2025-06-02 23:49:56.154000+00:00 2025-06-02 23:50:37.699000+00:00             1            NaT                 0 2025-05-31 14:02:54+00:00           1  26.62     12      12\n",
       "4  164040409         0      2025-06-01      ios     4242  Medellin          22     Colombia            0    liveness 2025-06-01 02:00:00.198000+00:00 2025-06-01 02:00:01.595000+00:00 2025-06-01 02:00:43.179000+00:00             1            NaT                 0 2025-06-01 02:12:26+00:00           1  42.78     18      32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_colombia['rides'] = df_colombia['rides'].fillna(0)\n",
    "df_colombia['gmv'] = df_colombia['gmv'].fillna(0)\n",
    "df_colombia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac395077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>group0_sample_size</th>\n",
       "      <th>group1_sample_size</th>\n",
       "      <th>group0</th>\n",
       "      <th>group1</th>\n",
       "      <th>statistic</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>diff_mean</th>\n",
       "      <th>diff_mean_%</th>\n",
       "      <th>lb</th>\n",
       "      <th>ub</th>\n",
       "      <th>lb_%</th>\n",
       "      <th>ub_%</th>\n",
       "      <th>criteria</th>\n",
       "      <th>region</th>\n",
       "      <th>significance</th>\n",
       "      <th>result_with_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approve_flag</td>\n",
       "      <td>14704</td>\n",
       "      <td>2133</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-62.86</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-65.45</td>\n",
       "      <td>-60.28</td>\n",
       "      <td>ztest</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_approve_flag</td>\n",
       "      <td>14704</td>\n",
       "      <td>2133</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-24.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3,664.95</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3,374.35</td>\n",
       "      <td>3,955.56</td>\n",
       "      <td>ztest</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_flag</td>\n",
       "      <td>14704</td>\n",
       "      <td>2133</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-60.61</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-64.27</td>\n",
       "      <td>-56.94</td>\n",
       "      <td>ztest</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rides</td>\n",
       "      <td>14704</td>\n",
       "      <td>2133</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-59.28</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-64.53</td>\n",
       "      <td>-54.03</td>\n",
       "      <td>ttest</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gmv</td>\n",
       "      <td>14704</td>\n",
       "      <td>2133</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.36</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>-58.21</td>\n",
       "      <td>-2.08</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>-63.74</td>\n",
       "      <td>-52.69</td>\n",
       "      <td>ttest</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approve_flag</td>\n",
       "      <td>1704</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-27.27</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-35.52</td>\n",
       "      <td>-19.02</td>\n",
       "      <td>ztest</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_approve_flag</td>\n",
       "      <td>1704</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2,300.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>401.82</td>\n",
       "      <td>4,198.18</td>\n",
       "      <td>ztest</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_flag</td>\n",
       "      <td>1704</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-27.43</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-40.40</td>\n",
       "      <td>-14.46</td>\n",
       "      <td>ztest</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rides</td>\n",
       "      <td>1704</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-31.30</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-48.62</td>\n",
       "      <td>-13.98</td>\n",
       "      <td>ttest</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gmv</td>\n",
       "      <td>1704</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.77</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-32.32</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-50.01</td>\n",
       "      <td>-14.64</td>\n",
       "      <td>ttest</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        metric_name group0_sample_size group1_sample_size group0 group1  statistic  pvalue  mean0  mean1  diff_mean  diff_mean_%    lb    ub     lb_%     ub_% criteria    region  significance  result_with_corr\n",
       "0      approve_flag              14704               2133      0      1      47.70    0.00   0.79   0.29      -0.50       -62.86 -0.52 -0.48   -65.45   -60.28    ztest  Colombia             1                 1\n",
       "0  not_approve_flag              14704               2133      0      1     -24.72    0.00   0.01   0.23       0.23     3,664.95  0.21  0.24 3,374.35 3,955.56    ztest  Colombia             1                 1\n",
       "0        order_flag              14704               2133      0      1      32.41    0.00   0.52   0.20      -0.31       -60.61 -0.33 -0.29   -64.27   -56.94    ztest  Colombia             1                 1\n",
       "0             rides              14704               2133      0      1      22.14    0.00   0.86   0.35      -0.51       -59.28 -0.55 -0.46   -64.53   -54.03    ttest  Colombia             1                 1\n",
       "0               gmv              14704               2133      0      1      20.66    0.00   3.26   1.36      -1.90       -58.21 -2.08 -1.72   -63.74   -52.69    ttest  Colombia             1                 1\n",
       "0      approve_flag               1704                213      0      1       6.48    0.00   0.83   0.60      -0.23       -27.27 -0.29 -0.16   -35.52   -19.02    ztest      Peru             1                 1\n",
       "0  not_approve_flag               1704                213      0      1      -2.37    0.02   0.00   0.03       0.03     2,300.00  0.00  0.05   401.82 4,198.18    ztest      Peru             1                 1\n",
       "0        order_flag               1704                213      0      1       4.15    0.00   0.54   0.39      -0.15       -27.43 -0.22 -0.08   -40.40   -14.46    ztest      Peru             1                 1\n",
       "0             rides               1704                213      0      1       3.56    0.00   0.92   0.63      -0.29       -31.30 -0.45 -0.13   -48.62   -13.98    ttest      Peru             1                 1\n",
       "0               gmv               1704                213      0      1       3.60    0.00   2.61   1.77      -0.84       -32.32 -1.31 -0.38   -50.01   -14.64    ttest      Peru             1                 1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicators = ['approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']\n",
    "res_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for metric in indicators:\n",
    "\n",
    "    if metric in ['rides', 'gmv']:\n",
    "        ttest = expab.ttest(\n",
    "            df_colombia[(df_colombia['newbie_flag']==1)&(~df_colombia['show_dt'].isna())][['user_id', 'group_id', 'os_name', 'approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']],\n",
    "            metric,\n",
    "            'group_id'\n",
    "            )\n",
    "        ttest['criteria'] = 'ttest'\n",
    "        ttest['region'] = 'Colombia'\n",
    "        res_df = pd.concat([res_df, ttest])\n",
    "\n",
    "    else:\n",
    "        ztest = expab.ztest_proportion(\n",
    "            df_colombia[(df_colombia['newbie_flag']==1)&(~df_colombia['show_dt'].isna())][['user_id', 'group_id', 'os_name', 'approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']],\n",
    "            metric,\n",
    "            'group_id'\n",
    "            )\n",
    "        ztest['criteria'] = 'ztest'\n",
    "        ztest['region'] = 'Colombia'\n",
    "        res_df = pd.concat([res_df, ztest])\n",
    "\n",
    "\n",
    "    res_df['significance'] = (res_df['pvalue']<0.05)*1\n",
    "    res_df['result_with_corr'] = method_benjamini_hochberg(res_df['pvalue'].values)\n",
    "\n",
    "for metric in indicators:\n",
    "\n",
    "    if metric in ['rides', 'gmv']:\n",
    "        ttest = expab.ttest(\n",
    "            df_peru[(df_peru['newbie_flag']==1)&(~df_peru['show_dt'].isna())][['user_id', 'group_id', 'os_name', 'approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']],\n",
    "            metric,\n",
    "            'group_id'\n",
    "            )\n",
    "        ttest['criteria'] = 'ttest'\n",
    "        ttest['region'] = 'Peru'\n",
    "        res_df = pd.concat([res_df, ttest])\n",
    "\n",
    "    else:\n",
    "        ztest = expab.ztest_proportion(\n",
    "            df_peru[(df_peru['newbie_flag']==1)&(~df_peru['show_dt'].isna())][['user_id', 'group_id', 'os_name', 'approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']],\n",
    "            metric,\n",
    "            'group_id'\n",
    "            )\n",
    "        ztest['criteria'] = 'ztest'\n",
    "        ztest['region'] = 'Peru'\n",
    "        res_df = pd.concat([res_df, ztest])\n",
    "\n",
    "    res_df['significance'] = (res_df['pvalue']<0.05)*1\n",
    "    res_df['result_with_corr'] = method_benjamini_hochberg(res_df['pvalue'].values)\n",
    "\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "25e0155d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>participant_first_toggle_date</th>\n",
       "      <th>os_name</th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_id</th>\n",
       "      <th>country_name</th>\n",
       "      <th>newbie_flag</th>\n",
       "      <th>filled_flow</th>\n",
       "      <th>show_dt</th>\n",
       "      <th>click_dt</th>\n",
       "      <th>approve_dt</th>\n",
       "      <th>approve_flag</th>\n",
       "      <th>not_approve_dt</th>\n",
       "      <th>not_approve_flag</th>\n",
       "      <th>order_timestamp</th>\n",
       "      <th>order_flag</th>\n",
       "      <th>gmv</th>\n",
       "      <th>rides</th>\n",
       "      <th>orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69554358</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-21</td>\n",
       "      <td>android</td>\n",
       "      <td>4231</td>\n",
       "      <td>San Luis Potosi</td>\n",
       "      <td>12</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-22 19:24:57.653000+00:00</td>\n",
       "      <td>2025-06-22 19:25:01.442000+00:00</td>\n",
       "      <td>2025-06-22 19:25:31.148000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-22 19:35:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>12.36</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>268673902</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>android</td>\n",
       "      <td>4231</td>\n",
       "      <td>San Luis Potosi</td>\n",
       "      <td>12</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-20 22:07:33.428000+00:00</td>\n",
       "      <td>2025-06-20 22:07:35.686000+00:00</td>\n",
       "      <td>2025-06-20 22:07:55.345000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-22 03:35:51+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>52.68</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301580868</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-21</td>\n",
       "      <td>ios</td>\n",
       "      <td>4231</td>\n",
       "      <td>San Luis Potosi</td>\n",
       "      <td>12</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>1</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-21 21:10:08.375000+00:00</td>\n",
       "      <td>2025-06-21 21:10:09.485000+00:00</td>\n",
       "      <td>2025-06-21 21:10:28.477000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-21 22:13:29+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>26.73</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>239776795</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>ios</td>\n",
       "      <td>4228</td>\n",
       "      <td>Tijuana</td>\n",
       "      <td>12</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-24 12:37:50.728000+00:00</td>\n",
       "      <td>2025-06-24 12:37:51.830000+00:00</td>\n",
       "      <td>2025-06-24 12:38:32.884000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-24 12:40:20+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>63.73</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>236372252</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-21</td>\n",
       "      <td>ios</td>\n",
       "      <td>4228</td>\n",
       "      <td>Tijuana</td>\n",
       "      <td>12</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-21 09:42:34.932000+00:00</td>\n",
       "      <td>2025-06-21 09:42:37.736000+00:00</td>\n",
       "      <td>2025-06-21 09:43:14.565000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-22 07:30:49+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>48.96</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  group_id participant_first_toggle_date  os_name  city_id        city_name  country_id country_name  newbie_flag filled_flow                          show_dt                         click_dt                       approve_dt  approve_flag not_approve_dt  not_approve_flag           order_timestamp  order_flag   gmv  rides  orders\n",
       "0   69554358         0                    2025-06-21  android     4231  San Luis Potosi          12       Mexico            0    liveness 2025-06-22 19:24:57.653000+00:00 2025-06-22 19:25:01.442000+00:00 2025-06-22 19:25:31.148000+00:00             1            NaT                 0 2025-06-22 19:35:54+00:00           1 12.36      9      10\n",
       "1  268673902         0                    2025-06-20  android     4231  San Luis Potosi          12       Mexico            0    liveness 2025-06-20 22:07:33.428000+00:00 2025-06-20 22:07:35.686000+00:00 2025-06-20 22:07:55.345000+00:00             1            NaT                 0 2025-06-22 03:35:51+00:00           1 52.68     13      39\n",
       "2  301580868         0                    2025-06-21      ios     4231  San Luis Potosi          12       Mexico            1    liveness 2025-06-21 21:10:08.375000+00:00 2025-06-21 21:10:09.485000+00:00 2025-06-21 21:10:28.477000+00:00             1            NaT                 0 2025-06-21 22:13:29+00:00           1 26.73      9      12\n",
       "3  239776795         0                    2025-06-24      ios     4228          Tijuana          12       Mexico            0    liveness 2025-06-24 12:37:50.728000+00:00 2025-06-24 12:37:51.830000+00:00 2025-06-24 12:38:32.884000+00:00             1            NaT                 0 2025-06-24 12:40:20+00:00           1 63.73      8      12\n",
       "4  236372252         0                    2025-06-21      ios     4228          Tijuana          12       Mexico            0    liveness 2025-06-21 09:42:34.932000+00:00 2025-06-21 09:42:37.736000+00:00 2025-06-21 09:43:14.565000+00:00             1            NaT                 0 2025-06-22 07:30:49+00:00           1 48.96      8      19"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mexico = read_bq(\"\"\"\n",
    "WITH newbies AS (SELECT user_id,\n",
    "                        metric_date\n",
    "                 FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "                 WHERE user_type = 'pass'\n",
    "                   AND rides_count > 0\n",
    "                   AND metric_date >= DATE_ADD(CURRENT_DATE(), INTERVAL -1 YEAR)\n",
    "                   AND country_id = 12),\n",
    "     gmv AS (SELECT user_id,\n",
    "                    SUM(gmv_clean_usd) AS gmv,\n",
    "                    SUM(rides_count)   AS rides,\n",
    "                    SUM(orders_count)  AS orders\n",
    "             FROM indriver-bi.incity.tbl_incity_growth_metrics_detail\n",
    "             WHERE user_type = 'pass'\n",
    "               AND metric_date BETWEEN '2025-06-01' AND CURRENT_DATE()\n",
    "               AND country_id = 12\n",
    "             GROUP BY 1),\n",
    "     total AS (SELECT t1.user_id,\n",
    "                      t1.city_id,\n",
    "                      geo.city_name,\n",
    "                      geo.country_id,\n",
    "                      geo.country_name,\n",
    "                      IF(group_id = 4543357, 0, 1) AS group_id,\n",
    "                      participant_first_toggle_date,\n",
    "                      t2.metric_date,\n",
    "                      CASE\n",
    "                          WHEN t2.metric_date IS NULL THEN 1\n",
    "                          ELSE 0\n",
    "                          END                         newbie_flag\n",
    "               FROM indrive-core.ab_platform.tbl_ab_experiment_markup t1\n",
    "                        JOIN indriver-e6e40.heap.vw_macroregion_mapping geo\n",
    "                             ON\n",
    "                                 t1.city_id = geo.city_id\n",
    "                        LEFT JOIN newbies t2\n",
    "                                  ON t1.user_id = t2.user_id AND t2.metric_date < t1.participant_first_toggle_date\n",
    "               WHERE experiment_id = 3420\n",
    "               QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY metric_date DESC) = 1),\n",
    "     liveness AS (SELECT user_id,\n",
    "                         os_name,\n",
    "                         city_id,\n",
    "                         city_name,\n",
    "                         country_id,\n",
    "                         country_name,\n",
    "                         COALESCE(filled_flow, 'liveness')                                  AS filled_flow,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.show', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS show_dt,\n",
    "                         COALESCE(MAX(IF(name = 'client.verification_start.click', client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) = 'approve'), client_time, NULL)),\n",
    "                                  MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                          LOWER(status) != 'approve'), client_time, NULL))) AS click_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) = 'approve'), client_time, NULL))            AS approve_dt,\n",
    "                         MAX(IF((name = 'client.verification_flow_result_status.show' AND\n",
    "                                 LOWER(status) != 'approve'), client_time, NULL))           AS not_approve_dt\n",
    "                  FROM (SELECT t1.user_id,\n",
    "                               t1.name,\n",
    "                               t1.os_name,\n",
    "                               DATE(TIMESTAMP_MILLIS(t1.client_time))                  AS event_dt_part,\n",
    "                               TIMESTAMP_MILLIS(t1.client_time)                        AS client_time,\n",
    "                               t1.city_id,\n",
    "                               t2.city_name,\n",
    "                               t2.country_id,\n",
    "                               t2.country_name,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.verification_flow')     AS verification_flow,\n",
    "                               IF(JSON_EXTRACT_SCALAR(payload, '$.verification_flow') IS NULL,\n",
    "                                  LAG(JSON_EXTRACT_SCALAR(payload, '$.verification_flow'))\n",
    "                                      OVER (PARTITION BY t1.user_id ORDER BY client_time),\n",
    "                                  JSON_EXTRACT_SCALAR(payload, '$.verification_flow')) AS filled_flow,\n",
    "                               JSON_EXTRACT_SCALAR(payload, '$.status')                AS status\n",
    "                        FROM (SELECT *\n",
    "                              FROM indriver-e6e40.emart.product_event t1\n",
    "                              WHERE 1 = 1\n",
    "                                AND name IN (\n",
    "                                             'client.verification_start.show',\n",
    "                                             'client.verification_start.click',\n",
    "                                             'client.verification_flow_result_status.show'\n",
    "                                  )\n",
    "                                AND event_dt_part BETWEEN '2025-06-01' AND CURRENT_DATE()\n",
    "                                AND country_id IN (12)\n",
    "                              QUALIFY\n",
    "                                  ROW_NUMBER() OVER (PARTITION BY user_id, name, os_name, event_dt_part, JSON_EXTRACT_SCALAR(payload, '$.verification_flow') ORDER BY client_time DESC) =\n",
    "                                  1) t1\n",
    "                                 JOIN indriver-e6e40.heap.vw_macroregion_mapping t2\n",
    "                                      ON\n",
    "                                          t1.city_id = t2.city_id\n",
    "                        WHERE 1 = 1\n",
    "                          AND name IN (\n",
    "                                       'client.verification_start.show', 'client.verification_start.click',\n",
    "                                       'client.verification_flow_result_status.show'\n",
    "                            ))\n",
    "                  GROUP BY 1, 2, 3, 4, 5, 6, 7),\n",
    "     total_liv AS (SELECT t1.user_id,\n",
    "                          t1.city_id,\n",
    "                          t1.city_name,\n",
    "                          t1.country_id,\n",
    "                          t1.country_name,\n",
    "                          t1.group_id,\n",
    "                          t1.participant_first_toggle_date,\n",
    "                          t1.newbie_flag,\n",
    "                          t2.user_id AS user_with_svf,\n",
    "                          t2.os_name,\n",
    "                          t2.filled_flow,\n",
    "                          t2.show_dt,\n",
    "                          t2.click_dt,\n",
    "                          t2.approve_dt,\n",
    "                          t2.not_approve_dt\n",
    "                   FROM total t1\n",
    "                            JOIN liveness t2\n",
    "                                 ON t1.user_id = t2.user_id AND DATE(t2.show_dt) >= t1.participant_first_toggle_date),\n",
    "     rides AS (SELECT order_uuid,\n",
    "                      user_id    AS pass_id,\n",
    "                      driver_id,\n",
    "                      city_id    AS order_city_id,\n",
    "                      country_id AS order_country_id,\n",
    "                      status_order,\n",
    "                      order_timestamp,\n",
    "                      at_pickup_dttm,\n",
    "                      departed_pickup_dttm,\n",
    "                      at_destination_dttm,\n",
    "                      departed_destination_dttm,\n",
    "                      driveraccept_timestamp,\n",
    "                      driverarrived_timestamp,\n",
    "                      driverstarttheride_timestamp,\n",
    "                      driverdone_timestamp,\n",
    "                      clientdone_timestamp,\n",
    "                      clientcancel_timestamp,\n",
    "                      drivercancel_timestamp,\n",
    "                      user_reg_date,\n",
    "                      driver_reg_date,\n",
    "                      stage,\n",
    "                      created_date_order_part,\n",
    "                      duration_in_seconds\n",
    "               FROM indriver-e6e40.imart.incity_detail_new_order\n",
    "               WHERE created_date_order_part BETWEEN '2025-06-01'\n",
    "                   AND CURRENT_DATE()\n",
    "                 AND status_order = 'RIDE_STATUS_DONE'\n",
    "                 AND driveraccept_timestamp IS NOT NULL\n",
    "                 AND (clientcancel_timestamp IS NULL\n",
    "                   AND drivercancel_timestamp IS NULL))\n",
    "SELECT t1.user_id,\n",
    "       t1.group_id,\n",
    "       t1.participant_first_toggle_date,\n",
    "       t1.os_name,\n",
    "       t1.city_id,\n",
    "       t1.city_name,\n",
    "       t1.country_id,\n",
    "       t1.country_name,\n",
    "       t1.newbie_flag,\n",
    "       filled_flow,\n",
    "       show_dt,\n",
    "       click_dt,\n",
    "       approve_dt                                                  AS approve_dt,\n",
    "       IF(approve_dt IS NOT NULL, 1, 0)                            AS approve_flag,\n",
    "       not_approve_dt,\n",
    "       IF(not_approve_dt IS NOT NULL AND approve_dt IS NULL, 1, 0) AS not_approve_flag,\n",
    "       t2.order_timestamp,\n",
    "       IF(t2.order_timestamp IS NOT NULL, 1, 0)                    AS order_flag,\n",
    "       t3.gmv,\n",
    "       t3.rides,\n",
    "       t3.orders\n",
    "FROM total_liv t1\n",
    "         LEFT JOIN rides t2\n",
    "                   ON t1.user_id = t2.pass_id AND\n",
    "                      t2.created_date_order_part >= participant_first_toggle_date\n",
    "         LEFT JOIN gmv t3 ON t1.user_id = t3.user_id\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY t1.user_id ORDER BY t2.order_timestamp) = 1\n",
    "\"\"\")\n",
    "\n",
    "df_mexico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "83176084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>participant_first_toggle_date</th>\n",
       "      <th>os_name</th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_id</th>\n",
       "      <th>country_name</th>\n",
       "      <th>newbie_flag</th>\n",
       "      <th>filled_flow</th>\n",
       "      <th>show_dt</th>\n",
       "      <th>click_dt</th>\n",
       "      <th>approve_dt</th>\n",
       "      <th>approve_flag</th>\n",
       "      <th>not_approve_dt</th>\n",
       "      <th>not_approve_flag</th>\n",
       "      <th>order_timestamp</th>\n",
       "      <th>order_flag</th>\n",
       "      <th>gmv</th>\n",
       "      <th>rides</th>\n",
       "      <th>orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69554358</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-21</td>\n",
       "      <td>android</td>\n",
       "      <td>4231</td>\n",
       "      <td>San Luis Potosi</td>\n",
       "      <td>12</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-22 19:24:57.653000+00:00</td>\n",
       "      <td>2025-06-22 19:25:01.442000+00:00</td>\n",
       "      <td>2025-06-22 19:25:31.148000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-22 19:35:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>12.36</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>268673902</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>android</td>\n",
       "      <td>4231</td>\n",
       "      <td>San Luis Potosi</td>\n",
       "      <td>12</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-20 22:07:33.428000+00:00</td>\n",
       "      <td>2025-06-20 22:07:35.686000+00:00</td>\n",
       "      <td>2025-06-20 22:07:55.345000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-22 03:35:51+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>52.68</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301580868</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-21</td>\n",
       "      <td>ios</td>\n",
       "      <td>4231</td>\n",
       "      <td>San Luis Potosi</td>\n",
       "      <td>12</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>1</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-21 21:10:08.375000+00:00</td>\n",
       "      <td>2025-06-21 21:10:09.485000+00:00</td>\n",
       "      <td>2025-06-21 21:10:28.477000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-21 22:13:29+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>26.73</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>239776795</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>ios</td>\n",
       "      <td>4228</td>\n",
       "      <td>Tijuana</td>\n",
       "      <td>12</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-24 12:37:50.728000+00:00</td>\n",
       "      <td>2025-06-24 12:37:51.830000+00:00</td>\n",
       "      <td>2025-06-24 12:38:32.884000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-24 12:40:20+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>63.73</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>236372252</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-21</td>\n",
       "      <td>ios</td>\n",
       "      <td>4228</td>\n",
       "      <td>Tijuana</td>\n",
       "      <td>12</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>liveness</td>\n",
       "      <td>2025-06-21 09:42:34.932000+00:00</td>\n",
       "      <td>2025-06-21 09:42:37.736000+00:00</td>\n",
       "      <td>2025-06-21 09:43:14.565000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-22 07:30:49+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>48.96</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  group_id participant_first_toggle_date  os_name  city_id        city_name  country_id country_name  newbie_flag filled_flow                          show_dt                         click_dt                       approve_dt  approve_flag not_approve_dt  not_approve_flag           order_timestamp  order_flag   gmv  rides  orders\n",
       "0   69554358         0                    2025-06-21  android     4231  San Luis Potosi          12       Mexico            0    liveness 2025-06-22 19:24:57.653000+00:00 2025-06-22 19:25:01.442000+00:00 2025-06-22 19:25:31.148000+00:00             1            NaT                 0 2025-06-22 19:35:54+00:00           1 12.36      9      10\n",
       "1  268673902         0                    2025-06-20  android     4231  San Luis Potosi          12       Mexico            0    liveness 2025-06-20 22:07:33.428000+00:00 2025-06-20 22:07:35.686000+00:00 2025-06-20 22:07:55.345000+00:00             1            NaT                 0 2025-06-22 03:35:51+00:00           1 52.68     13      39\n",
       "2  301580868         0                    2025-06-21      ios     4231  San Luis Potosi          12       Mexico            1    liveness 2025-06-21 21:10:08.375000+00:00 2025-06-21 21:10:09.485000+00:00 2025-06-21 21:10:28.477000+00:00             1            NaT                 0 2025-06-21 22:13:29+00:00           1 26.73      9      12\n",
       "3  239776795         0                    2025-06-24      ios     4228          Tijuana          12       Mexico            0    liveness 2025-06-24 12:37:50.728000+00:00 2025-06-24 12:37:51.830000+00:00 2025-06-24 12:38:32.884000+00:00             1            NaT                 0 2025-06-24 12:40:20+00:00           1 63.73      8      12\n",
       "4  236372252         0                    2025-06-21      ios     4228          Tijuana          12       Mexico            0    liveness 2025-06-21 09:42:34.932000+00:00 2025-06-21 09:42:37.736000+00:00 2025-06-21 09:43:14.565000+00:00             1            NaT                 0 2025-06-22 07:30:49+00:00           1 48.96      8      19"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mexico['rides'] = df_mexico['rides'].fillna(0)\n",
    "df_mexico['gmv'] = df_mexico['gmv'].fillna(0)\n",
    "df_mexico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01c2d5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>group0_sample_size</th>\n",
       "      <th>group1_sample_size</th>\n",
       "      <th>group0</th>\n",
       "      <th>group1</th>\n",
       "      <th>statistic</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>diff_mean</th>\n",
       "      <th>diff_mean_%</th>\n",
       "      <th>lb</th>\n",
       "      <th>ub</th>\n",
       "      <th>lb_%</th>\n",
       "      <th>ub_%</th>\n",
       "      <th>criteria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rides</td>\n",
       "      <td>7336</td>\n",
       "      <td>1157</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-36.64</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-47.41</td>\n",
       "      <td>-25.87</td>\n",
       "      <td>ttest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric_name group0_sample_size group1_sample_size group0 group1  statistic  pvalue  mean0  mean1  diff_mean  diff_mean_%    lb    ub   lb_%   ub_% criteria\n",
       "0       rides               7336               1157      0      1       6.67    0.00   0.77   0.49      -0.28       -36.64 -0.37 -0.20 -47.41 -25.87    ttest"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicators = ['approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']\n",
    "\n",
    "ttest = expab.ttest(\n",
    "            df_mexico[(df_mexico['newbie_flag']==1)&(~df_mexico['show_dt'].isna())][['user_id', 'group_id', 'os_name', 'approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']],\n",
    "            'rides',\n",
    "            'group_id'\n",
    "            )\n",
    "ttest['criteria'] = 'ttest'\n",
    "ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e92dcd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>group0_sample_size</th>\n",
       "      <th>group1_sample_size</th>\n",
       "      <th>group0</th>\n",
       "      <th>group1</th>\n",
       "      <th>statistic</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>diff_mean</th>\n",
       "      <th>diff_mean_%</th>\n",
       "      <th>lb</th>\n",
       "      <th>ub</th>\n",
       "      <th>lb_%</th>\n",
       "      <th>ub_%</th>\n",
       "      <th>criteria</th>\n",
       "      <th>significance</th>\n",
       "      <th>result_with_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approve_flag</td>\n",
       "      <td>7336</td>\n",
       "      <td>1157</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-41.07</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-45.01</td>\n",
       "      <td>-37.13</td>\n",
       "      <td>ztest</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_approve_flag</td>\n",
       "      <td>7336</td>\n",
       "      <td>1157</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>79.65</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-8.79</td>\n",
       "      <td>168.08</td>\n",
       "      <td>ztest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_flag</td>\n",
       "      <td>7336</td>\n",
       "      <td>1157</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-44.12</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-50.59</td>\n",
       "      <td>-37.66</td>\n",
       "      <td>ztest</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rides</td>\n",
       "      <td>7336</td>\n",
       "      <td>1157</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-36.64</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-47.41</td>\n",
       "      <td>-25.87</td>\n",
       "      <td>ttest</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gmv</td>\n",
       "      <td>7336</td>\n",
       "      <td>1157</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.96</td>\n",
       "      <td>2.58</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>-34.79</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-46.96</td>\n",
       "      <td>-22.62</td>\n",
       "      <td>ttest</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        metric_name group0_sample_size group1_sample_size group0 group1  statistic  pvalue  mean0  mean1  diff_mean  diff_mean_%    lb    ub   lb_%   ub_% criteria  significance  result_with_corr\n",
       "0      approve_flag               7336               1157      0      1      20.44    0.00   0.77   0.45      -0.32       -41.07 -0.35 -0.29 -45.01 -37.13    ztest             1                 1\n",
       "0  not_approve_flag               7336               1157      0      1      -1.77    0.08   0.01   0.01       0.01        79.65 -0.00  0.01  -8.79 168.08    ztest             0                 0\n",
       "0        order_flag               7336               1157      0      1      13.38    0.00   0.41   0.23      -0.18       -44.12 -0.21 -0.16 -50.59 -37.66    ztest             1                 1\n",
       "0             rides               7336               1157      0      1       6.67    0.00   0.77   0.49      -0.28       -36.64 -0.37 -0.20 -47.41 -25.87    ttest             1                 1\n",
       "0               gmv               7336               1157      0      1       5.61    0.00   3.96   2.58      -1.38       -34.79 -1.86 -0.90 -46.96 -22.62    ttest             1                 1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicators = ['approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']\n",
    "res_df = pd.DataFrame()\n",
    "\n",
    "for metric in indicators:\n",
    "\n",
    "    if metric in ['rides', 'gmv']:\n",
    "        ttest = expab.ttest(\n",
    "            df_mexico[(df_mexico['newbie_flag']==1)&(~df_mexico['show_dt'].isna())][['user_id', 'group_id', 'os_name', 'approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']],\n",
    "            metric,\n",
    "            'group_id'\n",
    "            )\n",
    "        ttest['criteria'] = 'ttest'\n",
    "        res_df = pd.concat([res_df, ttest])\n",
    "\n",
    "    else:\n",
    "        ztest = expab.ztest_proportion(\n",
    "            df_mexico[(df_mexico['newbie_flag']==1)&(~df_mexico['show_dt'].isna())][['user_id', 'group_id', 'os_name', 'approve_flag', 'not_approve_flag', 'order_flag', 'rides', 'gmv']],\n",
    "            metric,\n",
    "            'group_id'\n",
    "            )\n",
    "        ztest['criteria'] = 'ztest'\n",
    "        res_df = pd.concat([res_df, ztest])\n",
    "\n",
    "    res_df['significance'] = (res_df['pvalue']<0.05)*1\n",
    "    res_df['result_with_corr'] = method_benjamini_hochberg(res_df['pvalue'].values)\n",
    "\n",
    "res_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
