{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eba1d59",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f4cd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisation\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Data analysis / Data processing\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.options.display.float_format = \"{:,.4f}\".format\n",
    "from datetime import time, timedelta, datetime\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "# Maths & Stats\n",
    "import math \n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import statsmodels.stats.weightstats as ws\n",
    "from statsmodels.stats.proportion import test_proportions_2indep\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "# from ambrosia.designer import Designer\n",
    "# from ambrosia.tester import Tester\n",
    "import expab\n",
    "from sklearn.linear_model import Ridge\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "# System library\n",
    "import os\n",
    "import ipywidgets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# from itables import init_notebook_mode\n",
    "# init_notebook_mode(all_interactive=True)\n",
    "import openpyxl\n",
    "\n",
    "# Data connection\n",
    "from google.cloud import bigquery\n",
    "bigquery_client = bigquery.Client(project='analytics-dev-333113')\n",
    "\n",
    "\n",
    "# Useful functions\n",
    "def read_bq(query, project='analytics-dev-333113'):\n",
    "    client = bigquery.Client(project=project)\n",
    "    query_job = client.query(query)\n",
    "    result_df = query_job.to_dataframe()\n",
    "    return result_df\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "\n",
    "    html_str = ''\n",
    "    for df in args:\n",
    "        html_str += df.to_html()\n",
    "    display_html(\n",
    "        html_str.replace('table','table style=\"display:inline\"'), \n",
    "        raw=True\n",
    "    )\n",
    "\n",
    "def cycle_sql(start, end, query, weeks=False):\n",
    "    \"\"\"\n",
    "    You have to use {date} in your script to add cycle date into this backets\n",
    "    \"\"\"\n",
    "    date_start = datetime.strptime(start, '%Y-%m-%d')\n",
    "    date_end = datetime.strptime(end, '%Y-%m-%d')\n",
    "\n",
    "    if weeks == False:\n",
    "        daterange = [(date_start + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days)+1)]\n",
    "    else:\n",
    "        daterange = [(date_start + timedelta(weeks=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days//7)+1)] # weeks dividing days by 7\n",
    "\n",
    "    total_df = pd.DataFrame()\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for date in daterange:\n",
    "        counter+=1\n",
    "        print(f\"{counter}) Uploading - {date}:\", datetime.today().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        script = query.format(date = date)\n",
    "        df_cycle = bigquery_client.query(script).to_dataframe()\n",
    "        if df_cycle.empty == True:\n",
    "            print('Dataframe is empty')\n",
    "        total_df = pd.concat([df_cycle, total_df])\n",
    "    return total_df  \n",
    "\n",
    "def writing_excel(name:str, dataset1=None, dataset2=None, dataset3=None, dataset4=None):\n",
    "    with pd.ExcelWriter(f\"{name}.xlsx\") as writer:\n",
    "\n",
    "    # use to_excel function and specify the sheet_name and index \n",
    "    # to store the dataframe in specified sheet\n",
    "\n",
    "        if dataset1 is not None:\n",
    "            if dataset2 is not None:\n",
    "                if dataset3 is not None:\n",
    "                    if dataset4 is not None:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset4.to_excel(writer, sheet_name=f\"4-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                    else:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                else:\n",
    "                    dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "                    dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "            else:\n",
    "                dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                #   index=False\n",
    "                                    )\n",
    "\n",
    "        print('DataFrame is written to Excel File successfully.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f486a",
   "metadata": {},
   "source": [
    "# Pulling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e52555b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>macroregion_name</th>\n",
       "      <th>night_time_flg</th>\n",
       "      <th>liveness_picture</th>\n",
       "      <th>avatar_picture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10894660</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>0</td>\n",
       "      <td>0196e4b8-a9ec-7c81-81d9-46571000bec2</td>\n",
       "      <td>https://file-storage-front.eu-east-1.indriverapp.com/api/v1/files/0196d63a-321a-7032-bd3e-ca5483f7275a?resize=800x600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13022962</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>0</td>\n",
       "      <td>01974b1c-e9f2-735f-a2c7-3fceba2f5314</td>\n",
       "      <td>https://file-storage-front.eu-east-1.indriverapp.com/api/v1/files/01974b19-cc69-7384-8a67-9da0b86c1d19?resize=800x600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13536252</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>0</td>\n",
       "      <td>019674bf-ffb2-7067-8508-91d4c9ef0135</td>\n",
       "      <td>https://file-storage-front.eu-east-1.indriverapp.com/api/v1/files/0195d413-06c0-76b7-9e3c-649290421ff5?resize=800x600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13570013</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>0</td>\n",
       "      <td>019756f3-84b3-7aae-89ca-1988ae0f334d</td>\n",
       "      <td>https://file-storage-front.eu-east-1.indriverapp.com/api/v1/files/01956c85-6438-7134-8139-0d384957cb4a?resize=800x600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13702862</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>0</td>\n",
       "      <td>019712df-b058-7acf-ab37-aad022570cf0</td>\n",
       "      <td>https://file-storage-front.eu-east-1.indriverapp.com/api/v1/files/01970a0e-56bf-7bd3-837b-5cda5778a9a9?resize=800x600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id macroregion_name  night_time_flg                      liveness_picture                                                                                                         avatar_picture\n",
       "0  10894660    Latin America               0  0196e4b8-a9ec-7c81-81d9-46571000bec2  https://file-storage-front.eu-east-1.indriverapp.com/api/v1/files/0196d63a-321a-7032-bd3e-ca5483f7275a?resize=800x600\n",
       "1  13022962    Latin America               0  01974b1c-e9f2-735f-a2c7-3fceba2f5314  https://file-storage-front.eu-east-1.indriverapp.com/api/v1/files/01974b19-cc69-7384-8a67-9da0b86c1d19?resize=800x600\n",
       "2  13536252    Latin America               0  019674bf-ffb2-7067-8508-91d4c9ef0135  https://file-storage-front.eu-east-1.indriverapp.com/api/v1/files/0195d413-06c0-76b7-9e3c-649290421ff5?resize=800x600\n",
       "3  13570013    Latin America               0  019756f3-84b3-7aae-89ca-1988ae0f334d  https://file-storage-front.eu-east-1.indriverapp.com/api/v1/files/01956c85-6438-7134-8139-0d384957cb4a?resize=800x600\n",
       "4  13702862    Latin America               0  019712df-b058-7acf-ab37-aad022570cf0  https://file-storage-front.eu-east-1.indriverapp.com/api/v1/files/01970a0e-56bf-7bd3-837b-5cda5778a9a9?resize=800x600"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_bq(\"\"\"\n",
    "WITH photos AS (SELECT t1.user_id,\n",
    "                       t1.photo_uuid,\n",
    "                       IF(EXTRACT(HOUR FROM DATETIME(t1.created_at, tz.timezone)) IN\n",
    "                          (21, 22, 23, 0, 1, 2, 3, 4, 5, 6), 1,\n",
    "                          0) AS night_time_flg,\n",
    "                       t3.macroregion_name\n",
    "                FROM indriver-e6e40.ods_facechecker.user_liveness t1\n",
    "                         JOIN dwh-storage-327422.personal_data.tbl_user_act t2\n",
    "                              ON t1.user_id = t2.id\n",
    "                         JOIN indriver-e6e40.ods_monolith.tbl_city tz ON t2.city_id = tz.id\n",
    "                         JOIN indriver-e6e40.heap.vw_macroregion_mapping t3\n",
    "                              ON\n",
    "                                  t2.city_id = t3.city_id\n",
    "                WHERE created_at >= '2025-03-01'\n",
    "                  AND t2.country_id IN (12, 23, 54, 25, 13, 43, 24, 75, 72, 77, 11, 22, 10)\n",
    "                  AND photo_uuid IS NOT NULL\n",
    "                QUALIFY ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) = 1),\n",
    "     avatars AS (SELECT av.user_id,\n",
    "                        tcv.url_first\n",
    "                 FROM indriver-e6e40.inappropriate_content.ds_avatar_check av\n",
    "                          JOIN dwh-storage-327422.personal_data.taskcv tcv ON tcv.task_id = CAST(av.task_id AS string)\n",
    "                 WHERE tcv.export_dt >= '2025-03-01'\n",
    "                   AND result_code = 'RESULT_AVATAR_CHECK_FACE_OK')\n",
    "SELECT t1.user_id,\n",
    "       t1.macroregion_name,\n",
    "       t1.night_time_flg,\n",
    "       t1.photo_uuid AS liveness_picture,\n",
    "       t3.url_first  AS avatar_picture\n",
    "FROM photos t1\n",
    "         LEFT JOIN avatars t3 ON t1.user_id = t3.user_id\n",
    "WHERE (t1.photo_uuid IS NOT NULL AND t3.url_first IS NOT NULL)\n",
    "\"\"\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcf88f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_excel(name:str, dataset1=None, dataset2=None, dataset3=None, dataset4=None):\n",
    "    with pd.ExcelWriter(f\"{name}.xlsx\") as writer:\n",
    "\n",
    "    # use to_excel function and specify the sheet_name and index \n",
    "    # to store the dataframe in specified sheet\n",
    "\n",
    "        if dataset1 is not None:\n",
    "            if dataset2 is not None:\n",
    "                if dataset3 is not None:\n",
    "                    if dataset4 is not None:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset4.to_excel(writer, sheet_name=f\"4-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                    else:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                else:\n",
    "                    dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "                    dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "            else:\n",
    "                dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                #   index=False\n",
    "                                    )\n",
    "\n",
    "        print('DataFrame is written to Excel File successfully.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "540ba287",
   "metadata": {},
   "outputs": [],
   "source": [
    "latam_0 = df[(df['macroregion_name'].isin(['Latin America', 'Brazil']))&(df['night_time_flg']==0)].sample(2000)\n",
    "latam_1 = df[(df['macroregion_name'].isin(['Latin America', 'Brazil']))&(df['night_time_flg']==1)].sample(2000)\n",
    "africa_0 = df[(df['macroregion_name']=='Africa')&(df['night_time_flg']==0)].sample(2000)\n",
    "africa_1 = df[(df['macroregion_name']=='Africa')&(df['night_time_flg']==1)].sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "129f997a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written to Excel File successfully.\n"
     ]
    }
   ],
   "source": [
    "writing_excel('Avatar_Liveness_ML_comparison', \n",
    "              latam_0,\n",
    "              latam_1,\n",
    "              africa_0,\n",
    "              africa_1\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
