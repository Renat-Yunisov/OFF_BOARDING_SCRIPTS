{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "466da462",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fbf9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisation\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyvis.network import Network\n",
    "import shap\n",
    "\n",
    "\n",
    "# Data analysis / Data processing\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "from datetime import time, timedelta, datetime\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "from ydata_profiling import ProfileReport\n",
    "import re\n",
    "from typing import Set, List, Dict\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Maths & Stats\n",
    "import math \n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import statsmodels.stats.weightstats as ws\n",
    "from statsmodels.stats.proportion import test_proportions_2indep\n",
    "import AB_library\n",
    "import random\n",
    "\n",
    "# System library\n",
    "import os\n",
    "import ipywidgets\n",
    "import warnings\n",
    "import pandas_gbq\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# from itables import init_notebook_mode\n",
    "# init_notebook_mode(all_interactive=True)\n",
    "import openpyxl\n",
    "\n",
    "# Data connection\n",
    "from google.cloud import bigquery\n",
    "bigquery_client = bigquery.Client(project='analytics-dev-333113')\n",
    "\n",
    "\n",
    "# Useful functions\n",
    "def cycle_sql(start, end, query, weeks=False):\n",
    "    \"\"\"\n",
    "    You have to use {date} in your script to add cycle date into this backets\n",
    "    \"\"\"\n",
    "    date_start = datetime.strptime(start, '%Y-%m-%d')\n",
    "    date_end = datetime.strptime(end, '%Y-%m-%d')\n",
    "\n",
    "    if weeks == False:\n",
    "        daterange = [(date_start + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days)+1)]\n",
    "    else:\n",
    "        daterange = [(date_start + timedelta(weeks=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days//7)+1)] # weeks dividing days by 7\n",
    "\n",
    "    total_df = pd.DataFrame()\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for date in daterange:\n",
    "        counter+=1\n",
    "        print(f\"{counter}) Uploading - {date}:\", datetime.today().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        script = query.format(date = date)\n",
    "        df_cycle = bigquery_client.query(script).to_dataframe()\n",
    "        if df_cycle.empty == True:\n",
    "            print('Dataframe is empty')\n",
    "        total_df = pd.concat([df_cycle, total_df])\n",
    "    return total_df\n",
    "\n",
    "def read_bq(query, project='analytics-dev-333113'):\n",
    "    client = bigquery.Client(project=project)\n",
    "    query_job = client.query(query)\n",
    "    result_df = query_job.to_dataframe()\n",
    "    return result_df\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "    html_str = ''\n",
    "    for df in args:\n",
    "        html_str += df.to_html()\n",
    "    display_html(\n",
    "        html_str.replace('table','table style=\"display:inline\"'), \n",
    "        raw=True\n",
    "    )\n",
    "\n",
    "def writing_excel(name:str, dataset1=None, dataset2=None, dataset3=None, dataset4=None):\n",
    "    with pd.ExcelWriter(f\"{name}.xlsx\") as writer:\n",
    "\n",
    "    # use to_excel function and specify the sheet_name and index \n",
    "    # to store the dataframe in specified sheet\n",
    "\n",
    "        if dataset1 is not None:\n",
    "            if dataset2 is not None:\n",
    "                if dataset3 is not None:\n",
    "                    if dataset4 is not None:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset4.to_excel(writer, sheet_name=f\"4-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                    else:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                            )\n",
    "                else:\n",
    "                    dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "                    dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                    #   index=False\n",
    "                                        )\n",
    "            else:\n",
    "                dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                #   index=False\n",
    "                                    )\n",
    "\n",
    "        print('DataFrame is written to Excel File successfully.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6bbff",
   "metadata": {},
   "source": [
    "# Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a609d9",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd440b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample = pd.read_csv('analytics_dev_333113ty_score_total_for_ml.csv')\n",
    "\n",
    "df_sample = pd.read_csv('/Users/renatyunison/Desktop/VSC scripts/Working/new_data_scoring.csv')\n",
    "\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_category(model: str) -> str:\n",
    "\n",
    "    device_price_map = {\n",
    "    'pro max': 'premium', 'ultra': 'premium', 'galaxy z': 'premium',\n",
    "    'galaxy s': 'premium', 'fold': 'premium', 'flip': 'premium',\n",
    "    'pixel': 'premium', 'pro': 'premium', 'iphone': 'premium',\n",
    "    'rog': 'premium', 'sony': 'premium', \n",
    "    \n",
    "    'oneplus': 'mid-range', 'honor': 'mid-range', 'huawei': 'mid-range',\n",
    "    'galaxy a': 'mid-range', 'samsung': 'mid-range', 'pixel a': 'mid-range',\n",
    "    'nord': 'mid-range', 'realme': 'mid-range', 'oppo': 'mid-range',\n",
    "    'xiaomi': 'mid-range', 'motorola': 'mid-range', 'vivo': 'mid-range',\n",
    "    'iqoo': 'mid-range', 'lge': 'mid-range', 'nothing': 'mid-range',\n",
    "    'tcl': 'mid-range', 'nubia': 'mid-range', 'asus': 'mid-range',\n",
    "    \n",
    "    'sm-a': 'budget', 'moto g': 'budget', 'lite': 'budget',\n",
    "    'redmi': 'budget', 'poco': 'budget', 'infinix': 'budget',\n",
    "    'tecno': 'budget', 'lenovo': 'budget', 'nokia': 'budget',\n",
    "    'itel': 'budget', 'lava': 'budget', 'zte': 'budget', 'op': 'budget',\n",
    "    'ulefone': 'budget', 'sparx': 'budget', 'hisense': 'budget',\n",
    "    'blackview': 'budget', 'cubot': 'budget', 'doogee': 'budget',\n",
    "    'benco': 'budget', 'vgo_tel': 'budget', 'hmd': 'budget',\n",
    "    'villaon': 'budget', \n",
    "    'vios': 'budget', \n",
    "    'marcel': 'budget', \n",
    "    'cg_mobiles': 'budget', \n",
    "    'ulesson': 'budget', \n",
    "    'mobice': 'budget', \n",
    "    'mirage': 'budget' \n",
    "}\n",
    "\n",
    "    if not isinstance(model, str):\n",
    "        return 'unknown'\n",
    "\n",
    "    cleaned_model = model.lower().strip()\n",
    "    cleaned_model = re.sub(r'[^\\w\\s]', '', cleaned_model)\n",
    "    cleaned_model = re.sub(r'\\s+', ' ', cleaned_model).strip()\n",
    "\n",
    "    for keyword, category in device_price_map.items():\n",
    "        if keyword in cleaned_model:\n",
    "            return category\n",
    "    \n",
    "    return 'unknown' \n",
    "\n",
    "\n",
    "df_sample['device_price_category'] = df_sample['devicemodel'].apply(get_device_category)\n",
    "\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_name_suspicious_flag(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    import unicodedata\n",
    "\n",
    "    common_names_whitelist = {\n",
    "        'michael', 'john', 'anna', 'mary', 'david', 'chris', 'james', 'anna',\n",
    "        'robert', 'william', 'joseph', 'charles', 'thomas', 'daniel', 'matthew',\n",
    "        'elizabeth', 'sandra', 'barbara', 'patricia', 'jennifer', 'maria',\n",
    "        'hector', 'adriana', 'rodrigo', 'italo', 'karen', 'julia', 'fabio', 'antonio',\n",
    "        'thaylla', 'rania', 'lwazi', 'miriam', 'ronaldo', 'costanza', 'fernando',\n",
    "        'vanessa', 'nigel', 'rudy', 'dimitri', 'sharon', 'mavuzo', 'ana', 'danny',\n",
    "        'paola', 'david', 'camila', 'alexis', 'alejandra', 'dante', 'juanita',\n",
    "        'wilmer', 'william', 'fernanda', 'leon', 'jeremy', 'atif', 'judith',\n",
    "        'thiago', 'michel', 'didier', 'isaias', 'melissa', 'nayara', 'kaitlin',\n",
    "        'karla', 'anthony', 'gerson', 'daniel', 'alfred', 'ailton', 'victoria',\n",
    "        'mirzhan', 'миржан' # Добавлены имена из вашего списка\n",
    "    }\n",
    "\n",
    "    suspicious_ngrams = {\n",
    "        'vv', 'ww', 'qq', 'jj', 'kk', 'uu', 'oo', 'yy', 'zz',\n",
    "        'qwe', 'asd', 'zxc', 'rty', 'fgh', 'vbn', 'tyu', 'ghj', 'bnm', 'dfg', 'jkl', 'uio', 'iop', 'klj',\n",
    "        'j.d', 'j.r', 'j d', 'j r', 'k d', 'l d', 'l r', 'r d', 'jd', 'jr', 'kl', 'gh', 'kk', 'qq',\n",
    "        '123', '234', '345', '456', '567', '678', '789', '890', '000',\n",
    "        'abc', 'xyz', 'mnp', 'qaz', 'wsx', 'edc',\n",
    "        'b1', 'c1', 'd1', 'e1', 'f1',\n",
    "        '1a', '2a', '3a', '4a', '5a',\n",
    "    }\n",
    "\n",
    "    def has_repeated_chars(s: str) -> bool:\n",
    "        \"\"\"\n",
    "        Проверяет, содержит ли строка повторяющийся символ 3 или более раз подряд.\n",
    "        \"\"\"\n",
    "        return bool(re.search(r'(.)\\1\\1', s))\n",
    "    \n",
    "    def normalize_name(s: str) -> str:\n",
    "        \"\"\"Конвертирует строку в ASCII-представление, убирая акценты и диакритические знаки.\"\"\"\n",
    "        return unicodedata.normalize('NFKD', s).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "    def check_name_adequacy(name: str) -> int:\n",
    "        name_str = str(name).strip()\n",
    "        name_lower = name_str.lower()\n",
    "        \n",
    "        # ПРАВИЛО 0: Проверка по \"белому списку\" (перед нормализацией)\n",
    "        if name_lower in common_names_whitelist:\n",
    "            return 0\n",
    "\n",
    "        # ПРАВИЛО 1 (НОВОЕ): Нормализация имени\n",
    "        # Применяем нормализацию к имени перед дальнейшими проверками\n",
    "        normalized_name_str = normalize_name(name_str)\n",
    "        normalized_name_lower = normalized_name_str.lower()\n",
    "        \n",
    "        # ПРАВИЛО 2: Проверка на повторяющиеся символы\n",
    "        if has_repeated_chars(normalized_name_lower):\n",
    "            return 1\n",
    "\n",
    "        # Правило 3: Имя слишком короткое\n",
    "        name_no_space = normalized_name_lower.replace(' ', '')\n",
    "        if len(name_no_space) < 3:\n",
    "            return 1\n",
    "            \n",
    "        # Правило 4: Имя состоит из одной или двух букв, которые являются заглавными\n",
    "        if len(name_no_space) <= 2 and normalized_name_str.isupper():\n",
    "            return 1\n",
    "\n",
    "        # Правило 5: Наличие необычных символов или цифр\n",
    "        # Теперь это правило будет проверять только те символы, которые остались после нормализации\n",
    "        if bool(re.search(r'[^a-zA-Zа-яА-Я\\s]', normalized_name_str)):\n",
    "            return 1\n",
    "            \n",
    "        # Правило 6: Имя написано полностью в нижнем регистре\n",
    "        if normalized_name_str.islower():\n",
    "            return 1\n",
    "\n",
    "        # Правило 7: Наличие подозрительных n-грамм\n",
    "        for i in range(len(normalized_name_lower) - 1):\n",
    "            if normalized_name_lower[i:i+2] in suspicious_ngrams:\n",
    "                return 1\n",
    "        for i in range(len(normalized_name_lower) - 2):\n",
    "            if normalized_name_lower[i:i+3] in suspicious_ngrams:\n",
    "                return 1\n",
    "\n",
    "        return 0\n",
    "\n",
    "    df['name_suspicious_flag'] = df['firstname'].apply(check_name_adequacy)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_sample_for_ml = create_name_suspicious_flag(df_sample)\n",
    "\n",
    "df_sample_for_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fac889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_for_ml['price_order_usd'] = pd.to_numeric(df_sample_for_ml['price_order_usd'], errors='coerce').fillna(0)\n",
    "df_sample_for_ml['distance_kilometers'] = pd.to_numeric(df_sample_for_ml['distance_kilometers'], errors='coerce').fillna(0)\n",
    "\n",
    "df_sample_for_ml['price_per_meter'] = df_sample_for_ml['price_order_usd'] / (df_sample_for_ml['distance_kilometers'] + 0.001)\n",
    "\n",
    "df_sample_for_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13aafe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_for_ml.to_csv('df_sample_for_ml.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18995901",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a078096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_for_ml = pd.read_csv(\"/Users/renatyunison/Desktop/VSC scripts/Working/df_sample_for_ml.csv\")\n",
    "\n",
    "\n",
    "user_ids = df_sample_for_ml['user_id']\n",
    "incident_level = df_sample_for_ml['incident_level']\n",
    "incident_type = df_sample_for_ml['incident_type']\n",
    "city_id = df_sample_for_ml['city_id']\n",
    "\n",
    "print(\"Данные загружены. Размер:\", df_sample_for_ml.shape)\n",
    "\n",
    "print(\"Предобработка данных...\")\n",
    "\n",
    "TARGET = 'incident_flag'\n",
    "\n",
    "X = df_sample_for_ml[\n",
    "    ['user_id', 'incident_level', 'incident_type', 'lifetime', 'appropriate_avatar_flag', \n",
    "    'os_version', 'nighttime_flag', 'distance_meters', \n",
    "    'price_order_usd', 'total_orders', 'total_cancel_orders', 'total_cancel_accepted_orders', 'total_rides', 'cancel_orders_1d_window', \n",
    "    'cancel_accepted_orders_1d_window', 'orders_1d_window', 'rides_1d_window', 'total_device_change', \n",
    "    'total_nickname_change', 'total_avatar_change', 'device_change_1d_window', 'nickname_change_1d_window', \n",
    "    'avatar_change_1d_window', 'device_change_6h_window', 'nickname_change_6h_window', 'avatar_change_6h_window', \n",
    "    'device_change_7d_window', 'nickname_change_7d_window', 'avatar_change_7d_window',\n",
    "    'day_diff_before_order', 'first_day_order', 'customer_rating_1w_window', 'customer_rating_1m_window', 'customer_rating_total', \n",
    "    'bans_before_order', 'appeals_2d_window', 'appeals_1w_window', 'appeals_2w_window', 'appeals_all_time', \n",
    "    'reviews_2d_window', 'reviews_1w_window', 'reviews_2w_window', 'reviews_all_time', 'geo_permission_2d_window', \n",
    "    'device_price_category', 'price_per_meter', 'name_suspicious_flag', 'incident_flag', 'complaints_in_feed', 'appeals_feed_1m', 'appeals_feed_7w']\n",
    "\n",
    "       ].drop(columns=[TARGET, 'user_id', 'incident_level', 'incident_type'])\n",
    "y = df_sample_for_ml[TARGET]\n",
    "\n",
    "categorical_features: List[str] = [\n",
    "    col for col in X.columns if X[col].dtype == 'object'\n",
    "]\n",
    "for col in categorical_features:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "X['cancel_ratio'] = X['total_cancel_orders'] / X['total_orders']\n",
    "X['cancel_ratio'] = X['cancel_ratio'].fillna(0)\n",
    "\n",
    "X['cancel_ratio_1d'] = X['cancel_accepted_orders_1d_window'] / X['orders_1d_window']\n",
    "X['cancel_ratio_1d'] = X['cancel_ratio_1d'].fillna(0)\n",
    "\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "for col in numerical_features:\n",
    "    if X[col].isnull().any():\n",
    "        X[col] = X[col].fillna(0)\n",
    "\n",
    "print(\"Предобработка завершена.\")\n",
    "\n",
    "print(\"Разделение данных и обучение модели...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 150,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 35,\n",
    "    'max_depth': -1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'class_weight': 'balanced',\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "model = lgb.LGBMClassifier(**params)\n",
    "model.fit(X_train, y_train,\n",
    "          categorical_feature=categorical_features)\n",
    "\n",
    "print(\"Обучение модели завершено.\")\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Сохраняем исходные колонки тестового набора для фильтрации\n",
    "df_test = df_sample_for_ml.iloc[y_test.index]\n",
    "df_test['y_test'] = y_test\n",
    "df_test['y_pred_proba'] = y_pred_proba\n",
    "df_test = pd.merge(df_test, incident_level, left_index=True, right_index=True)\n",
    "df_test = pd.merge(df_test, city_id, left_index=True, right_index=True)\n",
    "\n",
    "df_test.drop(columns='incident_level_y', inplace=True)\n",
    "df_test.rename(columns={'incident_level_x':'incident_level'}, inplace=True)\n",
    "df_test.drop(columns='city_id_y', inplace=True)\n",
    "df_test.rename(columns={'city_id_x':'city_id'}, inplace=True)\n",
    "\n",
    "mapping_df = df_test.dropna(subset=['incident_level'])\n",
    "\n",
    "if not mapping_df.groupby('incident_type')['incident_level'].nunique().le(1).all():\n",
    "    type_to_level_mapping = mapping_df.groupby('incident_type')['incident_level'].agg(lambda x: x.mode()[0]).to_dict()\n",
    "else:\n",
    "    type_to_level_mapping = mapping_df.set_index('incident_type')['incident_level'].to_dict()\n",
    "\n",
    "df_test['incident_level'] = df_test['incident_level'].fillna(\n",
    "    df_test['incident_type'].map(type_to_level_mapping)\n",
    ")\n",
    "\n",
    "df_test.to_csv('df_test.csv', index=True)\n",
    "\n",
    "y_pred_proba_full = model.predict_proba(X)[:, 1]\n",
    "\n",
    "final_df = df_sample_for_ml.copy()\n",
    "final_df['user_id'] = user_ids\n",
    "final_df['incident_level'] = incident_level\n",
    "final_df['incident_type'] = incident_type\n",
    "final_df['predicted_probability'] = y_pred_proba_full\n",
    "final_df['predicted_class'] = (final_df['predicted_probability'] >= 0.86).astype(int) # Порог 0.5 для примера\n",
    "\n",
    "final_df.to_csv('final_df.csv')\n",
    "\n",
    "\n",
    "print(\"Расчет метрик для разных порогов...\")\n",
    "metrics_df = pd.DataFrame(columns=[\n",
    "    'Threshold',\n",
    "    'True Positives (TP)', 'False Positives (FP)',\n",
    "    'False Negatives (FN)', 'True Negatives (TN)',\n",
    "    'Recall',\n",
    "    'Precision',\n",
    "    'Accuracy', 'F1-Score', 'FPR'\n",
    "])\n",
    "thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresholded = (y_pred_proba >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_thresholded).ravel()\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    metrics_df.loc[len(metrics_df)] = [\n",
    "        threshold, tp, fp, fn, tn,\n",
    "        recall, precision, accuracy, f1, fpr\n",
    "    ]\n",
    "metrics_df['Recall'] = (metrics_df['Recall'] * 100).round(3)\n",
    "metrics_df['Precision'] = (metrics_df['Precision'] * 100).round(3)\n",
    "metrics_df['Accuracy'] = (metrics_df['Accuracy'] * 100).round(3)\n",
    "metrics_df['F1-Score'] = (metrics_df['F1-Score'] * 100).round(3)\n",
    "metrics_df['FPR'] = (metrics_df['FPR'] * 100).round(3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Финальная таблица метрик:\")\n",
    "print(\"=\"*50)\n",
    "print(metrics_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Анализ важности признаков\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Получаем важность признаков\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Создаем DataFrame для важности признаков\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Сортируем по важности\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353b08ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>lifetime</th>\n",
       "      <th>avatar_flag</th>\n",
       "      <th>appropriate_avatar_flag</th>\n",
       "      <th>city_id</th>\n",
       "      <th>devicemodel</th>\n",
       "      <th>os_version</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>phone</th>\n",
       "      <th>registration_date</th>\n",
       "      <th>nighttime_flag</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_uuid</th>\n",
       "      <th>order_timestamp</th>\n",
       "      <th>incident_flag</th>\n",
       "      <th>incident_level</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>distance_meters</th>\n",
       "      <th>distance_kilometers</th>\n",
       "      <th>price_order_usd</th>\n",
       "      <th>avg_price_order_usd</th>\n",
       "      <th>ratio_price_order_usd</th>\n",
       "      <th>total_orders</th>\n",
       "      <th>total_cancel_orders</th>\n",
       "      <th>total_cancel_accepted_orders</th>\n",
       "      <th>total_rides</th>\n",
       "      <th>cancel_orders_1d_window</th>\n",
       "      <th>cancel_accepted_orders_1d_window</th>\n",
       "      <th>orders_1d_window</th>\n",
       "      <th>rides_1d_window</th>\n",
       "      <th>total_device_change</th>\n",
       "      <th>total_nickname_change</th>\n",
       "      <th>total_avatar_change</th>\n",
       "      <th>device_change_1d_window</th>\n",
       "      <th>nickname_change_1d_window</th>\n",
       "      <th>avatar_change_1d_window</th>\n",
       "      <th>device_change_6h_window</th>\n",
       "      <th>nickname_change_6h_window</th>\n",
       "      <th>avatar_change_6h_window</th>\n",
       "      <th>device_change_7d_window</th>\n",
       "      <th>nickname_change_7d_window</th>\n",
       "      <th>avatar_change_7d_window</th>\n",
       "      <th>device</th>\n",
       "      <th>liveness</th>\n",
       "      <th>device_liveness</th>\n",
       "      <th>last_ride_date</th>\n",
       "      <th>day_diff_before_order</th>\n",
       "      <th>first_day_order</th>\n",
       "      <th>customer_rating_1w_window</th>\n",
       "      <th>customer_rating_1m_window</th>\n",
       "      <th>customer_rating_total</th>\n",
       "      <th>bans_before_order</th>\n",
       "      <th>appeals_2d_window</th>\n",
       "      <th>appeals_1w_window</th>\n",
       "      <th>appeals_2w_window</th>\n",
       "      <th>appeals_all_time</th>\n",
       "      <th>reviews_2d_window</th>\n",
       "      <th>reviews_1w_window</th>\n",
       "      <th>reviews_2w_window</th>\n",
       "      <th>reviews_all_time</th>\n",
       "      <th>geo_permission_2d_window</th>\n",
       "      <th>complaints_in_feed</th>\n",
       "      <th>appeals_feed_1m</th>\n",
       "      <th>appeals_feed_7w</th>\n",
       "      <th>device_price_category</th>\n",
       "      <th>name_suspicious_flag</th>\n",
       "      <th>price_per_meter</th>\n",
       "      <th>predicted_probability</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>289646646</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5640</td>\n",
       "      <td>V2333 vivo V2333</td>\n",
       "      <td>Android</td>\n",
       "      <td>ridwan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6282349886014</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>0</td>\n",
       "      <td>3,874,366,842,494,306,304.00</td>\n",
       "      <td>0196cce4-1873-7989-8776-12d8f31d879e</td>\n",
       "      <td>2025-05-14 11:43:42.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>994.17</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.27</td>\n",
       "      <td>14.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-17</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mid-range</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>290241495</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4532</td>\n",
       "      <td>a54x samsung SM-A546E</td>\n",
       "      <td>Android</td>\n",
       "      <td>Ana Luiza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5562991466332</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>2,343,484,012,339,849,728.00</td>\n",
       "      <td>0197fcc1-4900-800b-c05a-f89388b5e54a</td>\n",
       "      <td>2025-07-12 00:50:15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,141.22</td>\n",
       "      <td>3.14</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.85</td>\n",
       "      <td>22.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>enable</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mid-range</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>295896279</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6079</td>\n",
       "      <td>a15x samsung SM-A156M</td>\n",
       "      <td>Android</td>\n",
       "      <td>Miguel Ángel Aníbal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50254434430</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>1</td>\n",
       "      <td>6,807,366,403,132,298,240.00</td>\n",
       "      <td>0197bb83-4fcd-8017-c040-d4766e5f44a7</td>\n",
       "      <td>2025-06-29 05:47:14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,488.64</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.01</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4.77</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mid-range</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>275248105</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10155</td>\n",
       "      <td>blue Redmi 23129RN51X</td>\n",
       "      <td>Android</td>\n",
       "      <td>صلاح</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201151905046</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>3,738,610,074,304,463,872.00</td>\n",
       "      <td>01955e9c-ac80-7926-804d-a44b938a1120</td>\n",
       "      <td>2025-03-04 02:44:40.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,632.93</td>\n",
       "      <td>5.63</td>\n",
       "      <td>1.96</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.87</td>\n",
       "      <td>17.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>budget</td>\n",
       "      <td>1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>292936861</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>840</td>\n",
       "      <td>iPhone 16 Pro</td>\n",
       "      <td>IOS</td>\n",
       "      <td>Anne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639062671417</td>\n",
       "      <td>2025-04-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1,344,414,298,766,548,224.00</td>\n",
       "      <td>019681c3-b84b-7053-a4ef-b71d69715f4e</td>\n",
       "      <td>2025-04-29 21:36:49.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53,539.52</td>\n",
       "      <td>53.54</td>\n",
       "      <td>26.89</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.05</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>premium</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    user_id  lifetime  avatar_flag  appropriate_avatar_flag  city_id            devicemodel os_version              firstname lastname          phone registration_date  nighttime_flag                     order_id                            order_uuid             order_timestamp  incident_flag incident_level incident_type  distance_meters  distance_kilometers  price_order_usd  avg_price_order_usd  ratio_price_order_usd  total_orders  total_cancel_orders  total_cancel_accepted_orders  total_rides  cancel_orders_1d_window  cancel_accepted_orders_1d_window  orders_1d_window  rides_1d_window  total_device_change  total_nickname_change  total_avatar_change  device_change_1d_window  nickname_change_1d_window  avatar_change_1d_window  device_change_6h_window  nickname_change_6h_window  avatar_change_6h_window  device_change_7d_window  nickname_change_7d_window  avatar_change_7d_window  device  liveness  device_liveness last_ride_date  day_diff_before_order  first_day_order  \\\n",
       "0           0  289646646       139            0                        0     5640       V2333 vivo V2333    Android                 ridwan      NaN  6282349886014        2025-04-09               0 3,874,366,842,494,306,304.00  0196cce4-1873-7989-8776-12d8f31d879e  2025-05-14 11:43:42.000000              0            NaN           NaN           994.17                 0.99             0.85                 3.17                   0.27         14.00                 6.00                          6.00         7.00                        1                                 1                 3                1                    1                      1                    0                        0                          0                        0                        0                          0                        0                        0                          0                        0       0         0                0     2025-04-17                     27                0   \n",
       "1           1  290241495       136            1                        0     4532  a54x samsung SM-A546E    Android              Ana Luiza      NaN  5562991466332        2025-04-12               1 2,343,484,012,339,849,728.00  0197fcc1-4900-800b-c05a-f89388b5e54a  2025-07-12 00:50:15.000000              0            NaN           NaN         3,141.22                 3.14             2.88                 3.37                   0.85         22.00                12.00                          1.00         9.00                        0                                 0                 1                0                    1                      1                    1                        0                          0                        0                        0                          0                        0                        0                          0                        0       0         0                0     2025-07-11                      1                0   \n",
       "2           2  295896279       101            1                        0     6079  a15x samsung SM-A156M    Android  Miguel Ángel Aníbal      NaN    50254434430        2025-05-17               1 6,807,366,403,132,298,240.00  0197bb83-4fcd-8017-c040-d4766e5f44a7  2025-06-29 05:47:14.000000              0            NaN           NaN         1,488.64                 1.49             2.60                 2.58                   1.01          7.00                 1.00                          0.00         6.00                        0                                 0                 1                0                    1                      1                    1                        0                          0                        0                        0                          0                        0                        0                          0                        0       0         0                0     2025-06-16                     13                0   \n",
       "3           3  275248105       230            0                        0    10155  blue Redmi 23129RN51X    Android                   صلاح      NaN   201151905046        2025-01-08               1 3,738,610,074,304,463,872.00  01955e9c-ac80-7926-804d-a44b938a1120  2025-03-04 02:44:40.000000              0            NaN           NaN         5,632.93                 5.63             1.96                 2.26                   0.87         17.00                11.00                          4.00         4.00                        0                                 0                 2                0                    1                      1                    0                        0                          0                        0                        0                          0                        0                        0                          0                        0       0         0                0     2025-03-01                      3                0   \n",
       "4           4  292936861       119            0                        0      840          iPhone 16 Pro        IOS                   Anne      NaN   639062671417        2025-04-29               1 1,344,414,298,766,548,224.00  019681c3-b84b-7053-a4ef-b71d69715f4e  2025-04-29 21:36:49.000000              0            NaN           NaN        53,539.52                53.54            26.89                 5.33                   5.05          2.00                 2.00                          0.00         0.00                        1                                 0                 1                0                    1                      1                    0                        1                          1                        0                        0                          0                        0                        1                          1                        0       0         0                0            NaN                      0                1   \n",
       "\n",
       "   customer_rating_1w_window  customer_rating_1m_window  customer_rating_total  bans_before_order  appeals_2d_window  appeals_1w_window  appeals_2w_window  appeals_all_time  reviews_2d_window  reviews_1w_window  reviews_2w_window  reviews_all_time geo_permission_2d_window  complaints_in_feed  appeals_feed_1m  appeals_feed_7w device_price_category  name_suspicious_flag  price_per_meter  predicted_probability  predicted_class  \n",
       "0                       5.00                       5.00                   5.00                  0                  0                  0                  0                 0                  0                  0                  0                 0                  unknown                   0                0                0             mid-range                     1             0.85                   0.36                0  \n",
       "1                       3.81                       3.81                   4.70                  0                  0                  0                  0                 0                  0                  0                  0                 0                   enable                   0                0                0             mid-range                     0             0.92                   0.62                0  \n",
       "2                       4.77                       4.73                   4.67                  0                  0                  0                  0                 0                  0                  0                  0                 0                  unknown                   0                0                0             mid-range                     0             1.75                   0.14                0  \n",
       "3                       1.00                       1.00                   1.14                  1                  0                  0                  0                 0                  0                  0                  0                 0                  unknown                   0                0                0                budget                     1             0.35                   0.65                0  \n",
       "4                       4.80                       4.80                   4.80                  0                  0                  0                  0                 0                  0                  0                  0                 0                  unknown                   0                0                0               premium                     0             0.50                   0.01                0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/renatyunison/Desktop/VSC scripts/Working/final_df.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b244960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10082.46it/s]\n"
     ]
    }
   ],
   "source": [
    "df['order_timestamp'] = pd.to_datetime(df['order_timestamp'])\n",
    "\n",
    "\n",
    "pandas_gbq.to_gbq(df[['user_id', 'city_id', 'order_timestamp', 'predicted_probability', 'predicted_class']],\n",
    "                destination_table='renat_yunisov.lgb_results_safety_scoring',\n",
    "                project_id='analytics-dev-333113',\n",
    "                if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61cab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"Значение ROC-AUC на тестовой выборке: {roc_auc:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.sort_values('Precision', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d43728",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df[(metrics_df['Recall']>50)&(metrics_df['Recall']<70)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e07a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv('metrics_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e17c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "X_sample = X_test.sample(n=10000, random_state=42)\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "if isinstance(shap_values, list):\n",
    "    if len(shap_values) > 1:\n",
    "        shap_values_to_plot = shap_values[1]\n",
    "    else:\n",
    "\n",
    "        shap_values_to_plot = shap_values[0]\n",
    "else:\n",
    "    shap_values_to_plot = shap_values\n",
    "\n",
    "shap.summary_plot(shap_values_to_plot, X_sample)\n",
    "\n",
    "shap.summary_plot(shap_values_to_plot, X_sample, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_features = categorical_features + ['name_suspicious_flag']\n",
    "\n",
    "for value in categorical_features:\n",
    "    shap.dependence_plot(value, shap_values_to_plot, X_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea111266",
   "metadata": {},
   "source": [
    "##### By Incident level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b34cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = pd.concat([y_test, df_test[['incident_level', 'y_pred_proba', 'city_id']]], axis=1)\n",
    "\n",
    "levels = ['Red', 'Green', 'Yellow']\n",
    "\n",
    "df_metric_res = pd.DataFrame()\n",
    "\n",
    "for level in levels:\n",
    "    print(f'Region: {level}')\n",
    "\n",
    "    metrics_df_by_levels = pd.DataFrame(columns=[\n",
    "        'Threshold',\n",
    "        'True Positives (TP)', 'False Positives (FP)',\n",
    "        'False Negatives (FN)', 'True Negatives (TN)',\n",
    "        'Recall',\n",
    "        'Precision',\n",
    "        'Accuracy', 'F1-Score', 'FPR'\n",
    "    ])\n",
    "\n",
    "\n",
    "    thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "    for threshold in thresholds:\n",
    "        \n",
    "        y_pred_thresholded = (model_res[(model_res['incident_level'].isna())|(model_res['incident_level']==level)]['y_pred_proba'] >= threshold).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(model_res[(model_res['incident_level'].isna())|(model_res['incident_level']==level)]['incident_flag'], y_pred_thresholded).ravel()\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        metrics_df_by_levels.loc[len(metrics_df_by_levels)] = [\n",
    "            threshold, tp, fp, fn, tn,\n",
    "            recall, precision, accuracy, f1, fpr\n",
    "        ]\n",
    "    metrics_df_by_levels['Recall'] = (metrics_df_by_levels['Recall'] * 100).round(3)\n",
    "    metrics_df_by_levels['Precision'] = (metrics_df_by_levels['Precision'] * 100).round(3)\n",
    "    metrics_df_by_levels['Accuracy'] = (metrics_df_by_levels['Accuracy'] * 100).round(3)\n",
    "    metrics_df_by_levels['F1-Score'] = (metrics_df_by_levels['F1-Score'] * 100).round(3)\n",
    "    metrics_df_by_levels['FPR'] = (metrics_df_by_levels['FPR'] * 100).round(3)\n",
    "    metrics_df_by_levels['Level'] = level\n",
    "\n",
    "    df_metric_res = pd.concat([df_metric_res, metrics_df_by_levels])\n",
    "\n",
    "df_metric_res.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5fc90b",
   "metadata": {},
   "source": [
    "##### By Incident type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321956de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = pd.concat([y_test, df_test[['incident_type', 'y_pred_proba', 'city_id']]], axis=1)\n",
    "\n",
    "df_metric_res = pd.DataFrame()\n",
    "\n",
    "for level in tqdm(df_test[~df_test['incident_type'].isna()]['incident_type'].unique()):\n",
    "    print(f'Region: {level}')\n",
    "\n",
    "    metrics_df_by_levels = pd.DataFrame(columns=[\n",
    "        'Threshold',\n",
    "        'True Positives (TP)', 'False Positives (FP)',\n",
    "        'False Negatives (FN)', 'True Negatives (TN)',\n",
    "        'Recall',\n",
    "        'Precision',\n",
    "        'Accuracy', 'F1-Score', 'FPR'\n",
    "    ])\n",
    "\n",
    "\n",
    "    thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "    for threshold in thresholds:\n",
    "        \n",
    "        y_pred_thresholded = (model_res[(model_res['incident_type'].isna())|(model_res['incident_type']==level)]['y_pred_proba'] >= threshold).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(model_res[(model_res['incident_type'].isna())|(model_res['incident_type']==level)]['incident_flag'], y_pred_thresholded).ravel()\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        metrics_df_by_levels.loc[len(metrics_df_by_levels)] = [\n",
    "            threshold, tp, fp, fn, tn,\n",
    "            recall, precision, accuracy, f1, fpr\n",
    "        ]\n",
    "    metrics_df_by_levels['Recall'] = (metrics_df_by_levels['Recall'] * 100).round(3)\n",
    "    metrics_df_by_levels['Precision'] = (metrics_df_by_levels['Precision'] * 100).round(3)\n",
    "    metrics_df_by_levels['Accuracy'] = (metrics_df_by_levels['Accuracy'] * 100).round(3)\n",
    "    metrics_df_by_levels['F1-Score'] = (metrics_df_by_levels['F1-Score'] * 100).round(3)\n",
    "    metrics_df_by_levels['FPR'] = (metrics_df_by_levels['FPR'] * 100).round(3)\n",
    "    metrics_df_by_levels['Level'] = level\n",
    "\n",
    "    df_metric_res = pd.concat([df_metric_res, metrics_df_by_levels])\n",
    "\n",
    "df_metric_res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1642ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric_res.to_csv('df_metric_res.csv', index=True)\n",
    "model_res.to_csv('model_res.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c60d0c",
   "metadata": {},
   "source": [
    "#### By cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('df_test.csv')\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities = read_bq(\"\"\"\n",
    "SELECT city_id, country_id, country_name, macroregion_name\n",
    "FROM indriver-e6e40.heap.vw_macroregion_mapping\n",
    "\"\"\")\n",
    "\n",
    "df_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.merge(df_cities, left_on='city_id', right_on='city_id', how='inner')\n",
    "\n",
    "df_test_by_region = df_test.rename(columns={'Unnamed: 0':'index'}).set_index('index')\n",
    "\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67549329",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = pd.merge(y_test, df_test_by_region[['incident_level', 'y_pred_proba', 'country_name', 'macroregion_name']], left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "df_metric_res = pd.DataFrame()\n",
    "\n",
    "for country in tqdm(model_res['macroregion_name'].unique()):\n",
    "    print(f'Region: {country}')\n",
    "\n",
    "    metrics_df_by_region = pd.DataFrame(columns=[\n",
    "        'Threshold',\n",
    "        'True Positives (TP)', 'False Positives (FP)',\n",
    "        'False Negatives (FN)', 'True Negatives (TN)',\n",
    "        'Recall',\n",
    "        'Precision',\n",
    "        'Accuracy', 'F1-Score', 'FPR'\n",
    "    ])\n",
    "\n",
    "\n",
    "    thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "    for threshold in thresholds:\n",
    "        \n",
    "        y_pred_thresholded = (model_res[(model_res['macroregion_name']==country)]['y_pred_proba'] >= threshold).astype(int)\n",
    "\n",
    "        try:\n",
    "            tn, fp, fn, tp = confusion_matrix(model_res[(model_res['macroregion_name']==country)]['incident_flag'], y_pred_thresholded).ravel()\n",
    "        except ValueError:\n",
    "            continue\n",
    "        \n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        metrics_df_by_region.loc[len(metrics_df_by_region)] = [\n",
    "            threshold, tp, fp, fn, tn,\n",
    "            recall, precision, accuracy, f1, fpr\n",
    "        ]\n",
    "    metrics_df_by_region['Recall'] = (metrics_df_by_region['Recall'] * 100).round(3)\n",
    "    metrics_df_by_region['Precision'] = (metrics_df_by_region['Precision'] * 100).round(3)\n",
    "    metrics_df_by_region['Accuracy'] = (metrics_df_by_region['Accuracy'] * 100).round(3)\n",
    "    metrics_df_by_region['F1-Score'] = (metrics_df_by_region['F1-Score'] * 100).round(3)\n",
    "    metrics_df_by_region['FPR'] = (metrics_df_by_region['FPR'] * 100).round(3)\n",
    "    metrics_df_by_region['Level'] = country\n",
    "\n",
    "    df_metric_res_reg = pd.concat([df_metric_res, metrics_df_by_region])\n",
    "\n",
    "df_metric_res_reg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b06be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric_res_reg.to_csv('df_metric_res_reg.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric_res.sort_values('F1-Score', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af282288",
   "metadata": {},
   "source": [
    "### Log regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9441b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_for_ml[[\n",
    "    'price_per_meter', 'price_order_usd', 'total_cancel_accepted_orders', 'customer_rating_1w_window', 'day_diff_before_order', 'lifetime',\n",
    "    'total_rides', 'orders_1d_window', 'customer_rating_1m_window', 'bans_before_order', 'total_cancel_orders', 'total_orders', 'nighttime_flag', 'cancel_accepted_orders_1d_window'\n",
    "    ] + ['user_id', 'incident_level', 'incident_type', 'city_id', 'complaints_in_feed', 'appeals_feed_1m', 'appeals_feed_7w', 'incident_flag']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sample_for_ml = pd.read_csv(\"/Users/renatyunison/Desktop/VSC scripts/Working/df_sample_for_ml.csv\")\n",
    "\n",
    "user_ids = df_sample_for_ml['user_id']\n",
    "incident_level = df_sample_for_ml['incident_level']\n",
    "incident_type = df_sample_for_ml['incident_type']\n",
    "city_id = df_sample_for_ml['city_id']\n",
    "\n",
    "df_full = df_sample_for_ml.copy()\n",
    "\n",
    "\n",
    "sample_size_frac = 0.5\n",
    "\n",
    "\n",
    "_, df_sampled = train_test_split(df_full, test_size=sample_size_frac, random_state=42, stratify=df_full['incident_flag'])\n",
    "\n",
    "df = df_sampled.copy()\n",
    "\n",
    "\n",
    "TARGET = 'incident_flag'\n",
    "\n",
    "X = df[[\n",
    "    'price_per_meter', 'price_order_usd', 'total_cancel_accepted_orders', 'customer_rating_1w_window', 'day_diff_before_order', 'lifetime',\n",
    "    'total_rides', 'orders_1d_window', 'customer_rating_1m_window', 'bans_before_order', 'total_cancel_orders', 'total_orders', 'nighttime_flag', 'cancel_accepted_orders_1d_window'\n",
    "    ] + ['user_id', 'incident_level', 'incident_type', 'city_id', 'complaints_in_feed', 'appeals_feed_1m', 'appeals_feed_7w', 'incident_flag']].drop(columns=[TARGET, 'user_id', 'incident_level', 'incident_type', 'city_id'])\n",
    "y = df[TARGET]\n",
    "\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "for col in numerical_features:\n",
    "    if X[col].isnull().any():\n",
    "        X[col] = X[col].fillna(0)\n",
    "\n",
    "object_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "for col in object_cols:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "print(\"Предобработка данных для логистической регрессии...\")\n",
    "\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include='category').columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    "\n",
    "print(\"Разделение данных и обучение модели...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "logreg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Обучение модели завершено.\")\n",
    "\n",
    "y_pred_proba = logreg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Расчет метрик для разных порогов...\")\n",
    "metrics_df = pd.DataFrame(columns=[\n",
    "    'Threshold',\n",
    "    'True Positives (TP)', 'False Positives (FP)',\n",
    "    'False Negatives (FN)', 'True Negatives (TN)',\n",
    "    'Recall',\n",
    "    'Precision',\n",
    "    'Accuracy', 'F1-Score', 'FPR'\n",
    "])\n",
    "\n",
    "thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresholded = (y_pred_proba >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_thresholded).ravel()\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    metrics_df.loc[len(metrics_df)] = [\n",
    "        threshold, tp, fp, fn, tn,\n",
    "        recall, precision, accuracy, f1, fpr\n",
    "    ]\n",
    "\n",
    "metrics_df['Recall'] = (metrics_df['Recall'] * 100).round(3)\n",
    "metrics_df['Precision'] = (metrics_df['Precision'] * 100).round(3)\n",
    "metrics_df['Accuracy'] = (metrics_df['Accuracy'] * 100).round(3)\n",
    "metrics_df['F1-Score'] = (metrics_df['F1-Score'] * 100).round(3)\n",
    "metrics_df['FPR'] = (metrics_df['FPR'] * 100).round(3)\n",
    "    \n",
    "print(\"Расчет метрик завершен.\")\n",
    "print(metrics_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Анализ важности признаков (коэффициенты)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "coefficients = logreg_pipeline.named_steps['classifier'].coef_[0]\n",
    "\n",
    "all_feature_names = numerical_features + ohe_feature_names.tolist()\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "importance_df['Absolute_Coefficient'] = importance_df['Coefficient'].abs()\n",
    "importance_df = importance_df.sort_values(by='Absolute_Coefficient', ascending=False)\n",
    "print(importance_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e967807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('Safety Scoring ML - Error matrix Log regression.csv')\n",
    "\n",
    "df[\"TPR\"] = df[\"Recall\"] / 100\n",
    "df[\"FPR\"] = df[\"FPR\"] / 100\n",
    "\n",
    "df = df.sort_values(\"FPR\")\n",
    "roc_auc = auc(df[\"FPR\"], df[\"TPR\"])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(df[\"FPR\"], df[\"TPR\"], marker='', label=f\"ROC (AUC = {roc_auc:.3f})\", color='orange')\n",
    "plt.plot([0,1], [0,1], 'k--', label=\"Random guess\", color='blue')\n",
    "\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (Recall / TPR)\")\n",
    "plt.title(\"ROC Curve for Regression Model\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54639461",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_names = numerical_features\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "importance_df['Absolute_Coefficient'] = importance_df['Coefficient'].abs()\n",
    "importance_df = importance_df.sort_values(by='Absolute_Coefficient', ascending=False)\n",
    "importance_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e687e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv('log_regression.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cbd34",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Union\n",
    "\n",
    "def calculate_feature_importance_share(\n",
    "    importance_scores: Union[np.ndarray, List[float]], \n",
    "    feature_names: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Рассчитывает относительный и кумулятивный процент важности признаков.\n",
    "\n",
    "    Args:\n",
    "        importance_scores: Массив или список с оценками важности признаков.\n",
    "        feature_names: Список названий признаков.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame с отсортированными признаками и их долей важности.\n",
    "    \"\"\"\n",
    "    if len(importance_scores) != len(feature_names):\n",
    "        raise ValueError(\"Размеры массивов 'importance_scores' и 'feature_names' должны совпадать.\")\n",
    "        \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance_Score': np.abs(importance_scores) # Используем абсолютное значение для коэффициентов\n",
    "    })\n",
    "    \n",
    "    # Сортируем по убыванию\n",
    "    importance_df = importance_df.sort_values(by='Importance_Score', ascending=False)\n",
    "    \n",
    "    # Рассчитываем общую сумму важности\n",
    "    total_importance = importance_df['Importance_Score'].sum()\n",
    "    \n",
    "    # Рассчитываем относительный процент\n",
    "    importance_df['Relative_Share (%)'] = (importance_df['Importance_Score'] / total_importance) * 100\n",
    "    \n",
    "    # Рассчитываем кумулятивный процент\n",
    "    importance_df['Cumulative_Share (%)'] = importance_df['Relative_Share (%)'].cumsum()\n",
    "    \n",
    "    return importance_df.reset_index(drop=True)\n",
    "\n",
    "lgbm_importance = model.feature_importances_\n",
    "lgbm_feature_names = X_train.columns.tolist()\n",
    "\n",
    "lgbm_importance_df = calculate_feature_importance_share(lgbm_importance, lgbm_feature_names)\n",
    "\n",
    "lgbm_importance_df.head(10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logreg_coeffs = logreg_pipeline.named_steps['classifier'].coef_[0]\n",
    "\n",
    "all_feature_names = numerical_features\n",
    "\n",
    "logreg_importance_df = calculate_feature_importance_share(logreg_coeffs, all_feature_names)\n",
    "\n",
    "print(\"\\n--- Важность признаков для логистической регрессии (доля) ---\")\n",
    "print(logreg_importance_df.head(10))\n",
    "\n",
    "top_80_percent_features = logreg_importance_df[logreg_importance_df['Cumulative_Share (%)'] <= 80]\n",
    "print(\"\\n--- 80% самых важных признаков в логистической регрессии ---\")\n",
    "print(top_80_percent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af33d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e99c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_importance_df[lgbm_importance_df['Cumulative_Share (%)']>80]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
